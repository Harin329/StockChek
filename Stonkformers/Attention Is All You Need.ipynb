{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib==3.2.2 in /usr/local/lib/python3.6/dist-packages (3.2.2)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.2.2) (1.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.2.2) (2.8.1)\r\n",
      "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.2.2) (1.18.5)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.2.2) (0.10.0)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.2.2) (2.4.7)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib==3.2.2) (1.15.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q tfds-nightly\n",
    "\n",
    "# Pin matplotlib version to 3.2.2 since in the latest version\n",
    "# transformer.ipynb fails with the following error:\n",
    "# https://stackoverflow.com/questions/62953704/valueerror-the-number-of-fixedlocator-locations-5-usually-from-a-call-to-set\n",
    "!pip install matplotlib==3.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True,\n",
    "                               as_supervised=True)\n",
    "train_examples, val_examples = examples['train'], examples['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (en.numpy() for pt, en in train_examples), target_vocab_size=2**13)\n",
    "\n",
    "tokenizer_pt = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    (pt.numpy() for pt, en in train_examples), target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized string is [7915, 1248, 7946, 7194, 13, 2799, 7877]\n",
      "The original string: Transformer is awesome.\n"
     ]
    }
   ],
   "source": [
    "sample_string = 'Transformer is awesome.'\n",
    "\n",
    "tokenized_string = tokenizer_en.encode(sample_string)\n",
    "print ('Tokenized string is {}'.format(tokenized_string))\n",
    "\n",
    "original_string = tokenizer_en.decode(tokenized_string)\n",
    "print ('The original string: {}'.format(original_string))\n",
    "\n",
    "assert original_string == sample_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7915 ----> T\n",
      "1248 ----> ran\n",
      "7946 ----> s\n",
      "7194 ----> former \n",
      "13 ----> is \n",
      "2799 ----> awesome\n",
      "7877 ----> .\n"
     ]
    }
   ],
   "source": [
    "for ts in tokenized_string:\n",
    "  print ('{} ----> {}'.format(ts, tokenizer_en.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(lang1, lang2):\n",
    "  lang1 = [tokenizer_pt.vocab_size] + tokenizer_pt.encode(\n",
    "      lang1.numpy()) + [tokenizer_pt.vocab_size+1]\n",
    "\n",
    "  lang2 = [tokenizer_en.vocab_size] + tokenizer_en.encode(\n",
    "      lang2.numpy()) + [tokenizer_en.vocab_size+1]\n",
    "  \n",
    "  return lang1, lang2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_encode(pt, en):\n",
    "  result_pt, result_en = tf.py_function(encode, [pt, en], [tf.int64, tf.int64])\n",
    "  result_pt.set_shape([None])\n",
    "  result_en.set_shape([None])\n",
    "\n",
    "  return result_pt, result_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
    "  return tf.logical_and(tf.size(x) <= max_length,\n",
    "                        tf.size(y) <= max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_examples.map(tf_encode)\n",
    "train_dataset = train_dataset.filter(filter_max_length)\n",
    "# cache the dataset to memory to get a speedup while reading from it.\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE)\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "val_dataset = val_examples.map(tf_encode)\n",
    "val_dataset = val_dataset.filter(filter_max_length).padded_batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 38), dtype=int64, numpy=\n",
       " array([[8214,  342, 3032, ...,    0,    0,    0],\n",
       "        [8214,   95,  198, ...,    0,    0,    0],\n",
       "        [8214, 4479, 7990, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [8214,  584,   12, ...,    0,    0,    0],\n",
       "        [8214,   59, 1548, ...,    0,    0,    0],\n",
       "        [8214,  118,   34, ...,    0,    0,    0]])>,\n",
       " <tf.Tensor: shape=(64, 40), dtype=int64, numpy=\n",
       " array([[8087,   98,   25, ...,    0,    0,    0],\n",
       "        [8087,   12,   20, ...,    0,    0,    0],\n",
       "        [8087,   12, 5453, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [8087,   18, 2059, ...,    0,    0,    0],\n",
       "        [8087,   16, 1436, ...,    0,    0,    0],\n",
       "        [8087,   15,   57, ...,    0,    0,    0]])>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_batch, en_batch = next(iter(val_dataset))\n",
    "pt_batch, en_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "  return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "  \n",
    "  # apply sin to even indices in the array; 2i\n",
    "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "  # apply cos to odd indices in the array; 2i+1\n",
    "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "  pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_encoding = positional_encoding(50, 512)\n",
    "print (pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "  \n",
    "  # add extra dimensions to add the padding\n",
    "  # to the attention logits.\n",
    "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 1., 1., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
    "create_padding_mask(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "  return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.uniform((1, 3))\n",
    "temp = create_look_ahead_mask(x.shape[1])\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "  \"\"\"Calculate the attention weights.\n",
    "  q, k, v must have matching leading dimensions.\n",
    "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "  The mask has different shapes depending on its type(padding or look ahead) \n",
    "  but it must be broadcastable for addition.\n",
    "  \n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "    \n",
    "  Returns:\n",
    "    output, attention_weights\n",
    "  \"\"\"\n",
    "\n",
    "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "  \n",
    "  # scale matmul_qk\n",
    "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # add the mask to the scaled tensor.\n",
    "  if mask is not None:\n",
    "    scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "  # add up to 1.\n",
    "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "  return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_out(q, k, v):\n",
    "  temp_out, temp_attn = scaled_dot_product_attention(\n",
    "      q, k, v, None)\n",
    "  print ('Attention weights are:')\n",
    "  print (temp_attn)\n",
    "  print ('Output is:')\n",
    "  print (temp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "\n",
    "# This `query` aligns with the second `key`,\n",
    "# so the second `value` is returned.\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This query aligns with a repeated key (third and fourth), \n",
    "# so all associated values get averaged.\n",
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.5 0.5 0.  0. ]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[5.5 0. ]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This query aligns equally with the first and second key, \n",
    "# so their values get averaged.\n",
    "temp_q = tf.constant([[10, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor(\n",
      "[[550.    5.5]\n",
      " [ 10.    0. ]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads):\n",
    "    super(MultiHeadAttention, self).__init__()\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "    \n",
    "    assert d_model % self.num_heads == 0\n",
    "    \n",
    "    self.depth = d_model // self.num_heads\n",
    "    \n",
    "    self.wq = tf.keras.layers.Dense(d_model)\n",
    "    self.wk = tf.keras.layers.Dense(d_model)\n",
    "    self.wv = tf.keras.layers.Dense(d_model)\n",
    "    \n",
    "    self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "  def split_heads(self, x, batch_size):\n",
    "    \"\"\"Split the last dimension into (num_heads, depth).\n",
    "    Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "    \"\"\"\n",
    "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "  def call(self, v, k, q, mask):\n",
    "    batch_size = tf.shape(q)[0]\n",
    "    \n",
    "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "    \n",
    "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "    \n",
    "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "        q, k, v, mask)\n",
    "    \n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "    concat_attention = tf.reshape(scaled_attention, \n",
    "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
    "y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n",
    "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
    "out.shape, attn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "  return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
    "sample_ffn(tf.random.uniform((64, 50, 512))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(EncoderLayer, self).__init__()\n",
    "\n",
    "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "    attn_output = self.dropout1(attn_output, training=training)\n",
    "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "    ffn_output = self.dropout2(ffn_output, training=training)\n",
    "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "    \n",
    "    return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 43, 512])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_encoder_layer_output = sample_encoder_layer(\n",
    "    tf.random.uniform((64, 43, 512)), False, None)\n",
    "\n",
    "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    " \n",
    "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn1 = self.dropout1(attn1, training=training)\n",
    "    out1 = self.layernorm1(attn1 + x)\n",
    "    \n",
    "    attn2, attn_weights_block2 = self.mha2(\n",
    "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "    attn2 = self.dropout2(attn2, training=training)\n",
    "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "    ffn_output = self.dropout3(ffn_output, training=training)\n",
    "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "    \n",
    "    return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
    "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, \n",
    "    False, None, None)\n",
    "\n",
    "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Encoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                            self.d_model)\n",
    "    \n",
    "    \n",
    "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "  \n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "  def call(self, x, training, mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    \n",
    "    # adding embedding and position encoding.\n",
    "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "    x = self.dropout(x, training=training)\n",
    "    \n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x, training, mask)\n",
    "    \n",
    "    return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 62, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, input_vocab_size=8500,\n",
    "                         maximum_position_encoding=10000)\n",
    "temp_input = tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
    "\n",
    "print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "    \n",
    "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    attention_weights = {}\n",
    "    \n",
    "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "    \n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                             look_ahead_mask, padding_mask)\n",
    "      \n",
    "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "    \n",
    "    # x.shape == (batch_size, target_seq_len, d_model)\n",
    "    return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 62]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, \n",
    "                         dff=2048, target_vocab_size=8000,\n",
    "                         maximum_position_encoding=5000)\n",
    "temp_input = tf.random.uniform((64, 26), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "output, attn = sample_decoder(temp_input, \n",
    "                              enc_output=sample_encoder_output, \n",
    "                              training=False,\n",
    "                              look_ahead_mask=None, \n",
    "                              padding_mask=None)\n",
    "\n",
    "output.shape, attn['decoder_layer2_block2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "    super(Transformer, self).__init__()\n",
    "\n",
    "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                           input_vocab_size, pe_input, rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                           target_vocab_size, pe_target, rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "  def call(self, inp, tar, training, enc_padding_mask, \n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "    \n",
    "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "    dec_output, attention_weights = self.decoder(\n",
    "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "    \n",
    "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "    \n",
    "    return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 36, 8000])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_transformer = Transformer(\n",
    "    num_layers=2, d_model=512, num_heads=8, dff=2048, \n",
    "    input_vocab_size=8500, target_vocab_size=8000, \n",
    "    pe_input=10000, pe_target=6000)\n",
    "\n",
    "temp_input = tf.random.uniform((64, 38), dtype=tf.int64, minval=0, maxval=200)\n",
    "temp_target = tf.random.uniform((64, 36), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "fn_out, _ = sample_transformer(temp_input, temp_target, training=False, \n",
    "                               enc_padding_mask=None, \n",
    "                               look_ahead_mask=None,\n",
    "                               dec_padding_mask=None)\n",
    "\n",
    "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = tokenizer_pt.vocab_size + 2\n",
    "target_vocab_size = tokenizer_en.vocab_size + 2\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "    \n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "    \n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "    \n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "  \n",
    "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "  # Encoder padding mask\n",
    "  enc_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # Used in the 2nd attention block in the decoder.\n",
    "  # This padding mask is used to mask the encoder outputs.\n",
    "  dec_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "  # Used in the 1st attention block in the decoder.\n",
    "  # It is used to pad and mask future tokens in the input received by \n",
    "  # the decoder.\n",
    "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "  dec_target_padding_mask = create_padding_mask(tar)\n",
    "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "  return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest checkpoint restored!!\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"./checkpoints/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "  print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
    "# execution. The function specializes to the precise shape of the argument\n",
    "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
    "# batch sizes (the last batch is smaller), use input_signature to specify\n",
    "# more generic shapes.\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "  tar_inp = tar[:, :-1]\n",
    "  tar_real = tar[:, 1:]\n",
    "  \n",
    "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "  \n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions, _ = transformer(inp, tar_inp, \n",
    "                                 True, \n",
    "                                 enc_padding_mask, \n",
    "                                 combined_mask, \n",
    "                                 dec_padding_mask)\n",
    "    loss = loss_function(tar_real, predictions)\n",
    "\n",
    "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "  \n",
    "  train_loss(loss)\n",
    "  train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 0.4804 Accuracy 0.4110\n",
      "Epoch 1 Batch 50 Loss 0.4836 Accuracy 0.4114\n",
      "Epoch 1 Batch 100 Loss 0.4951 Accuracy 0.4113\n",
      "Epoch 1 Batch 150 Loss 0.4999 Accuracy 0.4114\n",
      "Epoch 1 Batch 200 Loss 0.5058 Accuracy 0.4086\n",
      "Epoch 1 Batch 250 Loss 0.5093 Accuracy 0.4068\n",
      "Epoch 1 Batch 300 Loss 0.5135 Accuracy 0.4058\n",
      "Epoch 1 Batch 350 Loss 0.5173 Accuracy 0.4053\n",
      "Epoch 1 Batch 400 Loss 0.5205 Accuracy 0.4045\n",
      "Epoch 1 Batch 450 Loss 0.5238 Accuracy 0.4037\n",
      "Epoch 1 Batch 500 Loss 0.5268 Accuracy 0.4028\n",
      "Epoch 1 Batch 550 Loss 0.5316 Accuracy 0.4022\n",
      "Epoch 1 Batch 600 Loss 0.5356 Accuracy 0.4020\n",
      "Epoch 1 Batch 650 Loss 0.5387 Accuracy 0.4023\n",
      "Epoch 1 Batch 700 Loss 0.5430 Accuracy 0.4016\n",
      "Epoch 1 Loss 0.5430 Accuracy 0.4017\n",
      "Time taken for 1 epoch: 51.484150886535645 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.4642 Accuracy 0.4320\n",
      "Epoch 2 Batch 50 Loss 0.4885 Accuracy 0.4114\n",
      "Epoch 2 Batch 100 Loss 0.4843 Accuracy 0.4081\n",
      "Epoch 2 Batch 150 Loss 0.4900 Accuracy 0.4079\n",
      "Epoch 2 Batch 200 Loss 0.4961 Accuracy 0.4059\n",
      "Epoch 2 Batch 250 Loss 0.5007 Accuracy 0.4057\n",
      "Epoch 2 Batch 300 Loss 0.5061 Accuracy 0.4048\n",
      "Epoch 2 Batch 350 Loss 0.5111 Accuracy 0.4060\n",
      "Epoch 2 Batch 400 Loss 0.5134 Accuracy 0.4062\n",
      "Epoch 2 Batch 450 Loss 0.5161 Accuracy 0.4057\n",
      "Epoch 2 Batch 500 Loss 0.5201 Accuracy 0.4052\n",
      "Epoch 2 Batch 550 Loss 0.5244 Accuracy 0.4045\n",
      "Epoch 2 Batch 600 Loss 0.5288 Accuracy 0.4039\n",
      "Epoch 2 Batch 650 Loss 0.5331 Accuracy 0.4032\n",
      "Epoch 2 Batch 700 Loss 0.5374 Accuracy 0.4024\n",
      "Epoch 2 Loss 0.5378 Accuracy 0.4024\n",
      "Time taken for 1 epoch: 35.105165243148804 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.5290 Accuracy 0.4045\n",
      "Epoch 3 Batch 50 Loss 0.4801 Accuracy 0.4047\n",
      "Epoch 3 Batch 100 Loss 0.4829 Accuracy 0.4049\n",
      "Epoch 3 Batch 150 Loss 0.4888 Accuracy 0.4058\n",
      "Epoch 3 Batch 200 Loss 0.4940 Accuracy 0.4046\n",
      "Epoch 3 Batch 250 Loss 0.4984 Accuracy 0.4040\n",
      "Epoch 3 Batch 300 Loss 0.5023 Accuracy 0.4029\n",
      "Epoch 3 Batch 350 Loss 0.5079 Accuracy 0.4032\n",
      "Epoch 3 Batch 400 Loss 0.5102 Accuracy 0.4034\n",
      "Epoch 3 Batch 450 Loss 0.5143 Accuracy 0.4035\n",
      "Epoch 3 Batch 500 Loss 0.5181 Accuracy 0.4032\n",
      "Epoch 3 Batch 550 Loss 0.5224 Accuracy 0.4025\n",
      "Epoch 3 Batch 600 Loss 0.5259 Accuracy 0.4025\n",
      "Epoch 3 Batch 650 Loss 0.5301 Accuracy 0.4022\n",
      "Epoch 3 Batch 700 Loss 0.5342 Accuracy 0.4022\n",
      "Epoch 3 Loss 0.5343 Accuracy 0.4022\n",
      "Time taken for 1 epoch: 35.1383330821991 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.4249 Accuracy 0.4171\n",
      "Epoch 4 Batch 50 Loss 0.4769 Accuracy 0.4127\n",
      "Epoch 4 Batch 100 Loss 0.4818 Accuracy 0.4102\n",
      "Epoch 4 Batch 150 Loss 0.4864 Accuracy 0.4082\n",
      "Epoch 4 Batch 200 Loss 0.4929 Accuracy 0.4068\n",
      "Epoch 4 Batch 250 Loss 0.4945 Accuracy 0.4073\n",
      "Epoch 4 Batch 300 Loss 0.4981 Accuracy 0.4069\n",
      "Epoch 4 Batch 350 Loss 0.5016 Accuracy 0.4058\n",
      "Epoch 4 Batch 400 Loss 0.5046 Accuracy 0.4062\n",
      "Epoch 4 Batch 450 Loss 0.5080 Accuracy 0.4064\n",
      "Epoch 4 Batch 500 Loss 0.5110 Accuracy 0.4057\n",
      "Epoch 4 Batch 550 Loss 0.5147 Accuracy 0.4045\n",
      "Epoch 4 Batch 600 Loss 0.5189 Accuracy 0.4036\n",
      "Epoch 4 Batch 650 Loss 0.5226 Accuracy 0.4031\n",
      "Epoch 4 Batch 700 Loss 0.5261 Accuracy 0.4031\n",
      "Epoch 4 Loss 0.5263 Accuracy 0.4031\n",
      "Time taken for 1 epoch: 35.14978623390198 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.4759 Accuracy 0.4317\n",
      "Epoch 5 Batch 50 Loss 0.4678 Accuracy 0.4062\n",
      "Epoch 5 Batch 100 Loss 0.4739 Accuracy 0.4054\n",
      "Epoch 5 Batch 150 Loss 0.4759 Accuracy 0.4065\n",
      "Epoch 5 Batch 200 Loss 0.4827 Accuracy 0.4057\n",
      "Epoch 5 Batch 250 Loss 0.4879 Accuracy 0.4062\n",
      "Epoch 5 Batch 300 Loss 0.4893 Accuracy 0.4077\n",
      "Epoch 5 Batch 350 Loss 0.4941 Accuracy 0.4069\n",
      "Epoch 5 Batch 400 Loss 0.4982 Accuracy 0.4070\n",
      "Epoch 5 Batch 450 Loss 0.5009 Accuracy 0.4066\n",
      "Epoch 5 Batch 500 Loss 0.5048 Accuracy 0.4054\n",
      "Epoch 5 Batch 550 Loss 0.5088 Accuracy 0.4052\n",
      "Epoch 5 Batch 600 Loss 0.5131 Accuracy 0.4049\n",
      "Epoch 5 Batch 650 Loss 0.5172 Accuracy 0.4047\n",
      "Epoch 5 Batch 700 Loss 0.5209 Accuracy 0.4039\n",
      "Saving checkpoint for epoch 5 at ./checkpoints/train/ckpt-13\n",
      "Epoch 5 Loss 0.5211 Accuracy 0.4039\n",
      "Time taken for 1 epoch: 35.37702751159668 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.4705 Accuracy 0.4354\n",
      "Epoch 6 Batch 50 Loss 0.4708 Accuracy 0.4114\n",
      "Epoch 6 Batch 100 Loss 0.4705 Accuracy 0.4117\n",
      "Epoch 6 Batch 150 Loss 0.4729 Accuracy 0.4119\n",
      "Epoch 6 Batch 200 Loss 0.4780 Accuracy 0.4101\n",
      "Epoch 6 Batch 250 Loss 0.4810 Accuracy 0.4094\n",
      "Epoch 6 Batch 300 Loss 0.4855 Accuracy 0.4087\n",
      "Epoch 6 Batch 350 Loss 0.4888 Accuracy 0.4082\n",
      "Epoch 6 Batch 400 Loss 0.4924 Accuracy 0.4076\n",
      "Epoch 6 Batch 450 Loss 0.4959 Accuracy 0.4073\n",
      "Epoch 6 Batch 500 Loss 0.4993 Accuracy 0.4071\n",
      "Epoch 6 Batch 550 Loss 0.5037 Accuracy 0.4063\n",
      "Epoch 6 Batch 600 Loss 0.5081 Accuracy 0.4060\n",
      "Epoch 6 Batch 650 Loss 0.5113 Accuracy 0.4051\n",
      "Epoch 6 Batch 700 Loss 0.5150 Accuracy 0.4050\n",
      "Epoch 6 Loss 0.5152 Accuracy 0.4049\n",
      "Time taken for 1 epoch: 35.30424523353577 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.4985 Accuracy 0.3538\n",
      "Epoch 7 Batch 50 Loss 0.4612 Accuracy 0.4087\n",
      "Epoch 7 Batch 100 Loss 0.4670 Accuracy 0.4085\n",
      "Epoch 7 Batch 150 Loss 0.4690 Accuracy 0.4090\n",
      "Epoch 7 Batch 200 Loss 0.4724 Accuracy 0.4100\n",
      "Epoch 7 Batch 250 Loss 0.4765 Accuracy 0.4103\n",
      "Epoch 7 Batch 300 Loss 0.4800 Accuracy 0.4090\n",
      "Epoch 7 Batch 350 Loss 0.4851 Accuracy 0.4087\n",
      "Epoch 7 Batch 400 Loss 0.4876 Accuracy 0.4079\n",
      "Epoch 7 Batch 450 Loss 0.4913 Accuracy 0.4081\n",
      "Epoch 7 Batch 500 Loss 0.4951 Accuracy 0.4068\n",
      "Epoch 7 Batch 550 Loss 0.4996 Accuracy 0.4059\n",
      "Epoch 7 Batch 600 Loss 0.5033 Accuracy 0.4051\n",
      "Epoch 7 Batch 650 Loss 0.5069 Accuracy 0.4048\n",
      "Epoch 7 Batch 700 Loss 0.5098 Accuracy 0.4051\n",
      "Epoch 7 Loss 0.5101 Accuracy 0.4052\n",
      "Time taken for 1 epoch: 35.251370429992676 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.4251 Accuracy 0.4333\n",
      "Epoch 8 Batch 50 Loss 0.4548 Accuracy 0.4174\n",
      "Epoch 8 Batch 100 Loss 0.4581 Accuracy 0.4148\n",
      "Epoch 8 Batch 150 Loss 0.4630 Accuracy 0.4138\n",
      "Epoch 8 Batch 200 Loss 0.4682 Accuracy 0.4134\n",
      "Epoch 8 Batch 250 Loss 0.4703 Accuracy 0.4120\n",
      "Epoch 8 Batch 300 Loss 0.4743 Accuracy 0.4113\n",
      "Epoch 8 Batch 350 Loss 0.4792 Accuracy 0.4095\n",
      "Epoch 8 Batch 400 Loss 0.4828 Accuracy 0.4090\n",
      "Epoch 8 Batch 450 Loss 0.4867 Accuracy 0.4087\n",
      "Epoch 8 Batch 500 Loss 0.4903 Accuracy 0.4081\n",
      "Epoch 8 Batch 550 Loss 0.4941 Accuracy 0.4080\n",
      "Epoch 8 Batch 600 Loss 0.4977 Accuracy 0.4072\n",
      "Epoch 8 Batch 650 Loss 0.5005 Accuracy 0.4067\n",
      "Epoch 8 Batch 700 Loss 0.5041 Accuracy 0.4057\n",
      "Epoch 8 Loss 0.5044 Accuracy 0.4057\n",
      "Time taken for 1 epoch: 35.23501515388489 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.4400 Accuracy 0.4380\n",
      "Epoch 9 Batch 50 Loss 0.4516 Accuracy 0.4072\n",
      "Epoch 9 Batch 100 Loss 0.4527 Accuracy 0.4127\n",
      "Epoch 9 Batch 150 Loss 0.4598 Accuracy 0.4121\n",
      "Epoch 9 Batch 200 Loss 0.4666 Accuracy 0.4104\n",
      "Epoch 9 Batch 250 Loss 0.4707 Accuracy 0.4095\n",
      "Epoch 9 Batch 300 Loss 0.4740 Accuracy 0.4096\n",
      "Epoch 9 Batch 350 Loss 0.4776 Accuracy 0.4092\n",
      "Epoch 9 Batch 400 Loss 0.4813 Accuracy 0.4089\n",
      "Epoch 9 Batch 450 Loss 0.4844 Accuracy 0.4081\n",
      "Epoch 9 Batch 500 Loss 0.4877 Accuracy 0.4077\n",
      "Epoch 9 Batch 550 Loss 0.4911 Accuracy 0.4074\n",
      "Epoch 9 Batch 600 Loss 0.4947 Accuracy 0.4071\n",
      "Epoch 9 Batch 650 Loss 0.4980 Accuracy 0.4067\n",
      "Epoch 9 Batch 700 Loss 0.5014 Accuracy 0.4062\n",
      "Epoch 9 Loss 0.5016 Accuracy 0.4063\n",
      "Time taken for 1 epoch: 35.14858436584473 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.4752 Accuracy 0.3775\n",
      "Epoch 10 Batch 50 Loss 0.4456 Accuracy 0.4116\n",
      "Epoch 10 Batch 100 Loss 0.4462 Accuracy 0.4112\n",
      "Epoch 10 Batch 150 Loss 0.4511 Accuracy 0.4096\n",
      "Epoch 10 Batch 200 Loss 0.4549 Accuracy 0.4097\n",
      "Epoch 10 Batch 250 Loss 0.4586 Accuracy 0.4100\n",
      "Epoch 10 Batch 300 Loss 0.4636 Accuracy 0.4094\n",
      "Epoch 10 Batch 350 Loss 0.4673 Accuracy 0.4098\n",
      "Epoch 10 Batch 400 Loss 0.4714 Accuracy 0.4094\n",
      "Epoch 10 Batch 450 Loss 0.4754 Accuracy 0.4086\n",
      "Epoch 10 Batch 500 Loss 0.4799 Accuracy 0.4079\n",
      "Epoch 10 Batch 550 Loss 0.4848 Accuracy 0.4080\n",
      "Epoch 10 Batch 600 Loss 0.4884 Accuracy 0.4076\n",
      "Epoch 10 Batch 650 Loss 0.4915 Accuracy 0.4073\n",
      "Epoch 10 Batch 700 Loss 0.4948 Accuracy 0.4071\n",
      "Saving checkpoint for epoch 10 at ./checkpoints/train/ckpt-14\n",
      "Epoch 10 Loss 0.4949 Accuracy 0.4071\n",
      "Time taken for 1 epoch: 35.3100368976593 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.4427 Accuracy 0.4317\n",
      "Epoch 11 Batch 50 Loss 0.4394 Accuracy 0.4151\n",
      "Epoch 11 Batch 100 Loss 0.4422 Accuracy 0.4134\n",
      "Epoch 11 Batch 150 Loss 0.4499 Accuracy 0.4133\n",
      "Epoch 11 Batch 200 Loss 0.4531 Accuracy 0.4124\n",
      "Epoch 11 Batch 250 Loss 0.4571 Accuracy 0.4123\n",
      "Epoch 11 Batch 300 Loss 0.4613 Accuracy 0.4124\n",
      "Epoch 11 Batch 350 Loss 0.4657 Accuracy 0.4115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Batch 400 Loss 0.4688 Accuracy 0.4111\n",
      "Epoch 11 Batch 450 Loss 0.4734 Accuracy 0.4095\n",
      "Epoch 11 Batch 500 Loss 0.4766 Accuracy 0.4092\n",
      "Epoch 11 Batch 550 Loss 0.4802 Accuracy 0.4086\n",
      "Epoch 11 Batch 600 Loss 0.4837 Accuracy 0.4085\n",
      "Epoch 11 Batch 650 Loss 0.4881 Accuracy 0.4080\n",
      "Epoch 11 Batch 700 Loss 0.4912 Accuracy 0.4072\n",
      "Epoch 11 Loss 0.4913 Accuracy 0.4072\n",
      "Time taken for 1 epoch: 35.24862575531006 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.4580 Accuracy 0.4001\n",
      "Epoch 12 Batch 50 Loss 0.4329 Accuracy 0.4082\n",
      "Epoch 12 Batch 100 Loss 0.4398 Accuracy 0.4091\n",
      "Epoch 12 Batch 150 Loss 0.4448 Accuracy 0.4099\n",
      "Epoch 12 Batch 200 Loss 0.4515 Accuracy 0.4087\n",
      "Epoch 12 Batch 250 Loss 0.4549 Accuracy 0.4086\n",
      "Epoch 12 Batch 300 Loss 0.4585 Accuracy 0.4080\n",
      "Epoch 12 Batch 350 Loss 0.4613 Accuracy 0.4089\n",
      "Epoch 12 Batch 400 Loss 0.4658 Accuracy 0.4087\n",
      "Epoch 12 Batch 450 Loss 0.4692 Accuracy 0.4089\n",
      "Epoch 12 Batch 500 Loss 0.4738 Accuracy 0.4085\n",
      "Epoch 12 Batch 550 Loss 0.4775 Accuracy 0.4073\n",
      "Epoch 12 Batch 600 Loss 0.4804 Accuracy 0.4074\n",
      "Epoch 12 Batch 650 Loss 0.4834 Accuracy 0.4071\n",
      "Epoch 12 Batch 700 Loss 0.4874 Accuracy 0.4070\n",
      "Epoch 12 Loss 0.4877 Accuracy 0.4069\n",
      "Time taken for 1 epoch: 35.20231604576111 secs\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.4966 Accuracy 0.3938\n",
      "Epoch 13 Batch 50 Loss 0.4302 Accuracy 0.4164\n",
      "Epoch 13 Batch 100 Loss 0.4347 Accuracy 0.4139\n",
      "Epoch 13 Batch 150 Loss 0.4425 Accuracy 0.4114\n",
      "Epoch 13 Batch 200 Loss 0.4486 Accuracy 0.4108\n",
      "Epoch 13 Batch 250 Loss 0.4510 Accuracy 0.4096\n",
      "Epoch 13 Batch 300 Loss 0.4531 Accuracy 0.4101\n",
      "Epoch 13 Batch 350 Loss 0.4563 Accuracy 0.4103\n",
      "Epoch 13 Batch 400 Loss 0.4598 Accuracy 0.4105\n",
      "Epoch 13 Batch 450 Loss 0.4629 Accuracy 0.4104\n",
      "Epoch 13 Batch 500 Loss 0.4662 Accuracy 0.4101\n",
      "Epoch 13 Batch 550 Loss 0.4704 Accuracy 0.4099\n",
      "Epoch 13 Batch 600 Loss 0.4742 Accuracy 0.4094\n",
      "Epoch 13 Batch 650 Loss 0.4775 Accuracy 0.4089\n",
      "Epoch 13 Batch 700 Loss 0.4809 Accuracy 0.4083\n",
      "Epoch 13 Loss 0.4810 Accuracy 0.4084\n",
      "Time taken for 1 epoch: 35.181479930877686 secs\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.3913 Accuracy 0.4173\n",
      "Epoch 14 Batch 50 Loss 0.4231 Accuracy 0.4164\n",
      "Epoch 14 Batch 100 Loss 0.4316 Accuracy 0.4131\n",
      "Epoch 14 Batch 150 Loss 0.4390 Accuracy 0.4110\n",
      "Epoch 14 Batch 200 Loss 0.4418 Accuracy 0.4109\n",
      "Epoch 14 Batch 250 Loss 0.4466 Accuracy 0.4118\n",
      "Epoch 14 Batch 300 Loss 0.4506 Accuracy 0.4121\n",
      "Epoch 14 Batch 350 Loss 0.4529 Accuracy 0.4120\n",
      "Epoch 14 Batch 400 Loss 0.4564 Accuracy 0.4112\n",
      "Epoch 14 Batch 450 Loss 0.4593 Accuracy 0.4109\n",
      "Epoch 14 Batch 500 Loss 0.4626 Accuracy 0.4108\n",
      "Epoch 14 Batch 550 Loss 0.4667 Accuracy 0.4105\n",
      "Epoch 14 Batch 600 Loss 0.4703 Accuracy 0.4101\n",
      "Epoch 14 Batch 650 Loss 0.4739 Accuracy 0.4098\n",
      "Epoch 14 Batch 700 Loss 0.4773 Accuracy 0.4098\n",
      "Epoch 14 Loss 0.4775 Accuracy 0.4098\n",
      "Time taken for 1 epoch: 35.21148943901062 secs\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.4142 Accuracy 0.4089\n",
      "Epoch 15 Batch 50 Loss 0.4207 Accuracy 0.4068\n",
      "Epoch 15 Batch 100 Loss 0.4268 Accuracy 0.4099\n",
      "Epoch 15 Batch 150 Loss 0.4342 Accuracy 0.4099\n",
      "Epoch 15 Batch 200 Loss 0.4387 Accuracy 0.4084\n",
      "Epoch 15 Batch 250 Loss 0.4415 Accuracy 0.4096\n",
      "Epoch 15 Batch 300 Loss 0.4453 Accuracy 0.4094\n",
      "Epoch 15 Batch 350 Loss 0.4483 Accuracy 0.4102\n",
      "Epoch 15 Batch 400 Loss 0.4525 Accuracy 0.4100\n",
      "Epoch 15 Batch 450 Loss 0.4559 Accuracy 0.4100\n",
      "Epoch 15 Batch 500 Loss 0.4598 Accuracy 0.4102\n",
      "Epoch 15 Batch 550 Loss 0.4637 Accuracy 0.4103\n",
      "Epoch 15 Batch 600 Loss 0.4669 Accuracy 0.4097\n",
      "Epoch 15 Batch 650 Loss 0.4703 Accuracy 0.4094\n",
      "Epoch 15 Batch 700 Loss 0.4746 Accuracy 0.4088\n",
      "Saving checkpoint for epoch 15 at ./checkpoints/train/ckpt-15\n",
      "Epoch 15 Loss 0.4747 Accuracy 0.4088\n",
      "Time taken for 1 epoch: 35.4024863243103 secs\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.4534 Accuracy 0.4278\n",
      "Epoch 16 Batch 50 Loss 0.4207 Accuracy 0.4124\n",
      "Epoch 16 Batch 100 Loss 0.4262 Accuracy 0.4151\n",
      "Epoch 16 Batch 150 Loss 0.4282 Accuracy 0.4132\n",
      "Epoch 16 Batch 200 Loss 0.4321 Accuracy 0.4138\n",
      "Epoch 16 Batch 250 Loss 0.4372 Accuracy 0.4132\n",
      "Epoch 16 Batch 300 Loss 0.4413 Accuracy 0.4122\n",
      "Epoch 16 Batch 350 Loss 0.4453 Accuracy 0.4103\n",
      "Epoch 16 Batch 400 Loss 0.4490 Accuracy 0.4100\n",
      "Epoch 16 Batch 450 Loss 0.4525 Accuracy 0.4106\n",
      "Epoch 16 Batch 500 Loss 0.4547 Accuracy 0.4107\n",
      "Epoch 16 Batch 550 Loss 0.4589 Accuracy 0.4104\n",
      "Epoch 16 Batch 600 Loss 0.4626 Accuracy 0.4101\n",
      "Epoch 16 Batch 650 Loss 0.4659 Accuracy 0.4096\n",
      "Epoch 16 Batch 700 Loss 0.4694 Accuracy 0.4095\n",
      "Epoch 16 Loss 0.4696 Accuracy 0.4095\n",
      "Time taken for 1 epoch: 35.187063694000244 secs\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.4055 Accuracy 0.4079\n",
      "Epoch 17 Batch 50 Loss 0.4172 Accuracy 0.4112\n",
      "Epoch 17 Batch 100 Loss 0.4161 Accuracy 0.4117\n",
      "Epoch 17 Batch 150 Loss 0.4199 Accuracy 0.4123\n",
      "Epoch 17 Batch 200 Loss 0.4267 Accuracy 0.4137\n",
      "Epoch 17 Batch 250 Loss 0.4312 Accuracy 0.4137\n",
      "Epoch 17 Batch 300 Loss 0.4351 Accuracy 0.4143\n",
      "Epoch 17 Batch 350 Loss 0.4389 Accuracy 0.4137\n",
      "Epoch 17 Batch 400 Loss 0.4426 Accuracy 0.4130\n",
      "Epoch 17 Batch 450 Loss 0.4469 Accuracy 0.4128\n",
      "Epoch 17 Batch 500 Loss 0.4498 Accuracy 0.4123\n",
      "Epoch 17 Batch 550 Loss 0.4539 Accuracy 0.4113\n",
      "Epoch 17 Batch 600 Loss 0.4581 Accuracy 0.4107\n",
      "Epoch 17 Batch 650 Loss 0.4613 Accuracy 0.4108\n",
      "Epoch 17 Batch 700 Loss 0.4645 Accuracy 0.4101\n",
      "Epoch 17 Loss 0.4646 Accuracy 0.4101\n",
      "Time taken for 1 epoch: 35.195899963378906 secs\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.4083 Accuracy 0.3935\n",
      "Epoch 18 Batch 50 Loss 0.4082 Accuracy 0.4171\n",
      "Epoch 18 Batch 100 Loss 0.4162 Accuracy 0.4164\n",
      "Epoch 18 Batch 150 Loss 0.4239 Accuracy 0.4136\n",
      "Epoch 18 Batch 200 Loss 0.4284 Accuracy 0.4128\n",
      "Epoch 18 Batch 250 Loss 0.4308 Accuracy 0.4121\n",
      "Epoch 18 Batch 300 Loss 0.4355 Accuracy 0.4119\n",
      "Epoch 18 Batch 350 Loss 0.4393 Accuracy 0.4108\n",
      "Epoch 18 Batch 400 Loss 0.4432 Accuracy 0.4114\n",
      "Epoch 18 Batch 450 Loss 0.4460 Accuracy 0.4121\n",
      "Epoch 18 Batch 500 Loss 0.4495 Accuracy 0.4119\n",
      "Epoch 18 Batch 550 Loss 0.4522 Accuracy 0.4117\n",
      "Epoch 18 Batch 600 Loss 0.4559 Accuracy 0.4111\n",
      "Epoch 18 Batch 650 Loss 0.4584 Accuracy 0.4109\n",
      "Epoch 18 Batch 700 Loss 0.4617 Accuracy 0.4102\n",
      "Epoch 18 Loss 0.4618 Accuracy 0.4102\n",
      "Time taken for 1 epoch: 35.188833475112915 secs\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.3959 Accuracy 0.4038\n",
      "Epoch 19 Batch 50 Loss 0.4018 Accuracy 0.4151\n",
      "Epoch 19 Batch 100 Loss 0.4068 Accuracy 0.4117\n",
      "Epoch 19 Batch 150 Loss 0.4135 Accuracy 0.4133\n",
      "Epoch 19 Batch 200 Loss 0.4198 Accuracy 0.4129\n",
      "Epoch 19 Batch 250 Loss 0.4225 Accuracy 0.4134\n",
      "Epoch 19 Batch 300 Loss 0.4273 Accuracy 0.4135\n",
      "Epoch 19 Batch 350 Loss 0.4317 Accuracy 0.4130\n",
      "Epoch 19 Batch 400 Loss 0.4349 Accuracy 0.4129\n",
      "Epoch 19 Batch 450 Loss 0.4391 Accuracy 0.4125\n",
      "Epoch 19 Batch 500 Loss 0.4409 Accuracy 0.4122\n",
      "Epoch 19 Batch 550 Loss 0.4446 Accuracy 0.4120\n",
      "Epoch 19 Batch 600 Loss 0.4483 Accuracy 0.4118\n",
      "Epoch 19 Batch 650 Loss 0.4527 Accuracy 0.4115\n",
      "Epoch 19 Batch 700 Loss 0.4566 Accuracy 0.4111\n",
      "Epoch 19 Loss 0.4567 Accuracy 0.4110\n",
      "Time taken for 1 epoch: 35.19674468040466 secs\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.3773 Accuracy 0.3970\n",
      "Epoch 20 Batch 50 Loss 0.4061 Accuracy 0.4162\n",
      "Epoch 20 Batch 100 Loss 0.4074 Accuracy 0.4140\n",
      "Epoch 20 Batch 150 Loss 0.4134 Accuracy 0.4133\n",
      "Epoch 20 Batch 200 Loss 0.4161 Accuracy 0.4144\n",
      "Epoch 20 Batch 250 Loss 0.4207 Accuracy 0.4144\n",
      "Epoch 20 Batch 300 Loss 0.4268 Accuracy 0.4133\n",
      "Epoch 20 Batch 350 Loss 0.4301 Accuracy 0.4136\n",
      "Epoch 20 Batch 400 Loss 0.4325 Accuracy 0.4134\n",
      "Epoch 20 Batch 450 Loss 0.4354 Accuracy 0.4129\n",
      "Epoch 20 Batch 500 Loss 0.4387 Accuracy 0.4125\n",
      "Epoch 20 Batch 550 Loss 0.4418 Accuracy 0.4126\n",
      "Epoch 20 Batch 600 Loss 0.4446 Accuracy 0.4119\n",
      "Epoch 20 Batch 650 Loss 0.4481 Accuracy 0.4119\n",
      "Epoch 20 Batch 700 Loss 0.4517 Accuracy 0.4120\n",
      "Saving checkpoint for epoch 20 at ./checkpoints/train/ckpt-16\n",
      "Epoch 20 Loss 0.4519 Accuracy 0.4120\n",
      "Time taken for 1 epoch: 35.34379029273987 secs\n",
      "\n",
      "Epoch 21 Batch 0 Loss 0.3637 Accuracy 0.3932\n",
      "Epoch 21 Batch 50 Loss 0.3924 Accuracy 0.4200\n",
      "Epoch 21 Batch 100 Loss 0.3987 Accuracy 0.4190\n",
      "Epoch 21 Batch 150 Loss 0.4070 Accuracy 0.4171\n",
      "Epoch 21 Batch 200 Loss 0.4120 Accuracy 0.4162\n",
      "Epoch 21 Batch 250 Loss 0.4172 Accuracy 0.4157\n",
      "Epoch 21 Batch 300 Loss 0.4221 Accuracy 0.4161\n",
      "Epoch 21 Batch 350 Loss 0.4257 Accuracy 0.4153\n",
      "Epoch 21 Batch 400 Loss 0.4276 Accuracy 0.4158\n",
      "Epoch 21 Batch 450 Loss 0.4311 Accuracy 0.4150\n",
      "Epoch 21 Batch 500 Loss 0.4348 Accuracy 0.4149\n",
      "Epoch 21 Batch 550 Loss 0.4386 Accuracy 0.4138\n",
      "Epoch 21 Batch 600 Loss 0.4425 Accuracy 0.4135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Batch 650 Loss 0.4448 Accuracy 0.4135\n",
      "Epoch 21 Batch 700 Loss 0.4488 Accuracy 0.4131\n",
      "Epoch 21 Loss 0.4489 Accuracy 0.4132\n",
      "Time taken for 1 epoch: 35.172932624816895 secs\n",
      "\n",
      "Epoch 22 Batch 0 Loss 0.4073 Accuracy 0.4844\n",
      "Epoch 22 Batch 50 Loss 0.4019 Accuracy 0.4183\n",
      "Epoch 22 Batch 100 Loss 0.4012 Accuracy 0.4157\n",
      "Epoch 22 Batch 150 Loss 0.4061 Accuracy 0.4135\n",
      "Epoch 22 Batch 200 Loss 0.4107 Accuracy 0.4143\n",
      "Epoch 22 Batch 250 Loss 0.4161 Accuracy 0.4140\n",
      "Epoch 22 Batch 300 Loss 0.4201 Accuracy 0.4144\n",
      "Epoch 22 Batch 350 Loss 0.4239 Accuracy 0.4148\n",
      "Epoch 22 Batch 400 Loss 0.4266 Accuracy 0.4146\n",
      "Epoch 22 Batch 450 Loss 0.4294 Accuracy 0.4139\n",
      "Epoch 22 Batch 500 Loss 0.4333 Accuracy 0.4135\n",
      "Epoch 22 Batch 550 Loss 0.4365 Accuracy 0.4136\n",
      "Epoch 22 Batch 600 Loss 0.4400 Accuracy 0.4133\n",
      "Epoch 22 Batch 650 Loss 0.4432 Accuracy 0.4127\n",
      "Epoch 22 Batch 700 Loss 0.4462 Accuracy 0.4125\n",
      "Epoch 22 Loss 0.4463 Accuracy 0.4126\n",
      "Time taken for 1 epoch: 35.201555252075195 secs\n",
      "\n",
      "Epoch 23 Batch 0 Loss 0.4033 Accuracy 0.4017\n",
      "Epoch 23 Batch 50 Loss 0.3967 Accuracy 0.4171\n",
      "Epoch 23 Batch 100 Loss 0.3976 Accuracy 0.4160\n",
      "Epoch 23 Batch 150 Loss 0.4015 Accuracy 0.4163\n",
      "Epoch 23 Batch 200 Loss 0.4065 Accuracy 0.4171\n",
      "Epoch 23 Batch 250 Loss 0.4097 Accuracy 0.4179\n",
      "Epoch 23 Batch 300 Loss 0.4138 Accuracy 0.4169\n",
      "Epoch 23 Batch 350 Loss 0.4174 Accuracy 0.4164\n",
      "Epoch 23 Batch 400 Loss 0.4215 Accuracy 0.4161\n",
      "Epoch 23 Batch 450 Loss 0.4250 Accuracy 0.4152\n",
      "Epoch 23 Batch 500 Loss 0.4285 Accuracy 0.4150\n",
      "Epoch 23 Batch 550 Loss 0.4317 Accuracy 0.4147\n",
      "Epoch 23 Batch 600 Loss 0.4348 Accuracy 0.4142\n",
      "Epoch 23 Batch 650 Loss 0.4375 Accuracy 0.4138\n",
      "Epoch 23 Batch 700 Loss 0.4407 Accuracy 0.4135\n",
      "Epoch 23 Loss 0.4407 Accuracy 0.4134\n",
      "Time taken for 1 epoch: 35.21281623840332 secs\n",
      "\n",
      "Epoch 24 Batch 0 Loss 0.3922 Accuracy 0.4304\n",
      "Epoch 24 Batch 50 Loss 0.3921 Accuracy 0.4213\n",
      "Epoch 24 Batch 100 Loss 0.3962 Accuracy 0.4208\n",
      "Epoch 24 Batch 150 Loss 0.3996 Accuracy 0.4188\n",
      "Epoch 24 Batch 200 Loss 0.4037 Accuracy 0.4182\n",
      "Epoch 24 Batch 250 Loss 0.4070 Accuracy 0.4172\n",
      "Epoch 24 Batch 300 Loss 0.4109 Accuracy 0.4158\n",
      "Epoch 24 Batch 350 Loss 0.4153 Accuracy 0.4159\n",
      "Epoch 24 Batch 400 Loss 0.4186 Accuracy 0.4153\n",
      "Epoch 24 Batch 450 Loss 0.4218 Accuracy 0.4156\n",
      "Epoch 24 Batch 500 Loss 0.4243 Accuracy 0.4155\n",
      "Epoch 24 Batch 550 Loss 0.4276 Accuracy 0.4145\n",
      "Epoch 24 Batch 600 Loss 0.4305 Accuracy 0.4140\n",
      "Epoch 24 Batch 650 Loss 0.4337 Accuracy 0.4142\n",
      "Epoch 24 Batch 700 Loss 0.4375 Accuracy 0.4141\n",
      "Epoch 24 Loss 0.4377 Accuracy 0.4142\n",
      "Time taken for 1 epoch: 35.17109417915344 secs\n",
      "\n",
      "Epoch 25 Batch 0 Loss 0.3369 Accuracy 0.3874\n",
      "Epoch 25 Batch 50 Loss 0.3904 Accuracy 0.4149\n",
      "Epoch 25 Batch 100 Loss 0.3935 Accuracy 0.4151\n",
      "Epoch 25 Batch 150 Loss 0.3974 Accuracy 0.4149\n",
      "Epoch 25 Batch 200 Loss 0.4035 Accuracy 0.4158\n",
      "Epoch 25 Batch 250 Loss 0.4068 Accuracy 0.4160\n",
      "Epoch 25 Batch 300 Loss 0.4102 Accuracy 0.4161\n",
      "Epoch 25 Batch 350 Loss 0.4124 Accuracy 0.4162\n",
      "Epoch 25 Batch 400 Loss 0.4155 Accuracy 0.4163\n",
      "Epoch 25 Batch 450 Loss 0.4182 Accuracy 0.4161\n",
      "Epoch 25 Batch 500 Loss 0.4227 Accuracy 0.4159\n",
      "Epoch 25 Batch 550 Loss 0.4255 Accuracy 0.4154\n",
      "Epoch 25 Batch 600 Loss 0.4284 Accuracy 0.4152\n",
      "Epoch 25 Batch 650 Loss 0.4325 Accuracy 0.4150\n",
      "Epoch 25 Batch 700 Loss 0.4361 Accuracy 0.4145\n",
      "Saving checkpoint for epoch 25 at ./checkpoints/train/ckpt-17\n",
      "Epoch 25 Loss 0.4362 Accuracy 0.4145\n",
      "Time taken for 1 epoch: 35.328924894332886 secs\n",
      "\n",
      "Epoch 26 Batch 0 Loss 0.3718 Accuracy 0.4679\n",
      "Epoch 26 Batch 50 Loss 0.3822 Accuracy 0.4208\n",
      "Epoch 26 Batch 100 Loss 0.3827 Accuracy 0.4207\n",
      "Epoch 26 Batch 150 Loss 0.3877 Accuracy 0.4195\n",
      "Epoch 26 Batch 200 Loss 0.3936 Accuracy 0.4183\n",
      "Epoch 26 Batch 250 Loss 0.3976 Accuracy 0.4169\n",
      "Epoch 26 Batch 300 Loss 0.4028 Accuracy 0.4166\n",
      "Epoch 26 Batch 350 Loss 0.4075 Accuracy 0.4170\n",
      "Epoch 26 Batch 400 Loss 0.4101 Accuracy 0.4170\n",
      "Epoch 26 Batch 450 Loss 0.4141 Accuracy 0.4169\n",
      "Epoch 26 Batch 500 Loss 0.4171 Accuracy 0.4167\n",
      "Epoch 26 Batch 550 Loss 0.4211 Accuracy 0.4162\n",
      "Epoch 26 Batch 600 Loss 0.4245 Accuracy 0.4155\n",
      "Epoch 26 Batch 650 Loss 0.4273 Accuracy 0.4150\n",
      "Epoch 26 Batch 700 Loss 0.4298 Accuracy 0.4147\n",
      "Epoch 26 Loss 0.4299 Accuracy 0.4147\n",
      "Time taken for 1 epoch: 35.25423455238342 secs\n",
      "\n",
      "Epoch 27 Batch 0 Loss 0.3770 Accuracy 0.3902\n",
      "Epoch 27 Batch 50 Loss 0.3771 Accuracy 0.4200\n",
      "Epoch 27 Batch 100 Loss 0.3825 Accuracy 0.4196\n",
      "Epoch 27 Batch 150 Loss 0.3872 Accuracy 0.4186\n",
      "Epoch 27 Batch 200 Loss 0.3908 Accuracy 0.4187\n",
      "Epoch 27 Batch 250 Loss 0.3954 Accuracy 0.4180\n",
      "Epoch 27 Batch 300 Loss 0.4009 Accuracy 0.4181\n",
      "Epoch 27 Batch 350 Loss 0.4043 Accuracy 0.4173\n",
      "Epoch 27 Batch 400 Loss 0.4078 Accuracy 0.4172\n",
      "Epoch 27 Batch 450 Loss 0.4110 Accuracy 0.4171\n",
      "Epoch 27 Batch 500 Loss 0.4142 Accuracy 0.4168\n",
      "Epoch 27 Batch 550 Loss 0.4180 Accuracy 0.4162\n",
      "Epoch 27 Batch 600 Loss 0.4212 Accuracy 0.4157\n",
      "Epoch 27 Batch 650 Loss 0.4244 Accuracy 0.4154\n",
      "Epoch 27 Batch 700 Loss 0.4274 Accuracy 0.4154\n",
      "Epoch 27 Loss 0.4275 Accuracy 0.4154\n",
      "Time taken for 1 epoch: 34.657716035842896 secs\n",
      "\n",
      "Epoch 28 Batch 0 Loss 0.3723 Accuracy 0.4494\n",
      "Epoch 28 Batch 50 Loss 0.3782 Accuracy 0.4199\n",
      "Epoch 28 Batch 100 Loss 0.3835 Accuracy 0.4148\n",
      "Epoch 28 Batch 150 Loss 0.3897 Accuracy 0.4138\n",
      "Epoch 28 Batch 200 Loss 0.3917 Accuracy 0.4144\n",
      "Epoch 28 Batch 250 Loss 0.3956 Accuracy 0.4156\n",
      "Epoch 28 Batch 300 Loss 0.3981 Accuracy 0.4152\n",
      "Epoch 28 Batch 350 Loss 0.4016 Accuracy 0.4152\n",
      "Epoch 28 Batch 400 Loss 0.4050 Accuracy 0.4157\n",
      "Epoch 28 Batch 450 Loss 0.4087 Accuracy 0.4152\n",
      "Epoch 28 Batch 500 Loss 0.4124 Accuracy 0.4156\n",
      "Epoch 28 Batch 550 Loss 0.4154 Accuracy 0.4153\n",
      "Epoch 28 Batch 600 Loss 0.4185 Accuracy 0.4150\n",
      "Epoch 28 Batch 650 Loss 0.4215 Accuracy 0.4148\n",
      "Epoch 28 Batch 700 Loss 0.4247 Accuracy 0.4149\n",
      "Epoch 28 Loss 0.4248 Accuracy 0.4150\n",
      "Time taken for 1 epoch: 34.29077506065369 secs\n",
      "\n",
      "Epoch 29 Batch 0 Loss 0.3862 Accuracy 0.4067\n",
      "Epoch 29 Batch 50 Loss 0.3792 Accuracy 0.4239\n",
      "Epoch 29 Batch 100 Loss 0.3832 Accuracy 0.4200\n",
      "Epoch 29 Batch 150 Loss 0.3900 Accuracy 0.4184\n",
      "Epoch 29 Batch 200 Loss 0.3924 Accuracy 0.4185\n",
      "Epoch 29 Batch 250 Loss 0.3966 Accuracy 0.4177\n",
      "Epoch 29 Batch 300 Loss 0.3999 Accuracy 0.4172\n",
      "Epoch 29 Batch 350 Loss 0.4030 Accuracy 0.4169\n",
      "Epoch 29 Batch 400 Loss 0.4052 Accuracy 0.4166\n",
      "Epoch 29 Batch 450 Loss 0.4081 Accuracy 0.4163\n",
      "Epoch 29 Batch 500 Loss 0.4106 Accuracy 0.4159\n",
      "Epoch 29 Batch 550 Loss 0.4136 Accuracy 0.4159\n",
      "Epoch 29 Batch 600 Loss 0.4166 Accuracy 0.4155\n",
      "Epoch 29 Batch 650 Loss 0.4202 Accuracy 0.4154\n",
      "Epoch 29 Batch 700 Loss 0.4234 Accuracy 0.4151\n",
      "Epoch 29 Loss 0.4234 Accuracy 0.4151\n",
      "Time taken for 1 epoch: 34.35780930519104 secs\n",
      "\n",
      "Epoch 30 Batch 0 Loss 0.3669 Accuracy 0.3930\n",
      "Epoch 30 Batch 50 Loss 0.3768 Accuracy 0.4207\n",
      "Epoch 30 Batch 100 Loss 0.3775 Accuracy 0.4205\n",
      "Epoch 30 Batch 150 Loss 0.3800 Accuracy 0.4207\n",
      "Epoch 30 Batch 200 Loss 0.3845 Accuracy 0.4180\n",
      "Epoch 30 Batch 250 Loss 0.3896 Accuracy 0.4200\n",
      "Epoch 30 Batch 300 Loss 0.3942 Accuracy 0.4198\n",
      "Epoch 30 Batch 350 Loss 0.3976 Accuracy 0.4186\n",
      "Epoch 30 Batch 400 Loss 0.4003 Accuracy 0.4181\n",
      "Epoch 30 Batch 450 Loss 0.4030 Accuracy 0.4180\n",
      "Epoch 30 Batch 500 Loss 0.4057 Accuracy 0.4178\n",
      "Epoch 30 Batch 550 Loss 0.4093 Accuracy 0.4179\n",
      "Epoch 30 Batch 600 Loss 0.4133 Accuracy 0.4171\n",
      "Epoch 30 Batch 650 Loss 0.4168 Accuracy 0.4164\n",
      "Epoch 30 Batch 700 Loss 0.4195 Accuracy 0.4157\n",
      "Saving checkpoint for epoch 30 at ./checkpoints/train/ckpt-18\n",
      "Epoch 30 Loss 0.4196 Accuracy 0.4158\n",
      "Time taken for 1 epoch: 34.49616241455078 secs\n",
      "\n",
      "Epoch 31 Batch 0 Loss 0.3919 Accuracy 0.3894\n",
      "Epoch 31 Batch 50 Loss 0.3727 Accuracy 0.4219\n",
      "Epoch 31 Batch 100 Loss 0.3761 Accuracy 0.4234\n",
      "Epoch 31 Batch 150 Loss 0.3797 Accuracy 0.4220\n",
      "Epoch 31 Batch 200 Loss 0.3822 Accuracy 0.4218\n",
      "Epoch 31 Batch 250 Loss 0.3863 Accuracy 0.4206\n",
      "Epoch 31 Batch 300 Loss 0.3881 Accuracy 0.4204\n",
      "Epoch 31 Batch 350 Loss 0.3930 Accuracy 0.4195\n",
      "Epoch 31 Batch 400 Loss 0.3966 Accuracy 0.4196\n",
      "Epoch 31 Batch 450 Loss 0.4003 Accuracy 0.4192\n",
      "Epoch 31 Batch 500 Loss 0.4032 Accuracy 0.4183\n",
      "Epoch 31 Batch 550 Loss 0.4061 Accuracy 0.4176\n",
      "Epoch 31 Batch 600 Loss 0.4086 Accuracy 0.4175\n",
      "Epoch 31 Batch 650 Loss 0.4116 Accuracy 0.4178\n",
      "Epoch 31 Batch 700 Loss 0.4159 Accuracy 0.4173\n",
      "Epoch 31 Loss 0.4161 Accuracy 0.4173\n",
      "Time taken for 1 epoch: 35.10319423675537 secs\n",
      "\n",
      "Epoch 32 Batch 0 Loss 0.4012 Accuracy 0.3950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Batch 50 Loss 0.3617 Accuracy 0.4197\n",
      "Epoch 32 Batch 100 Loss 0.3657 Accuracy 0.4166\n",
      "Epoch 32 Batch 150 Loss 0.3706 Accuracy 0.4198\n",
      "Epoch 32 Batch 200 Loss 0.3762 Accuracy 0.4189\n",
      "Epoch 32 Batch 250 Loss 0.3819 Accuracy 0.4201\n",
      "Epoch 32 Batch 300 Loss 0.3850 Accuracy 0.4192\n",
      "Epoch 32 Batch 350 Loss 0.3889 Accuracy 0.4187\n",
      "Epoch 32 Batch 400 Loss 0.3941 Accuracy 0.4178\n",
      "Epoch 32 Batch 450 Loss 0.3979 Accuracy 0.4177\n",
      "Epoch 32 Batch 500 Loss 0.4007 Accuracy 0.4174\n",
      "Epoch 32 Batch 550 Loss 0.4036 Accuracy 0.4173\n",
      "Epoch 32 Batch 600 Loss 0.4069 Accuracy 0.4172\n",
      "Epoch 32 Batch 650 Loss 0.4099 Accuracy 0.4166\n",
      "Epoch 32 Batch 700 Loss 0.4128 Accuracy 0.4164\n",
      "Epoch 32 Loss 0.4129 Accuracy 0.4163\n",
      "Time taken for 1 epoch: 35.376795053482056 secs\n",
      "\n",
      "Epoch 33 Batch 0 Loss 0.3350 Accuracy 0.4469\n",
      "Epoch 33 Batch 50 Loss 0.3650 Accuracy 0.4270\n",
      "Epoch 33 Batch 100 Loss 0.3690 Accuracy 0.4222\n",
      "Epoch 33 Batch 150 Loss 0.3752 Accuracy 0.4216\n",
      "Epoch 33 Batch 200 Loss 0.3771 Accuracy 0.4208\n",
      "Epoch 33 Batch 250 Loss 0.3811 Accuracy 0.4191\n",
      "Epoch 33 Batch 300 Loss 0.3855 Accuracy 0.4182\n",
      "Epoch 33 Batch 350 Loss 0.3886 Accuracy 0.4186\n",
      "Epoch 33 Batch 400 Loss 0.3917 Accuracy 0.4191\n",
      "Epoch 33 Batch 450 Loss 0.3940 Accuracy 0.4188\n",
      "Epoch 33 Batch 500 Loss 0.3970 Accuracy 0.4183\n",
      "Epoch 33 Batch 550 Loss 0.4002 Accuracy 0.4178\n",
      "Epoch 33 Batch 600 Loss 0.4035 Accuracy 0.4172\n",
      "Epoch 33 Batch 650 Loss 0.4069 Accuracy 0.4170\n",
      "Epoch 33 Batch 700 Loss 0.4101 Accuracy 0.4169\n",
      "Epoch 33 Loss 0.4102 Accuracy 0.4169\n",
      "Time taken for 1 epoch: 35.21777844429016 secs\n",
      "\n",
      "Epoch 34 Batch 0 Loss 0.3896 Accuracy 0.4177\n",
      "Epoch 34 Batch 50 Loss 0.3572 Accuracy 0.4226\n",
      "Epoch 34 Batch 100 Loss 0.3624 Accuracy 0.4223\n",
      "Epoch 34 Batch 150 Loss 0.3693 Accuracy 0.4217\n",
      "Epoch 34 Batch 200 Loss 0.3733 Accuracy 0.4195\n",
      "Epoch 34 Batch 250 Loss 0.3780 Accuracy 0.4174\n",
      "Epoch 34 Batch 300 Loss 0.3813 Accuracy 0.4181\n",
      "Epoch 34 Batch 350 Loss 0.3853 Accuracy 0.4181\n",
      "Epoch 34 Batch 400 Loss 0.3870 Accuracy 0.4183\n",
      "Epoch 34 Batch 450 Loss 0.3909 Accuracy 0.4185\n",
      "Epoch 34 Batch 500 Loss 0.3942 Accuracy 0.4185\n",
      "Epoch 34 Batch 550 Loss 0.3983 Accuracy 0.4185\n",
      "Epoch 34 Batch 600 Loss 0.4014 Accuracy 0.4182\n",
      "Epoch 34 Batch 650 Loss 0.4047 Accuracy 0.4172\n",
      "Epoch 34 Batch 700 Loss 0.4077 Accuracy 0.4171\n",
      "Epoch 34 Loss 0.4079 Accuracy 0.4172\n",
      "Time taken for 1 epoch: 35.17141628265381 secs\n",
      "\n",
      "Epoch 35 Batch 0 Loss 0.3199 Accuracy 0.4318\n",
      "Epoch 35 Batch 50 Loss 0.3542 Accuracy 0.4266\n",
      "Epoch 35 Batch 100 Loss 0.3617 Accuracy 0.4244\n",
      "Epoch 35 Batch 150 Loss 0.3657 Accuracy 0.4225\n",
      "Epoch 35 Batch 200 Loss 0.3696 Accuracy 0.4213\n",
      "Epoch 35 Batch 250 Loss 0.3736 Accuracy 0.4208\n",
      "Epoch 35 Batch 300 Loss 0.3781 Accuracy 0.4190\n",
      "Epoch 35 Batch 350 Loss 0.3812 Accuracy 0.4184\n",
      "Epoch 35 Batch 400 Loss 0.3845 Accuracy 0.4193\n",
      "Epoch 35 Batch 450 Loss 0.3877 Accuracy 0.4194\n",
      "Epoch 35 Batch 500 Loss 0.3911 Accuracy 0.4186\n",
      "Epoch 35 Batch 550 Loss 0.3940 Accuracy 0.4184\n",
      "Epoch 35 Batch 600 Loss 0.3974 Accuracy 0.4179\n",
      "Epoch 35 Batch 650 Loss 0.4008 Accuracy 0.4176\n",
      "Epoch 35 Batch 700 Loss 0.4031 Accuracy 0.4171\n",
      "Saving checkpoint for epoch 35 at ./checkpoints/train/ckpt-19\n",
      "Epoch 35 Loss 0.4031 Accuracy 0.4171\n",
      "Time taken for 1 epoch: 35.35296416282654 secs\n",
      "\n",
      "Epoch 36 Batch 0 Loss 0.3373 Accuracy 0.4067\n",
      "Epoch 36 Batch 50 Loss 0.3474 Accuracy 0.4180\n",
      "Epoch 36 Batch 100 Loss 0.3564 Accuracy 0.4187\n",
      "Epoch 36 Batch 150 Loss 0.3624 Accuracy 0.4191\n",
      "Epoch 36 Batch 200 Loss 0.3698 Accuracy 0.4200\n",
      "Epoch 36 Batch 250 Loss 0.3741 Accuracy 0.4189\n",
      "Epoch 36 Batch 300 Loss 0.3770 Accuracy 0.4188\n",
      "Epoch 36 Batch 350 Loss 0.3799 Accuracy 0.4190\n",
      "Epoch 36 Batch 400 Loss 0.3827 Accuracy 0.4186\n",
      "Epoch 36 Batch 450 Loss 0.3874 Accuracy 0.4194\n",
      "Epoch 36 Batch 500 Loss 0.3895 Accuracy 0.4191\n",
      "Epoch 36 Batch 550 Loss 0.3919 Accuracy 0.4188\n",
      "Epoch 36 Batch 600 Loss 0.3954 Accuracy 0.4185\n",
      "Epoch 36 Batch 650 Loss 0.3988 Accuracy 0.4181\n",
      "Epoch 36 Batch 700 Loss 0.4022 Accuracy 0.4182\n",
      "Epoch 36 Loss 0.4023 Accuracy 0.4183\n",
      "Time taken for 1 epoch: 35.1704216003418 secs\n",
      "\n",
      "Epoch 37 Batch 0 Loss 0.3942 Accuracy 0.4324\n",
      "Epoch 37 Batch 50 Loss 0.3620 Accuracy 0.4230\n",
      "Epoch 37 Batch 100 Loss 0.3623 Accuracy 0.4222\n",
      "Epoch 37 Batch 150 Loss 0.3660 Accuracy 0.4233\n",
      "Epoch 37 Batch 200 Loss 0.3702 Accuracy 0.4224\n",
      "Epoch 37 Batch 250 Loss 0.3732 Accuracy 0.4221\n",
      "Epoch 37 Batch 300 Loss 0.3757 Accuracy 0.4222\n",
      "Epoch 37 Batch 350 Loss 0.3778 Accuracy 0.4215\n",
      "Epoch 37 Batch 400 Loss 0.3801 Accuracy 0.4216\n",
      "Epoch 37 Batch 450 Loss 0.3832 Accuracy 0.4211\n",
      "Epoch 37 Batch 500 Loss 0.3865 Accuracy 0.4206\n",
      "Epoch 37 Batch 550 Loss 0.3900 Accuracy 0.4203\n",
      "Epoch 37 Batch 600 Loss 0.3933 Accuracy 0.4201\n",
      "Epoch 37 Batch 650 Loss 0.3956 Accuracy 0.4199\n",
      "Epoch 37 Batch 700 Loss 0.3986 Accuracy 0.4193\n",
      "Epoch 37 Loss 0.3987 Accuracy 0.4193\n",
      "Time taken for 1 epoch: 35.14895534515381 secs\n",
      "\n",
      "Epoch 38 Batch 0 Loss 0.3260 Accuracy 0.4101\n",
      "Epoch 38 Batch 50 Loss 0.3562 Accuracy 0.4255\n",
      "Epoch 38 Batch 100 Loss 0.3610 Accuracy 0.4202\n",
      "Epoch 38 Batch 150 Loss 0.3646 Accuracy 0.4196\n",
      "Epoch 38 Batch 200 Loss 0.3683 Accuracy 0.4185\n",
      "Epoch 38 Batch 250 Loss 0.3720 Accuracy 0.4178\n",
      "Epoch 38 Batch 300 Loss 0.3737 Accuracy 0.4186\n",
      "Epoch 38 Batch 350 Loss 0.3771 Accuracy 0.4193\n",
      "Epoch 38 Batch 400 Loss 0.3791 Accuracy 0.4190\n",
      "Epoch 38 Batch 450 Loss 0.3808 Accuracy 0.4194\n",
      "Epoch 38 Batch 500 Loss 0.3838 Accuracy 0.4187\n",
      "Epoch 38 Batch 550 Loss 0.3873 Accuracy 0.4187\n",
      "Epoch 38 Batch 600 Loss 0.3911 Accuracy 0.4183\n",
      "Epoch 38 Batch 650 Loss 0.3938 Accuracy 0.4181\n",
      "Epoch 38 Batch 700 Loss 0.3965 Accuracy 0.4181\n",
      "Epoch 38 Loss 0.3967 Accuracy 0.4182\n",
      "Time taken for 1 epoch: 35.18145179748535 secs\n",
      "\n",
      "Epoch 39 Batch 0 Loss 0.3281 Accuracy 0.4189\n",
      "Epoch 39 Batch 50 Loss 0.3508 Accuracy 0.4262\n",
      "Epoch 39 Batch 100 Loss 0.3532 Accuracy 0.4263\n",
      "Epoch 39 Batch 150 Loss 0.3564 Accuracy 0.4219\n",
      "Epoch 39 Batch 200 Loss 0.3620 Accuracy 0.4217\n",
      "Epoch 39 Batch 250 Loss 0.3659 Accuracy 0.4201\n",
      "Epoch 39 Batch 300 Loss 0.3698 Accuracy 0.4206\n",
      "Epoch 39 Batch 350 Loss 0.3735 Accuracy 0.4192\n",
      "Epoch 39 Batch 400 Loss 0.3769 Accuracy 0.4201\n",
      "Epoch 39 Batch 450 Loss 0.3795 Accuracy 0.4196\n",
      "Epoch 39 Batch 500 Loss 0.3834 Accuracy 0.4192\n",
      "Epoch 39 Batch 550 Loss 0.3863 Accuracy 0.4192\n",
      "Epoch 39 Batch 600 Loss 0.3888 Accuracy 0.4191\n",
      "Epoch 39 Batch 650 Loss 0.3916 Accuracy 0.4190\n",
      "Epoch 39 Batch 700 Loss 0.3944 Accuracy 0.4186\n",
      "Epoch 39 Loss 0.3945 Accuracy 0.4187\n",
      "Time taken for 1 epoch: 36.42328763008118 secs\n",
      "\n",
      "Epoch 40 Batch 0 Loss 0.3122 Accuracy 0.4161\n",
      "Epoch 40 Batch 50 Loss 0.3436 Accuracy 0.4181\n",
      "Epoch 40 Batch 100 Loss 0.3469 Accuracy 0.4198\n",
      "Epoch 40 Batch 150 Loss 0.3522 Accuracy 0.4192\n",
      "Epoch 40 Batch 200 Loss 0.3578 Accuracy 0.4202\n",
      "Epoch 40 Batch 250 Loss 0.3624 Accuracy 0.4212\n",
      "Epoch 40 Batch 300 Loss 0.3650 Accuracy 0.4216\n",
      "Epoch 40 Batch 350 Loss 0.3679 Accuracy 0.4223\n",
      "Epoch 40 Batch 400 Loss 0.3711 Accuracy 0.4225\n",
      "Epoch 40 Batch 450 Loss 0.3743 Accuracy 0.4224\n",
      "Epoch 40 Batch 500 Loss 0.3776 Accuracy 0.4216\n",
      "Epoch 40 Batch 550 Loss 0.3807 Accuracy 0.4209\n",
      "Epoch 40 Batch 600 Loss 0.3838 Accuracy 0.4205\n",
      "Epoch 40 Batch 650 Loss 0.3871 Accuracy 0.4200\n",
      "Epoch 40 Batch 700 Loss 0.3903 Accuracy 0.4195\n",
      "Saving checkpoint for epoch 40 at ./checkpoints/train/ckpt-20\n",
      "Epoch 40 Loss 0.3905 Accuracy 0.4194\n",
      "Time taken for 1 epoch: 36.76204991340637 secs\n",
      "\n",
      "Epoch 41 Batch 0 Loss 0.3668 Accuracy 0.3968\n",
      "Epoch 41 Batch 50 Loss 0.3525 Accuracy 0.4214\n",
      "Epoch 41 Batch 100 Loss 0.3514 Accuracy 0.4233\n",
      "Epoch 41 Batch 150 Loss 0.3555 Accuracy 0.4216\n",
      "Epoch 41 Batch 200 Loss 0.3608 Accuracy 0.4225\n",
      "Epoch 41 Batch 250 Loss 0.3622 Accuracy 0.4221\n",
      "Epoch 41 Batch 300 Loss 0.3651 Accuracy 0.4218\n",
      "Epoch 41 Batch 350 Loss 0.3679 Accuracy 0.4207\n",
      "Epoch 41 Batch 400 Loss 0.3701 Accuracy 0.4216\n",
      "Epoch 41 Batch 450 Loss 0.3721 Accuracy 0.4216\n",
      "Epoch 41 Batch 500 Loss 0.3760 Accuracy 0.4211\n",
      "Epoch 41 Batch 550 Loss 0.3789 Accuracy 0.4206\n",
      "Epoch 41 Batch 600 Loss 0.3822 Accuracy 0.4201\n",
      "Epoch 41 Batch 650 Loss 0.3861 Accuracy 0.4202\n",
      "Epoch 41 Batch 700 Loss 0.3886 Accuracy 0.4197\n",
      "Epoch 41 Loss 0.3890 Accuracy 0.4197\n",
      "Time taken for 1 epoch: 36.32195067405701 secs\n",
      "\n",
      "Epoch 42 Batch 0 Loss 0.3178 Accuracy 0.3730\n",
      "Epoch 42 Batch 50 Loss 0.3417 Accuracy 0.4217\n",
      "Epoch 42 Batch 100 Loss 0.3453 Accuracy 0.4233\n",
      "Epoch 42 Batch 150 Loss 0.3478 Accuracy 0.4231\n",
      "Epoch 42 Batch 200 Loss 0.3516 Accuracy 0.4228\n",
      "Epoch 42 Batch 250 Loss 0.3573 Accuracy 0.4216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Batch 300 Loss 0.3605 Accuracy 0.4224\n",
      "Epoch 42 Batch 350 Loss 0.3629 Accuracy 0.4228\n",
      "Epoch 42 Batch 400 Loss 0.3659 Accuracy 0.4232\n",
      "Epoch 42 Batch 450 Loss 0.3693 Accuracy 0.4229\n",
      "Epoch 42 Batch 500 Loss 0.3727 Accuracy 0.4220\n",
      "Epoch 42 Batch 550 Loss 0.3757 Accuracy 0.4217\n",
      "Epoch 42 Batch 600 Loss 0.3785 Accuracy 0.4210\n",
      "Epoch 42 Batch 650 Loss 0.3814 Accuracy 0.4207\n",
      "Epoch 42 Batch 700 Loss 0.3841 Accuracy 0.4203\n",
      "Epoch 42 Loss 0.3841 Accuracy 0.4203\n",
      "Time taken for 1 epoch: 36.78624367713928 secs\n",
      "\n",
      "Epoch 43 Batch 0 Loss 0.2940 Accuracy 0.4652\n",
      "Epoch 43 Batch 50 Loss 0.3421 Accuracy 0.4297\n",
      "Epoch 43 Batch 100 Loss 0.3465 Accuracy 0.4247\n",
      "Epoch 43 Batch 150 Loss 0.3496 Accuracy 0.4240\n",
      "Epoch 43 Batch 200 Loss 0.3517 Accuracy 0.4247\n",
      "Epoch 43 Batch 250 Loss 0.3556 Accuracy 0.4244\n",
      "Epoch 43 Batch 300 Loss 0.3593 Accuracy 0.4233\n",
      "Epoch 43 Batch 350 Loss 0.3625 Accuracy 0.4225\n",
      "Epoch 43 Batch 400 Loss 0.3665 Accuracy 0.4225\n",
      "Epoch 43 Batch 450 Loss 0.3683 Accuracy 0.4228\n",
      "Epoch 43 Batch 500 Loss 0.3712 Accuracy 0.4215\n",
      "Epoch 43 Batch 550 Loss 0.3739 Accuracy 0.4212\n",
      "Epoch 43 Batch 600 Loss 0.3768 Accuracy 0.4206\n",
      "Epoch 43 Batch 650 Loss 0.3805 Accuracy 0.4205\n",
      "Epoch 43 Batch 700 Loss 0.3828 Accuracy 0.4200\n",
      "Epoch 43 Loss 0.3829 Accuracy 0.4200\n",
      "Time taken for 1 epoch: 37.1504864692688 secs\n",
      "\n",
      "Epoch 44 Batch 0 Loss 0.3486 Accuracy 0.4476\n",
      "Epoch 44 Batch 50 Loss 0.3417 Accuracy 0.4249\n",
      "Epoch 44 Batch 100 Loss 0.3467 Accuracy 0.4272\n",
      "Epoch 44 Batch 150 Loss 0.3487 Accuracy 0.4239\n",
      "Epoch 44 Batch 200 Loss 0.3512 Accuracy 0.4242\n",
      "Epoch 44 Batch 250 Loss 0.3559 Accuracy 0.4240\n",
      "Epoch 44 Batch 300 Loss 0.3582 Accuracy 0.4243\n",
      "Epoch 44 Batch 350 Loss 0.3599 Accuracy 0.4241\n",
      "Epoch 44 Batch 400 Loss 0.3626 Accuracy 0.4229\n",
      "Epoch 44 Batch 450 Loss 0.3665 Accuracy 0.4227\n",
      "Epoch 44 Batch 500 Loss 0.3696 Accuracy 0.4217\n",
      "Epoch 44 Batch 550 Loss 0.3723 Accuracy 0.4216\n",
      "Epoch 44 Batch 600 Loss 0.3751 Accuracy 0.4214\n",
      "Epoch 44 Batch 650 Loss 0.3787 Accuracy 0.4207\n",
      "Epoch 44 Batch 700 Loss 0.3817 Accuracy 0.4202\n",
      "Epoch 44 Loss 0.3819 Accuracy 0.4202\n",
      "Time taken for 1 epoch: 36.56122159957886 secs\n",
      "\n",
      "Epoch 45 Batch 0 Loss 0.3055 Accuracy 0.4026\n",
      "Epoch 45 Batch 50 Loss 0.3374 Accuracy 0.4185\n",
      "Epoch 45 Batch 100 Loss 0.3407 Accuracy 0.4211\n",
      "Epoch 45 Batch 150 Loss 0.3448 Accuracy 0.4235\n",
      "Epoch 45 Batch 200 Loss 0.3480 Accuracy 0.4210\n",
      "Epoch 45 Batch 250 Loss 0.3521 Accuracy 0.4208\n",
      "Epoch 45 Batch 300 Loss 0.3546 Accuracy 0.4225\n",
      "Epoch 45 Batch 350 Loss 0.3574 Accuracy 0.4227\n",
      "Epoch 45 Batch 400 Loss 0.3597 Accuracy 0.4225\n",
      "Epoch 45 Batch 450 Loss 0.3629 Accuracy 0.4226\n",
      "Epoch 45 Batch 500 Loss 0.3668 Accuracy 0.4226\n",
      "Epoch 45 Batch 550 Loss 0.3701 Accuracy 0.4219\n",
      "Epoch 45 Batch 600 Loss 0.3734 Accuracy 0.4219\n",
      "Epoch 45 Batch 650 Loss 0.3760 Accuracy 0.4220\n",
      "Epoch 45 Batch 700 Loss 0.3789 Accuracy 0.4216\n",
      "Saving checkpoint for epoch 45 at ./checkpoints/train/ckpt-21\n",
      "Epoch 45 Loss 0.3790 Accuracy 0.4217\n",
      "Time taken for 1 epoch: 36.59521794319153 secs\n",
      "\n",
      "Epoch 46 Batch 0 Loss 0.3271 Accuracy 0.3938\n",
      "Epoch 46 Batch 50 Loss 0.3337 Accuracy 0.4247\n",
      "Epoch 46 Batch 100 Loss 0.3367 Accuracy 0.4229\n",
      "Epoch 46 Batch 150 Loss 0.3409 Accuracy 0.4239\n",
      "Epoch 46 Batch 200 Loss 0.3457 Accuracy 0.4228\n",
      "Epoch 46 Batch 250 Loss 0.3492 Accuracy 0.4223\n",
      "Epoch 46 Batch 300 Loss 0.3534 Accuracy 0.4215\n",
      "Epoch 46 Batch 350 Loss 0.3561 Accuracy 0.4223\n",
      "Epoch 46 Batch 400 Loss 0.3587 Accuracy 0.4214\n",
      "Epoch 46 Batch 450 Loss 0.3615 Accuracy 0.4211\n",
      "Epoch 46 Batch 500 Loss 0.3645 Accuracy 0.4216\n",
      "Epoch 46 Batch 550 Loss 0.3678 Accuracy 0.4217\n",
      "Epoch 46 Batch 600 Loss 0.3701 Accuracy 0.4218\n",
      "Epoch 46 Batch 650 Loss 0.3730 Accuracy 0.4215\n",
      "Epoch 46 Batch 700 Loss 0.3757 Accuracy 0.4215\n",
      "Epoch 46 Loss 0.3761 Accuracy 0.4215\n",
      "Time taken for 1 epoch: 36.509318590164185 secs\n",
      "\n",
      "Epoch 47 Batch 0 Loss 0.3141 Accuracy 0.3862\n",
      "Epoch 47 Batch 50 Loss 0.3351 Accuracy 0.4188\n",
      "Epoch 47 Batch 100 Loss 0.3383 Accuracy 0.4231\n",
      "Epoch 47 Batch 150 Loss 0.3399 Accuracy 0.4235\n",
      "Epoch 47 Batch 200 Loss 0.3448 Accuracy 0.4247\n",
      "Epoch 47 Batch 250 Loss 0.3496 Accuracy 0.4240\n",
      "Epoch 47 Batch 300 Loss 0.3508 Accuracy 0.4234\n",
      "Epoch 47 Batch 350 Loss 0.3536 Accuracy 0.4227\n",
      "Epoch 47 Batch 400 Loss 0.3568 Accuracy 0.4220\n",
      "Epoch 47 Batch 450 Loss 0.3602 Accuracy 0.4220\n",
      "Epoch 47 Batch 500 Loss 0.3627 Accuracy 0.4221\n",
      "Epoch 47 Batch 550 Loss 0.3660 Accuracy 0.4213\n",
      "Epoch 47 Batch 600 Loss 0.3687 Accuracy 0.4213\n",
      "Epoch 47 Batch 650 Loss 0.3714 Accuracy 0.4216\n",
      "Epoch 47 Batch 700 Loss 0.3744 Accuracy 0.4210\n",
      "Epoch 47 Loss 0.3744 Accuracy 0.4210\n",
      "Time taken for 1 epoch: 35.995144844055176 secs\n",
      "\n",
      "Epoch 48 Batch 0 Loss 0.3591 Accuracy 0.4278\n",
      "Epoch 48 Batch 50 Loss 0.3342 Accuracy 0.4268\n",
      "Epoch 48 Batch 100 Loss 0.3381 Accuracy 0.4273\n",
      "Epoch 48 Batch 150 Loss 0.3426 Accuracy 0.4266\n",
      "Epoch 48 Batch 200 Loss 0.3432 Accuracy 0.4264\n",
      "Epoch 48 Batch 250 Loss 0.3464 Accuracy 0.4252\n",
      "Epoch 48 Batch 300 Loss 0.3489 Accuracy 0.4249\n",
      "Epoch 48 Batch 350 Loss 0.3516 Accuracy 0.4244\n",
      "Epoch 48 Batch 400 Loss 0.3547 Accuracy 0.4244\n",
      "Epoch 48 Batch 450 Loss 0.3572 Accuracy 0.4239\n",
      "Epoch 48 Batch 500 Loss 0.3606 Accuracy 0.4234\n",
      "Epoch 48 Batch 550 Loss 0.3633 Accuracy 0.4230\n",
      "Epoch 48 Batch 600 Loss 0.3658 Accuracy 0.4226\n",
      "Epoch 48 Batch 650 Loss 0.3686 Accuracy 0.4221\n",
      "Epoch 48 Batch 700 Loss 0.3712 Accuracy 0.4218\n",
      "Epoch 48 Loss 0.3713 Accuracy 0.4218\n",
      "Time taken for 1 epoch: 35.49601483345032 secs\n",
      "\n",
      "Epoch 49 Batch 0 Loss 0.3236 Accuracy 0.4083\n",
      "Epoch 49 Batch 50 Loss 0.3286 Accuracy 0.4273\n",
      "Epoch 49 Batch 100 Loss 0.3334 Accuracy 0.4278\n",
      "Epoch 49 Batch 150 Loss 0.3360 Accuracy 0.4263\n",
      "Epoch 49 Batch 200 Loss 0.3408 Accuracy 0.4231\n",
      "Epoch 49 Batch 250 Loss 0.3446 Accuracy 0.4218\n",
      "Epoch 49 Batch 300 Loss 0.3465 Accuracy 0.4207\n",
      "Epoch 49 Batch 350 Loss 0.3505 Accuracy 0.4215\n",
      "Epoch 49 Batch 400 Loss 0.3533 Accuracy 0.4212\n",
      "Epoch 49 Batch 450 Loss 0.3560 Accuracy 0.4210\n",
      "Epoch 49 Batch 500 Loss 0.3588 Accuracy 0.4218\n",
      "Epoch 49 Batch 550 Loss 0.3611 Accuracy 0.4217\n",
      "Epoch 49 Batch 600 Loss 0.3644 Accuracy 0.4216\n",
      "Epoch 49 Batch 650 Loss 0.3674 Accuracy 0.4217\n",
      "Epoch 49 Batch 700 Loss 0.3698 Accuracy 0.4214\n",
      "Epoch 49 Loss 0.3699 Accuracy 0.4214\n",
      "Time taken for 1 epoch: 36.474539041519165 secs\n",
      "\n",
      "Epoch 50 Batch 0 Loss 0.3301 Accuracy 0.4447\n",
      "Epoch 50 Batch 50 Loss 0.3321 Accuracy 0.4212\n",
      "Epoch 50 Batch 100 Loss 0.3336 Accuracy 0.4246\n",
      "Epoch 50 Batch 150 Loss 0.3377 Accuracy 0.4263\n",
      "Epoch 50 Batch 200 Loss 0.3393 Accuracy 0.4252\n",
      "Epoch 50 Batch 250 Loss 0.3433 Accuracy 0.4250\n",
      "Epoch 50 Batch 300 Loss 0.3478 Accuracy 0.4244\n",
      "Epoch 50 Batch 350 Loss 0.3488 Accuracy 0.4252\n",
      "Epoch 50 Batch 400 Loss 0.3512 Accuracy 0.4246\n",
      "Epoch 50 Batch 450 Loss 0.3535 Accuracy 0.4243\n",
      "Epoch 50 Batch 500 Loss 0.3567 Accuracy 0.4242\n",
      "Epoch 50 Batch 550 Loss 0.3591 Accuracy 0.4239\n",
      "Epoch 50 Batch 600 Loss 0.3624 Accuracy 0.4231\n",
      "Epoch 50 Batch 650 Loss 0.3646 Accuracy 0.4230\n",
      "Epoch 50 Batch 700 Loss 0.3679 Accuracy 0.4227\n",
      "Saving checkpoint for epoch 50 at ./checkpoints/train/ckpt-22\n",
      "Epoch 50 Loss 0.3681 Accuracy 0.4227\n",
      "Time taken for 1 epoch: 36.13149452209473 secs\n",
      "\n",
      "Epoch 51 Batch 0 Loss 0.3838 Accuracy 0.4159\n",
      "Epoch 51 Batch 50 Loss 0.3291 Accuracy 0.4264\n",
      "Epoch 51 Batch 100 Loss 0.3281 Accuracy 0.4270\n",
      "Epoch 51 Batch 150 Loss 0.3327 Accuracy 0.4254\n",
      "Epoch 51 Batch 200 Loss 0.3373 Accuracy 0.4254\n",
      "Epoch 51 Batch 250 Loss 0.3398 Accuracy 0.4244\n",
      "Epoch 51 Batch 300 Loss 0.3430 Accuracy 0.4244\n",
      "Epoch 51 Batch 350 Loss 0.3453 Accuracy 0.4249\n",
      "Epoch 51 Batch 400 Loss 0.3490 Accuracy 0.4247\n",
      "Epoch 51 Batch 450 Loss 0.3518 Accuracy 0.4244\n",
      "Epoch 51 Batch 500 Loss 0.3550 Accuracy 0.4243\n",
      "Epoch 51 Batch 550 Loss 0.3583 Accuracy 0.4241\n",
      "Epoch 51 Batch 600 Loss 0.3603 Accuracy 0.4240\n",
      "Epoch 51 Batch 650 Loss 0.3632 Accuracy 0.4235\n",
      "Epoch 51 Batch 700 Loss 0.3664 Accuracy 0.4228\n",
      "Epoch 51 Loss 0.3666 Accuracy 0.4228\n",
      "Time taken for 1 epoch: 36.513636112213135 secs\n",
      "\n",
      "Epoch 52 Batch 0 Loss 0.3484 Accuracy 0.4002\n",
      "Epoch 52 Batch 50 Loss 0.3233 Accuracy 0.4234\n",
      "Epoch 52 Batch 100 Loss 0.3293 Accuracy 0.4231\n",
      "Epoch 52 Batch 150 Loss 0.3328 Accuracy 0.4255\n",
      "Epoch 52 Batch 200 Loss 0.3362 Accuracy 0.4242\n",
      "Epoch 52 Batch 250 Loss 0.3384 Accuracy 0.4244\n",
      "Epoch 52 Batch 300 Loss 0.3413 Accuracy 0.4234\n",
      "Epoch 52 Batch 350 Loss 0.3448 Accuracy 0.4224\n",
      "Epoch 52 Batch 400 Loss 0.3466 Accuracy 0.4230\n",
      "Epoch 52 Batch 450 Loss 0.3487 Accuracy 0.4232\n",
      "Epoch 52 Batch 500 Loss 0.3509 Accuracy 0.4230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 Batch 550 Loss 0.3542 Accuracy 0.4224\n",
      "Epoch 52 Batch 600 Loss 0.3573 Accuracy 0.4223\n",
      "Epoch 52 Batch 650 Loss 0.3598 Accuracy 0.4221\n",
      "Epoch 52 Batch 700 Loss 0.3628 Accuracy 0.4222\n",
      "Epoch 52 Loss 0.3630 Accuracy 0.4222\n",
      "Time taken for 1 epoch: 35.74028515815735 secs\n",
      "\n",
      "Epoch 53 Batch 0 Loss 0.3330 Accuracy 0.3902\n",
      "Epoch 53 Batch 50 Loss 0.3195 Accuracy 0.4235\n",
      "Epoch 53 Batch 100 Loss 0.3281 Accuracy 0.4236\n",
      "Epoch 53 Batch 150 Loss 0.3308 Accuracy 0.4237\n",
      "Epoch 53 Batch 200 Loss 0.3333 Accuracy 0.4238\n",
      "Epoch 53 Batch 250 Loss 0.3378 Accuracy 0.4240\n",
      "Epoch 53 Batch 300 Loss 0.3416 Accuracy 0.4247\n",
      "Epoch 53 Batch 350 Loss 0.3426 Accuracy 0.4240\n",
      "Epoch 53 Batch 400 Loss 0.3456 Accuracy 0.4239\n",
      "Epoch 53 Batch 450 Loss 0.3478 Accuracy 0.4232\n",
      "Epoch 53 Batch 500 Loss 0.3503 Accuracy 0.4227\n",
      "Epoch 53 Batch 550 Loss 0.3527 Accuracy 0.4231\n",
      "Epoch 53 Batch 600 Loss 0.3559 Accuracy 0.4229\n",
      "Epoch 53 Batch 650 Loss 0.3586 Accuracy 0.4230\n",
      "Epoch 53 Batch 700 Loss 0.3613 Accuracy 0.4227\n",
      "Epoch 53 Loss 0.3614 Accuracy 0.4227\n",
      "Time taken for 1 epoch: 37.02077031135559 secs\n",
      "\n",
      "Epoch 54 Batch 0 Loss 0.2674 Accuracy 0.4034\n",
      "Epoch 54 Batch 50 Loss 0.3221 Accuracy 0.4304\n",
      "Epoch 54 Batch 100 Loss 0.3257 Accuracy 0.4276\n",
      "Epoch 54 Batch 150 Loss 0.3284 Accuracy 0.4253\n",
      "Epoch 54 Batch 200 Loss 0.3331 Accuracy 0.4277\n",
      "Epoch 54 Batch 250 Loss 0.3345 Accuracy 0.4259\n",
      "Epoch 54 Batch 300 Loss 0.3382 Accuracy 0.4259\n",
      "Epoch 54 Batch 350 Loss 0.3418 Accuracy 0.4251\n",
      "Epoch 54 Batch 400 Loss 0.3439 Accuracy 0.4237\n",
      "Epoch 54 Batch 450 Loss 0.3465 Accuracy 0.4243\n",
      "Epoch 54 Batch 500 Loss 0.3490 Accuracy 0.4237\n",
      "Epoch 54 Batch 550 Loss 0.3514 Accuracy 0.4237\n",
      "Epoch 54 Batch 600 Loss 0.3543 Accuracy 0.4235\n",
      "Epoch 54 Batch 650 Loss 0.3570 Accuracy 0.4235\n",
      "Epoch 54 Batch 700 Loss 0.3597 Accuracy 0.4233\n",
      "Epoch 54 Loss 0.3601 Accuracy 0.4233\n",
      "Time taken for 1 epoch: 36.996885538101196 secs\n",
      "\n",
      "Epoch 55 Batch 0 Loss 0.3347 Accuracy 0.4248\n",
      "Epoch 55 Batch 50 Loss 0.3211 Accuracy 0.4313\n",
      "Epoch 55 Batch 100 Loss 0.3256 Accuracy 0.4322\n",
      "Epoch 55 Batch 150 Loss 0.3264 Accuracy 0.4302\n",
      "Epoch 55 Batch 200 Loss 0.3296 Accuracy 0.4298\n",
      "Epoch 55 Batch 250 Loss 0.3339 Accuracy 0.4275\n",
      "Epoch 55 Batch 300 Loss 0.3374 Accuracy 0.4265\n",
      "Epoch 55 Batch 350 Loss 0.3403 Accuracy 0.4253\n",
      "Epoch 55 Batch 400 Loss 0.3427 Accuracy 0.4248\n",
      "Epoch 55 Batch 450 Loss 0.3449 Accuracy 0.4242\n",
      "Epoch 55 Batch 500 Loss 0.3473 Accuracy 0.4245\n",
      "Epoch 55 Batch 550 Loss 0.3502 Accuracy 0.4238\n",
      "Epoch 55 Batch 600 Loss 0.3524 Accuracy 0.4235\n",
      "Epoch 55 Batch 650 Loss 0.3549 Accuracy 0.4233\n",
      "Epoch 55 Batch 700 Loss 0.3575 Accuracy 0.4232\n",
      "Saving checkpoint for epoch 55 at ./checkpoints/train/ckpt-23\n",
      "Epoch 55 Loss 0.3576 Accuracy 0.4233\n",
      "Time taken for 1 epoch: 36.971620321273804 secs\n",
      "\n",
      "Epoch 56 Batch 0 Loss 0.3271 Accuracy 0.4379\n",
      "Epoch 56 Batch 50 Loss 0.3210 Accuracy 0.4211\n",
      "Epoch 56 Batch 100 Loss 0.3204 Accuracy 0.4223\n",
      "Epoch 56 Batch 150 Loss 0.3255 Accuracy 0.4228\n",
      "Epoch 56 Batch 200 Loss 0.3268 Accuracy 0.4246\n",
      "Epoch 56 Batch 250 Loss 0.3282 Accuracy 0.4242\n",
      "Epoch 56 Batch 300 Loss 0.3326 Accuracy 0.4244\n",
      "Epoch 56 Batch 350 Loss 0.3348 Accuracy 0.4241\n",
      "Epoch 56 Batch 400 Loss 0.3382 Accuracy 0.4242\n",
      "Epoch 56 Batch 450 Loss 0.3406 Accuracy 0.4239\n",
      "Epoch 56 Batch 500 Loss 0.3442 Accuracy 0.4234\n",
      "Epoch 56 Batch 550 Loss 0.3469 Accuracy 0.4232\n",
      "Epoch 56 Batch 600 Loss 0.3496 Accuracy 0.4228\n",
      "Epoch 56 Batch 650 Loss 0.3525 Accuracy 0.4228\n",
      "Epoch 56 Batch 700 Loss 0.3551 Accuracy 0.4226\n",
      "Epoch 56 Loss 0.3552 Accuracy 0.4226\n",
      "Time taken for 1 epoch: 36.582273721694946 secs\n",
      "\n",
      "Epoch 57 Batch 0 Loss 0.3207 Accuracy 0.4515\n",
      "Epoch 57 Batch 50 Loss 0.3166 Accuracy 0.4209\n",
      "Epoch 57 Batch 100 Loss 0.3204 Accuracy 0.4209\n",
      "Epoch 57 Batch 150 Loss 0.3242 Accuracy 0.4252\n",
      "Epoch 57 Batch 200 Loss 0.3285 Accuracy 0.4257\n",
      "Epoch 57 Batch 250 Loss 0.3306 Accuracy 0.4261\n",
      "Epoch 57 Batch 300 Loss 0.3334 Accuracy 0.4264\n",
      "Epoch 57 Batch 350 Loss 0.3357 Accuracy 0.4264\n",
      "Epoch 57 Batch 400 Loss 0.3386 Accuracy 0.4254\n",
      "Epoch 57 Batch 450 Loss 0.3415 Accuracy 0.4254\n",
      "Epoch 57 Batch 500 Loss 0.3439 Accuracy 0.4257\n",
      "Epoch 57 Batch 550 Loss 0.3458 Accuracy 0.4251\n",
      "Epoch 57 Batch 600 Loss 0.3482 Accuracy 0.4245\n",
      "Epoch 57 Batch 650 Loss 0.3507 Accuracy 0.4244\n",
      "Epoch 57 Batch 700 Loss 0.3531 Accuracy 0.4238\n",
      "Epoch 57 Loss 0.3533 Accuracy 0.4238\n",
      "Time taken for 1 epoch: 36.419538259506226 secs\n",
      "\n",
      "Epoch 58 Batch 0 Loss 0.3661 Accuracy 0.4319\n",
      "Epoch 58 Batch 50 Loss 0.3157 Accuracy 0.4256\n",
      "Epoch 58 Batch 100 Loss 0.3209 Accuracy 0.4267\n",
      "Epoch 58 Batch 150 Loss 0.3259 Accuracy 0.4270\n",
      "Epoch 58 Batch 200 Loss 0.3276 Accuracy 0.4267\n",
      "Epoch 58 Batch 250 Loss 0.3297 Accuracy 0.4266\n",
      "Epoch 58 Batch 300 Loss 0.3323 Accuracy 0.4270\n",
      "Epoch 58 Batch 350 Loss 0.3345 Accuracy 0.4267\n",
      "Epoch 58 Batch 400 Loss 0.3377 Accuracy 0.4260\n",
      "Epoch 58 Batch 450 Loss 0.3403 Accuracy 0.4246\n",
      "Epoch 58 Batch 500 Loss 0.3426 Accuracy 0.4242\n",
      "Epoch 58 Batch 550 Loss 0.3448 Accuracy 0.4244\n",
      "Epoch 58 Batch 600 Loss 0.3471 Accuracy 0.4239\n",
      "Epoch 58 Batch 650 Loss 0.3489 Accuracy 0.4238\n",
      "Epoch 58 Batch 700 Loss 0.3514 Accuracy 0.4239\n",
      "Epoch 58 Loss 0.3514 Accuracy 0.4240\n",
      "Time taken for 1 epoch: 37.081732988357544 secs\n",
      "\n",
      "Epoch 59 Batch 0 Loss 0.3100 Accuracy 0.4648\n",
      "Epoch 59 Batch 50 Loss 0.3115 Accuracy 0.4336\n",
      "Epoch 59 Batch 100 Loss 0.3123 Accuracy 0.4296\n",
      "Epoch 59 Batch 150 Loss 0.3164 Accuracy 0.4280\n",
      "Epoch 59 Batch 200 Loss 0.3214 Accuracy 0.4270\n",
      "Epoch 59 Batch 250 Loss 0.3243 Accuracy 0.4257\n",
      "Epoch 59 Batch 300 Loss 0.3274 Accuracy 0.4275\n",
      "Epoch 59 Batch 350 Loss 0.3308 Accuracy 0.4284\n",
      "Epoch 59 Batch 400 Loss 0.3330 Accuracy 0.4286\n",
      "Epoch 59 Batch 450 Loss 0.3358 Accuracy 0.4286\n",
      "Epoch 59 Batch 500 Loss 0.3388 Accuracy 0.4284\n",
      "Epoch 59 Batch 550 Loss 0.3415 Accuracy 0.4272\n",
      "Epoch 59 Batch 600 Loss 0.3441 Accuracy 0.4265\n",
      "Epoch 59 Batch 650 Loss 0.3469 Accuracy 0.4263\n",
      "Epoch 59 Batch 700 Loss 0.3494 Accuracy 0.4254\n",
      "Epoch 59 Loss 0.3495 Accuracy 0.4254\n",
      "Time taken for 1 epoch: 36.27461290359497 secs\n",
      "\n",
      "Epoch 60 Batch 0 Loss 0.3207 Accuracy 0.4652\n",
      "Epoch 60 Batch 50 Loss 0.3120 Accuracy 0.4249\n",
      "Epoch 60 Batch 100 Loss 0.3136 Accuracy 0.4272\n",
      "Epoch 60 Batch 150 Loss 0.3179 Accuracy 0.4275\n",
      "Epoch 60 Batch 200 Loss 0.3205 Accuracy 0.4278\n",
      "Epoch 60 Batch 250 Loss 0.3240 Accuracy 0.4279\n",
      "Epoch 60 Batch 300 Loss 0.3267 Accuracy 0.4270\n",
      "Epoch 60 Batch 350 Loss 0.3288 Accuracy 0.4268\n",
      "Epoch 60 Batch 400 Loss 0.3306 Accuracy 0.4259\n",
      "Epoch 60 Batch 450 Loss 0.3336 Accuracy 0.4258\n",
      "Epoch 60 Batch 500 Loss 0.3370 Accuracy 0.4257\n",
      "Epoch 60 Batch 550 Loss 0.3399 Accuracy 0.4250\n",
      "Epoch 60 Batch 600 Loss 0.3428 Accuracy 0.4250\n",
      "Epoch 60 Batch 650 Loss 0.3451 Accuracy 0.4247\n",
      "Epoch 60 Batch 700 Loss 0.3471 Accuracy 0.4240\n",
      "Saving checkpoint for epoch 60 at ./checkpoints/train/ckpt-24\n",
      "Epoch 60 Loss 0.3474 Accuracy 0.4240\n",
      "Time taken for 1 epoch: 36.40614676475525 secs\n",
      "\n",
      "Epoch 61 Batch 0 Loss 0.2779 Accuracy 0.4096\n",
      "Epoch 61 Batch 50 Loss 0.3090 Accuracy 0.4339\n",
      "Epoch 61 Batch 100 Loss 0.3115 Accuracy 0.4328\n",
      "Epoch 61 Batch 150 Loss 0.3145 Accuracy 0.4340\n",
      "Epoch 61 Batch 200 Loss 0.3175 Accuracy 0.4322\n",
      "Epoch 61 Batch 250 Loss 0.3220 Accuracy 0.4309\n",
      "Epoch 61 Batch 300 Loss 0.3245 Accuracy 0.4302\n",
      "Epoch 61 Batch 350 Loss 0.3273 Accuracy 0.4284\n",
      "Epoch 61 Batch 400 Loss 0.3300 Accuracy 0.4284\n",
      "Epoch 61 Batch 450 Loss 0.3328 Accuracy 0.4281\n",
      "Epoch 61 Batch 500 Loss 0.3363 Accuracy 0.4272\n",
      "Epoch 61 Batch 550 Loss 0.3392 Accuracy 0.4267\n",
      "Epoch 61 Batch 600 Loss 0.3417 Accuracy 0.4265\n",
      "Epoch 61 Batch 650 Loss 0.3445 Accuracy 0.4257\n",
      "Epoch 61 Batch 700 Loss 0.3473 Accuracy 0.4250\n",
      "Epoch 61 Loss 0.3475 Accuracy 0.4249\n",
      "Time taken for 1 epoch: 36.60392928123474 secs\n",
      "\n",
      "Epoch 62 Batch 0 Loss 0.3094 Accuracy 0.4465\n",
      "Epoch 62 Batch 50 Loss 0.3072 Accuracy 0.4285\n",
      "Epoch 62 Batch 100 Loss 0.3096 Accuracy 0.4266\n",
      "Epoch 62 Batch 150 Loss 0.3130 Accuracy 0.4266\n",
      "Epoch 62 Batch 200 Loss 0.3164 Accuracy 0.4264\n",
      "Epoch 62 Batch 250 Loss 0.3195 Accuracy 0.4258\n",
      "Epoch 62 Batch 300 Loss 0.3223 Accuracy 0.4271\n",
      "Epoch 62 Batch 350 Loss 0.3247 Accuracy 0.4281\n",
      "Epoch 62 Batch 400 Loss 0.3268 Accuracy 0.4272\n",
      "Epoch 62 Batch 450 Loss 0.3289 Accuracy 0.4274\n",
      "Epoch 62 Batch 500 Loss 0.3319 Accuracy 0.4269\n",
      "Epoch 62 Batch 550 Loss 0.3354 Accuracy 0.4263\n",
      "Epoch 62 Batch 600 Loss 0.3376 Accuracy 0.4262\n",
      "Epoch 62 Batch 650 Loss 0.3408 Accuracy 0.4255\n",
      "Epoch 62 Batch 700 Loss 0.3436 Accuracy 0.4250\n",
      "Epoch 62 Loss 0.3438 Accuracy 0.4250\n",
      "Time taken for 1 epoch: 37.04718637466431 secs\n",
      "\n",
      "Epoch 63 Batch 0 Loss 0.2925 Accuracy 0.4034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 Batch 50 Loss 0.3003 Accuracy 0.4314\n",
      "Epoch 63 Batch 100 Loss 0.3025 Accuracy 0.4331\n",
      "Epoch 63 Batch 150 Loss 0.3101 Accuracy 0.4325\n",
      "Epoch 63 Batch 200 Loss 0.3137 Accuracy 0.4302\n",
      "Epoch 63 Batch 250 Loss 0.3188 Accuracy 0.4300\n",
      "Epoch 63 Batch 300 Loss 0.3217 Accuracy 0.4298\n",
      "Epoch 63 Batch 350 Loss 0.3247 Accuracy 0.4280\n",
      "Epoch 63 Batch 400 Loss 0.3267 Accuracy 0.4275\n",
      "Epoch 63 Batch 450 Loss 0.3292 Accuracy 0.4273\n",
      "Epoch 63 Batch 500 Loss 0.3313 Accuracy 0.4268\n",
      "Epoch 63 Batch 550 Loss 0.3339 Accuracy 0.4261\n",
      "Epoch 63 Batch 600 Loss 0.3372 Accuracy 0.4262\n",
      "Epoch 63 Batch 650 Loss 0.3395 Accuracy 0.4261\n",
      "Epoch 63 Batch 700 Loss 0.3422 Accuracy 0.4258\n",
      "Epoch 63 Loss 0.3424 Accuracy 0.4258\n",
      "Time taken for 1 epoch: 37.33968424797058 secs\n",
      "\n",
      "Epoch 64 Batch 0 Loss 0.3125 Accuracy 0.4502\n",
      "Epoch 64 Batch 50 Loss 0.3064 Accuracy 0.4308\n",
      "Epoch 64 Batch 100 Loss 0.3056 Accuracy 0.4273\n",
      "Epoch 64 Batch 150 Loss 0.3108 Accuracy 0.4271\n",
      "Epoch 64 Batch 200 Loss 0.3122 Accuracy 0.4267\n",
      "Epoch 64 Batch 250 Loss 0.3155 Accuracy 0.4262\n",
      "Epoch 64 Batch 300 Loss 0.3193 Accuracy 0.4271\n",
      "Epoch 64 Batch 350 Loss 0.3221 Accuracy 0.4262\n",
      "Epoch 64 Batch 400 Loss 0.3240 Accuracy 0.4269\n",
      "Epoch 64 Batch 450 Loss 0.3267 Accuracy 0.4272\n",
      "Epoch 64 Batch 500 Loss 0.3296 Accuracy 0.4261\n",
      "Epoch 64 Batch 550 Loss 0.3334 Accuracy 0.4257\n",
      "Epoch 64 Batch 600 Loss 0.3366 Accuracy 0.4252\n",
      "Epoch 64 Batch 650 Loss 0.3386 Accuracy 0.4252\n",
      "Epoch 64 Batch 700 Loss 0.3413 Accuracy 0.4251\n",
      "Epoch 64 Loss 0.3414 Accuracy 0.4251\n",
      "Time taken for 1 epoch: 36.01337003707886 secs\n",
      "\n",
      "Epoch 65 Batch 0 Loss 0.2519 Accuracy 0.4402\n",
      "Epoch 65 Batch 50 Loss 0.3043 Accuracy 0.4222\n",
      "Epoch 65 Batch 100 Loss 0.3056 Accuracy 0.4260\n",
      "Epoch 65 Batch 150 Loss 0.3069 Accuracy 0.4307\n",
      "Epoch 65 Batch 200 Loss 0.3111 Accuracy 0.4299\n",
      "Epoch 65 Batch 250 Loss 0.3145 Accuracy 0.4292\n",
      "Epoch 65 Batch 300 Loss 0.3165 Accuracy 0.4287\n",
      "Epoch 65 Batch 350 Loss 0.3195 Accuracy 0.4290\n",
      "Epoch 65 Batch 400 Loss 0.3224 Accuracy 0.4292\n",
      "Epoch 65 Batch 450 Loss 0.3255 Accuracy 0.4291\n",
      "Epoch 65 Batch 500 Loss 0.3275 Accuracy 0.4289\n",
      "Epoch 65 Batch 550 Loss 0.3304 Accuracy 0.4290\n",
      "Epoch 65 Batch 600 Loss 0.3324 Accuracy 0.4283\n",
      "Epoch 65 Batch 650 Loss 0.3352 Accuracy 0.4276\n",
      "Epoch 65 Batch 700 Loss 0.3378 Accuracy 0.4270\n",
      "Saving checkpoint for epoch 65 at ./checkpoints/train/ckpt-25\n",
      "Epoch 65 Loss 0.3378 Accuracy 0.4271\n",
      "Time taken for 1 epoch: 36.56469750404358 secs\n",
      "\n",
      "Epoch 66 Batch 0 Loss 0.2994 Accuracy 0.4182\n",
      "Epoch 66 Batch 50 Loss 0.3054 Accuracy 0.4263\n",
      "Epoch 66 Batch 100 Loss 0.3075 Accuracy 0.4275\n",
      "Epoch 66 Batch 150 Loss 0.3086 Accuracy 0.4302\n",
      "Epoch 66 Batch 200 Loss 0.3113 Accuracy 0.4302\n",
      "Epoch 66 Batch 250 Loss 0.3144 Accuracy 0.4297\n",
      "Epoch 66 Batch 300 Loss 0.3164 Accuracy 0.4295\n",
      "Epoch 66 Batch 350 Loss 0.3188 Accuracy 0.4287\n",
      "Epoch 66 Batch 400 Loss 0.3215 Accuracy 0.4278\n",
      "Epoch 66 Batch 450 Loss 0.3233 Accuracy 0.4275\n",
      "Epoch 66 Batch 500 Loss 0.3272 Accuracy 0.4272\n",
      "Epoch 66 Batch 550 Loss 0.3300 Accuracy 0.4263\n",
      "Epoch 66 Batch 600 Loss 0.3319 Accuracy 0.4267\n",
      "Epoch 66 Batch 650 Loss 0.3347 Accuracy 0.4270\n",
      "Epoch 66 Batch 700 Loss 0.3368 Accuracy 0.4268\n",
      "Epoch 66 Loss 0.3368 Accuracy 0.4268\n",
      "Time taken for 1 epoch: 36.854790449142456 secs\n",
      "\n",
      "Epoch 67 Batch 0 Loss 0.3065 Accuracy 0.4219\n",
      "Epoch 67 Batch 50 Loss 0.3000 Accuracy 0.4256\n",
      "Epoch 67 Batch 100 Loss 0.3029 Accuracy 0.4256\n",
      "Epoch 67 Batch 150 Loss 0.3050 Accuracy 0.4266\n",
      "Epoch 67 Batch 200 Loss 0.3081 Accuracy 0.4276\n",
      "Epoch 67 Batch 250 Loss 0.3123 Accuracy 0.4282\n",
      "Epoch 67 Batch 300 Loss 0.3161 Accuracy 0.4285\n",
      "Epoch 67 Batch 350 Loss 0.3189 Accuracy 0.4288\n",
      "Epoch 67 Batch 400 Loss 0.3209 Accuracy 0.4283\n",
      "Epoch 67 Batch 450 Loss 0.3236 Accuracy 0.4283\n",
      "Epoch 67 Batch 500 Loss 0.3261 Accuracy 0.4278\n",
      "Epoch 67 Batch 550 Loss 0.3291 Accuracy 0.4270\n",
      "Epoch 67 Batch 600 Loss 0.3311 Accuracy 0.4266\n",
      "Epoch 67 Batch 650 Loss 0.3326 Accuracy 0.4272\n",
      "Epoch 67 Batch 700 Loss 0.3352 Accuracy 0.4270\n",
      "Epoch 67 Loss 0.3353 Accuracy 0.4270\n",
      "Time taken for 1 epoch: 36.44826865196228 secs\n",
      "\n",
      "Epoch 68 Batch 0 Loss 0.3491 Accuracy 0.3976\n",
      "Epoch 68 Batch 50 Loss 0.2950 Accuracy 0.4359\n",
      "Epoch 68 Batch 100 Loss 0.3017 Accuracy 0.4339\n",
      "Epoch 68 Batch 150 Loss 0.3060 Accuracy 0.4311\n",
      "Epoch 68 Batch 200 Loss 0.3091 Accuracy 0.4301\n",
      "Epoch 68 Batch 250 Loss 0.3128 Accuracy 0.4301\n",
      "Epoch 68 Batch 300 Loss 0.3166 Accuracy 0.4296\n",
      "Epoch 68 Batch 350 Loss 0.3191 Accuracy 0.4295\n",
      "Epoch 68 Batch 400 Loss 0.3205 Accuracy 0.4302\n",
      "Epoch 68 Batch 450 Loss 0.3230 Accuracy 0.4299\n",
      "Epoch 68 Batch 500 Loss 0.3258 Accuracy 0.4290\n",
      "Epoch 68 Batch 550 Loss 0.3269 Accuracy 0.4288\n",
      "Epoch 68 Batch 600 Loss 0.3295 Accuracy 0.4281\n",
      "Epoch 68 Batch 650 Loss 0.3326 Accuracy 0.4281\n",
      "Epoch 68 Batch 700 Loss 0.3357 Accuracy 0.4275\n",
      "Epoch 68 Loss 0.3359 Accuracy 0.4274\n",
      "Time taken for 1 epoch: 36.31588339805603 secs\n",
      "\n",
      "Epoch 69 Batch 0 Loss 0.3057 Accuracy 0.4165\n",
      "Epoch 69 Batch 50 Loss 0.2929 Accuracy 0.4294\n",
      "Epoch 69 Batch 100 Loss 0.2978 Accuracy 0.4285\n",
      "Epoch 69 Batch 150 Loss 0.3009 Accuracy 0.4274\n",
      "Epoch 69 Batch 200 Loss 0.3053 Accuracy 0.4271\n",
      "Epoch 69 Batch 250 Loss 0.3093 Accuracy 0.4269\n",
      "Epoch 69 Batch 300 Loss 0.3119 Accuracy 0.4268\n",
      "Epoch 69 Batch 350 Loss 0.3154 Accuracy 0.4275\n",
      "Epoch 69 Batch 400 Loss 0.3181 Accuracy 0.4276\n",
      "Epoch 69 Batch 450 Loss 0.3204 Accuracy 0.4279\n",
      "Epoch 69 Batch 500 Loss 0.3230 Accuracy 0.4276\n",
      "Epoch 69 Batch 550 Loss 0.3258 Accuracy 0.4280\n",
      "Epoch 69 Batch 600 Loss 0.3279 Accuracy 0.4278\n",
      "Epoch 69 Batch 650 Loss 0.3302 Accuracy 0.4274\n",
      "Epoch 69 Batch 700 Loss 0.3323 Accuracy 0.4269\n",
      "Epoch 69 Loss 0.3324 Accuracy 0.4269\n",
      "Time taken for 1 epoch: 36.41528868675232 secs\n",
      "\n",
      "Epoch 70 Batch 0 Loss 0.2676 Accuracy 0.4572\n",
      "Epoch 70 Batch 50 Loss 0.2855 Accuracy 0.4346\n",
      "Epoch 70 Batch 100 Loss 0.2963 Accuracy 0.4345\n",
      "Epoch 70 Batch 150 Loss 0.3005 Accuracy 0.4335\n",
      "Epoch 70 Batch 200 Loss 0.3042 Accuracy 0.4332\n",
      "Epoch 70 Batch 250 Loss 0.3072 Accuracy 0.4322\n",
      "Epoch 70 Batch 300 Loss 0.3107 Accuracy 0.4308\n",
      "Epoch 70 Batch 350 Loss 0.3122 Accuracy 0.4307\n",
      "Epoch 70 Batch 400 Loss 0.3155 Accuracy 0.4296\n",
      "Epoch 70 Batch 450 Loss 0.3180 Accuracy 0.4295\n",
      "Epoch 70 Batch 500 Loss 0.3198 Accuracy 0.4288\n",
      "Epoch 70 Batch 550 Loss 0.3221 Accuracy 0.4281\n",
      "Epoch 70 Batch 600 Loss 0.3246 Accuracy 0.4278\n",
      "Epoch 70 Batch 650 Loss 0.3279 Accuracy 0.4281\n",
      "Epoch 70 Batch 700 Loss 0.3299 Accuracy 0.4276\n",
      "Saving checkpoint for epoch 70 at ./checkpoints/train/ckpt-26\n",
      "Epoch 70 Loss 0.3300 Accuracy 0.4277\n",
      "Time taken for 1 epoch: 36.89113163948059 secs\n",
      "\n",
      "Epoch 71 Batch 0 Loss 0.2848 Accuracy 0.4239\n",
      "Epoch 71 Batch 50 Loss 0.2951 Accuracy 0.4268\n",
      "Epoch 71 Batch 100 Loss 0.3004 Accuracy 0.4241\n",
      "Epoch 71 Batch 150 Loss 0.3032 Accuracy 0.4232\n",
      "Epoch 71 Batch 200 Loss 0.3043 Accuracy 0.4267\n",
      "Epoch 71 Batch 250 Loss 0.3061 Accuracy 0.4275\n",
      "Epoch 71 Batch 300 Loss 0.3082 Accuracy 0.4279\n",
      "Epoch 71 Batch 350 Loss 0.3115 Accuracy 0.4277\n",
      "Epoch 71 Batch 400 Loss 0.3148 Accuracy 0.4275\n",
      "Epoch 71 Batch 450 Loss 0.3169 Accuracy 0.4271\n",
      "Epoch 71 Batch 500 Loss 0.3189 Accuracy 0.4273\n",
      "Epoch 71 Batch 550 Loss 0.3212 Accuracy 0.4275\n",
      "Epoch 71 Batch 600 Loss 0.3242 Accuracy 0.4274\n",
      "Epoch 71 Batch 650 Loss 0.3268 Accuracy 0.4269\n",
      "Epoch 71 Batch 700 Loss 0.3295 Accuracy 0.4268\n",
      "Epoch 71 Loss 0.3297 Accuracy 0.4268\n",
      "Time taken for 1 epoch: 36.60729646682739 secs\n",
      "\n",
      "Epoch 72 Batch 0 Loss 0.3128 Accuracy 0.4662\n",
      "Epoch 72 Batch 50 Loss 0.2946 Accuracy 0.4281\n",
      "Epoch 72 Batch 100 Loss 0.2981 Accuracy 0.4315\n",
      "Epoch 72 Batch 150 Loss 0.3015 Accuracy 0.4298\n",
      "Epoch 72 Batch 200 Loss 0.3032 Accuracy 0.4304\n",
      "Epoch 72 Batch 250 Loss 0.3058 Accuracy 0.4294\n",
      "Epoch 72 Batch 300 Loss 0.3078 Accuracy 0.4285\n",
      "Epoch 72 Batch 350 Loss 0.3102 Accuracy 0.4279\n",
      "Epoch 72 Batch 400 Loss 0.3121 Accuracy 0.4283\n",
      "Epoch 72 Batch 450 Loss 0.3151 Accuracy 0.4281\n",
      "Epoch 72 Batch 500 Loss 0.3176 Accuracy 0.4278\n",
      "Epoch 72 Batch 550 Loss 0.3204 Accuracy 0.4282\n",
      "Epoch 72 Batch 600 Loss 0.3230 Accuracy 0.4285\n",
      "Epoch 72 Batch 650 Loss 0.3254 Accuracy 0.4280\n",
      "Epoch 72 Batch 700 Loss 0.3282 Accuracy 0.4273\n",
      "Epoch 72 Loss 0.3283 Accuracy 0.4273\n",
      "Time taken for 1 epoch: 37.17716908454895 secs\n",
      "\n",
      "Epoch 73 Batch 0 Loss 0.2700 Accuracy 0.4665\n",
      "Epoch 73 Batch 50 Loss 0.2894 Accuracy 0.4368\n",
      "Epoch 73 Batch 100 Loss 0.2931 Accuracy 0.4313\n",
      "Epoch 73 Batch 150 Loss 0.2950 Accuracy 0.4286\n",
      "Epoch 73 Batch 200 Loss 0.3000 Accuracy 0.4282\n",
      "Epoch 73 Batch 250 Loss 0.3038 Accuracy 0.4287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 Batch 300 Loss 0.3075 Accuracy 0.4288\n",
      "Epoch 73 Batch 350 Loss 0.3102 Accuracy 0.4292\n",
      "Epoch 73 Batch 400 Loss 0.3134 Accuracy 0.4294\n",
      "Epoch 73 Batch 450 Loss 0.3156 Accuracy 0.4292\n",
      "Epoch 73 Batch 500 Loss 0.3177 Accuracy 0.4286\n",
      "Epoch 73 Batch 550 Loss 0.3206 Accuracy 0.4279\n",
      "Epoch 73 Batch 600 Loss 0.3231 Accuracy 0.4280\n",
      "Epoch 73 Batch 650 Loss 0.3255 Accuracy 0.4276\n",
      "Epoch 73 Batch 700 Loss 0.3277 Accuracy 0.4271\n",
      "Epoch 73 Loss 0.3278 Accuracy 0.4271\n",
      "Time taken for 1 epoch: 36.40369701385498 secs\n",
      "\n",
      "Epoch 74 Batch 0 Loss 0.2890 Accuracy 0.4514\n",
      "Epoch 74 Batch 50 Loss 0.2951 Accuracy 0.4346\n",
      "Epoch 74 Batch 100 Loss 0.2963 Accuracy 0.4336\n",
      "Epoch 74 Batch 150 Loss 0.2981 Accuracy 0.4332\n",
      "Epoch 74 Batch 200 Loss 0.2997 Accuracy 0.4330\n",
      "Epoch 74 Batch 250 Loss 0.3036 Accuracy 0.4318\n",
      "Epoch 74 Batch 300 Loss 0.3063 Accuracy 0.4307\n",
      "Epoch 74 Batch 350 Loss 0.3093 Accuracy 0.4303\n",
      "Epoch 74 Batch 400 Loss 0.3119 Accuracy 0.4298\n",
      "Epoch 74 Batch 450 Loss 0.3142 Accuracy 0.4295\n",
      "Epoch 74 Batch 500 Loss 0.3171 Accuracy 0.4294\n",
      "Epoch 74 Batch 550 Loss 0.3193 Accuracy 0.4294\n",
      "Epoch 74 Batch 600 Loss 0.3221 Accuracy 0.4294\n",
      "Epoch 74 Batch 650 Loss 0.3246 Accuracy 0.4287\n",
      "Epoch 74 Batch 700 Loss 0.3269 Accuracy 0.4278\n",
      "Epoch 74 Loss 0.3269 Accuracy 0.4278\n",
      "Time taken for 1 epoch: 36.341992139816284 secs\n",
      "\n",
      "Epoch 75 Batch 0 Loss 0.2871 Accuracy 0.4437\n",
      "Epoch 75 Batch 50 Loss 0.2896 Accuracy 0.4312\n",
      "Epoch 75 Batch 100 Loss 0.2890 Accuracy 0.4293\n",
      "Epoch 75 Batch 150 Loss 0.2925 Accuracy 0.4319\n",
      "Epoch 75 Batch 200 Loss 0.2973 Accuracy 0.4323\n",
      "Epoch 75 Batch 250 Loss 0.3006 Accuracy 0.4311\n",
      "Epoch 75 Batch 300 Loss 0.3042 Accuracy 0.4301\n",
      "Epoch 75 Batch 350 Loss 0.3075 Accuracy 0.4289\n",
      "Epoch 75 Batch 400 Loss 0.3108 Accuracy 0.4279\n",
      "Epoch 75 Batch 450 Loss 0.3125 Accuracy 0.4281\n",
      "Epoch 75 Batch 500 Loss 0.3145 Accuracy 0.4283\n",
      "Epoch 75 Batch 550 Loss 0.3167 Accuracy 0.4287\n",
      "Epoch 75 Batch 600 Loss 0.3186 Accuracy 0.4286\n",
      "Epoch 75 Batch 650 Loss 0.3213 Accuracy 0.4283\n",
      "Epoch 75 Batch 700 Loss 0.3243 Accuracy 0.4278\n",
      "Saving checkpoint for epoch 75 at ./checkpoints/train/ckpt-27\n",
      "Epoch 75 Loss 0.3244 Accuracy 0.4278\n",
      "Time taken for 1 epoch: 36.71827054023743 secs\n",
      "\n",
      "Epoch 76 Batch 0 Loss 0.3072 Accuracy 0.4375\n",
      "Epoch 76 Batch 50 Loss 0.2864 Accuracy 0.4296\n",
      "Epoch 76 Batch 100 Loss 0.2906 Accuracy 0.4313\n",
      "Epoch 76 Batch 150 Loss 0.2936 Accuracy 0.4300\n",
      "Epoch 76 Batch 200 Loss 0.2950 Accuracy 0.4286\n",
      "Epoch 76 Batch 250 Loss 0.2990 Accuracy 0.4291\n",
      "Epoch 76 Batch 300 Loss 0.3007 Accuracy 0.4306\n",
      "Epoch 76 Batch 350 Loss 0.3038 Accuracy 0.4300\n",
      "Epoch 76 Batch 400 Loss 0.3068 Accuracy 0.4307\n",
      "Epoch 76 Batch 450 Loss 0.3098 Accuracy 0.4305\n",
      "Epoch 76 Batch 500 Loss 0.3127 Accuracy 0.4299\n",
      "Epoch 76 Batch 550 Loss 0.3151 Accuracy 0.4298\n",
      "Epoch 76 Batch 600 Loss 0.3174 Accuracy 0.4295\n",
      "Epoch 76 Batch 650 Loss 0.3202 Accuracy 0.4291\n",
      "Epoch 76 Batch 700 Loss 0.3226 Accuracy 0.4291\n",
      "Epoch 76 Loss 0.3227 Accuracy 0.4291\n",
      "Time taken for 1 epoch: 36.3160982131958 secs\n",
      "\n",
      "Epoch 77 Batch 0 Loss 0.2938 Accuracy 0.4955\n",
      "Epoch 77 Batch 50 Loss 0.2847 Accuracy 0.4338\n",
      "Epoch 77 Batch 100 Loss 0.2895 Accuracy 0.4335\n",
      "Epoch 77 Batch 150 Loss 0.2925 Accuracy 0.4330\n",
      "Epoch 77 Batch 200 Loss 0.2969 Accuracy 0.4338\n",
      "Epoch 77 Batch 250 Loss 0.2995 Accuracy 0.4325\n",
      "Epoch 77 Batch 300 Loss 0.3019 Accuracy 0.4314\n",
      "Epoch 77 Batch 350 Loss 0.3041 Accuracy 0.4311\n",
      "Epoch 77 Batch 400 Loss 0.3065 Accuracy 0.4304\n",
      "Epoch 77 Batch 450 Loss 0.3087 Accuracy 0.4304\n",
      "Epoch 77 Batch 500 Loss 0.3111 Accuracy 0.4293\n",
      "Epoch 77 Batch 550 Loss 0.3135 Accuracy 0.4293\n",
      "Epoch 77 Batch 600 Loss 0.3162 Accuracy 0.4288\n",
      "Epoch 77 Batch 650 Loss 0.3186 Accuracy 0.4289\n",
      "Epoch 77 Batch 700 Loss 0.3207 Accuracy 0.4286\n",
      "Epoch 77 Loss 0.3207 Accuracy 0.4286\n",
      "Time taken for 1 epoch: 37.126206159591675 secs\n",
      "\n",
      "Epoch 78 Batch 0 Loss 0.2961 Accuracy 0.4279\n",
      "Epoch 78 Batch 50 Loss 0.2873 Accuracy 0.4281\n",
      "Epoch 78 Batch 100 Loss 0.2920 Accuracy 0.4309\n",
      "Epoch 78 Batch 150 Loss 0.2940 Accuracy 0.4299\n",
      "Epoch 78 Batch 200 Loss 0.2948 Accuracy 0.4296\n",
      "Epoch 78 Batch 250 Loss 0.2968 Accuracy 0.4287\n",
      "Epoch 78 Batch 300 Loss 0.2996 Accuracy 0.4281\n",
      "Epoch 78 Batch 350 Loss 0.3024 Accuracy 0.4279\n",
      "Epoch 78 Batch 400 Loss 0.3047 Accuracy 0.4281\n",
      "Epoch 78 Batch 450 Loss 0.3069 Accuracy 0.4288\n",
      "Epoch 78 Batch 500 Loss 0.3101 Accuracy 0.4281\n",
      "Epoch 78 Batch 550 Loss 0.3122 Accuracy 0.4283\n",
      "Epoch 78 Batch 600 Loss 0.3148 Accuracy 0.4283\n",
      "Epoch 78 Batch 650 Loss 0.3171 Accuracy 0.4282\n",
      "Epoch 78 Batch 700 Loss 0.3197 Accuracy 0.4277\n",
      "Epoch 78 Loss 0.3198 Accuracy 0.4277\n",
      "Time taken for 1 epoch: 37.13700866699219 secs\n",
      "\n",
      "Epoch 79 Batch 0 Loss 0.2578 Accuracy 0.4504\n",
      "Epoch 79 Batch 50 Loss 0.2789 Accuracy 0.4342\n",
      "Epoch 79 Batch 100 Loss 0.2828 Accuracy 0.4342\n",
      "Epoch 79 Batch 150 Loss 0.2862 Accuracy 0.4328\n",
      "Epoch 79 Batch 200 Loss 0.2895 Accuracy 0.4317\n",
      "Epoch 79 Batch 250 Loss 0.2940 Accuracy 0.4320\n",
      "Epoch 79 Batch 300 Loss 0.2977 Accuracy 0.4318\n",
      "Epoch 79 Batch 350 Loss 0.2999 Accuracy 0.4324\n",
      "Epoch 79 Batch 400 Loss 0.3028 Accuracy 0.4321\n",
      "Epoch 79 Batch 450 Loss 0.3051 Accuracy 0.4306\n",
      "Epoch 79 Batch 500 Loss 0.3077 Accuracy 0.4300\n",
      "Epoch 79 Batch 550 Loss 0.3107 Accuracy 0.4295\n",
      "Epoch 79 Batch 600 Loss 0.3132 Accuracy 0.4294\n",
      "Epoch 79 Batch 650 Loss 0.3155 Accuracy 0.4294\n",
      "Epoch 79 Batch 700 Loss 0.3181 Accuracy 0.4291\n",
      "Epoch 79 Loss 0.3184 Accuracy 0.4291\n",
      "Time taken for 1 epoch: 36.49919819831848 secs\n",
      "\n",
      "Epoch 80 Batch 0 Loss 0.2942 Accuracy 0.4658\n",
      "Epoch 80 Batch 50 Loss 0.2870 Accuracy 0.4293\n",
      "Epoch 80 Batch 100 Loss 0.2847 Accuracy 0.4301\n",
      "Epoch 80 Batch 150 Loss 0.2872 Accuracy 0.4302\n",
      "Epoch 80 Batch 200 Loss 0.2919 Accuracy 0.4294\n",
      "Epoch 80 Batch 250 Loss 0.2953 Accuracy 0.4301\n",
      "Epoch 80 Batch 300 Loss 0.2976 Accuracy 0.4303\n",
      "Epoch 80 Batch 350 Loss 0.3003 Accuracy 0.4303\n",
      "Epoch 80 Batch 400 Loss 0.3021 Accuracy 0.4303\n",
      "Epoch 80 Batch 450 Loss 0.3042 Accuracy 0.4300\n",
      "Epoch 80 Batch 500 Loss 0.3060 Accuracy 0.4299\n",
      "Epoch 80 Batch 550 Loss 0.3084 Accuracy 0.4302\n",
      "Epoch 80 Batch 600 Loss 0.3111 Accuracy 0.4298\n",
      "Epoch 80 Batch 650 Loss 0.3133 Accuracy 0.4297\n",
      "Epoch 80 Batch 700 Loss 0.3164 Accuracy 0.4293\n",
      "Saving checkpoint for epoch 80 at ./checkpoints/train/ckpt-28\n",
      "Epoch 80 Loss 0.3164 Accuracy 0.4293\n",
      "Time taken for 1 epoch: 37.11146569252014 secs\n",
      "\n",
      "Epoch 81 Batch 0 Loss 0.2953 Accuracy 0.4554\n",
      "Epoch 81 Batch 50 Loss 0.2783 Accuracy 0.4285\n",
      "Epoch 81 Batch 100 Loss 0.2823 Accuracy 0.4327\n",
      "Epoch 81 Batch 150 Loss 0.2845 Accuracy 0.4329\n",
      "Epoch 81 Batch 200 Loss 0.2885 Accuracy 0.4332\n",
      "Epoch 81 Batch 250 Loss 0.2919 Accuracy 0.4334\n",
      "Epoch 81 Batch 300 Loss 0.2944 Accuracy 0.4338\n",
      "Epoch 81 Batch 350 Loss 0.2968 Accuracy 0.4323\n",
      "Epoch 81 Batch 400 Loss 0.3001 Accuracy 0.4313\n",
      "Epoch 81 Batch 450 Loss 0.3023 Accuracy 0.4305\n",
      "Epoch 81 Batch 500 Loss 0.3053 Accuracy 0.4301\n",
      "Epoch 81 Batch 550 Loss 0.3073 Accuracy 0.4301\n",
      "Epoch 81 Batch 600 Loss 0.3096 Accuracy 0.4295\n",
      "Epoch 81 Batch 650 Loss 0.3115 Accuracy 0.4297\n",
      "Epoch 81 Batch 700 Loss 0.3145 Accuracy 0.4292\n",
      "Epoch 81 Loss 0.3146 Accuracy 0.4292\n",
      "Time taken for 1 epoch: 36.07577466964722 secs\n",
      "\n",
      "Epoch 82 Batch 0 Loss 0.2463 Accuracy 0.4282\n",
      "Epoch 82 Batch 50 Loss 0.2760 Accuracy 0.4338\n",
      "Epoch 82 Batch 100 Loss 0.2804 Accuracy 0.4307\n",
      "Epoch 82 Batch 150 Loss 0.2857 Accuracy 0.4307\n",
      "Epoch 82 Batch 200 Loss 0.2881 Accuracy 0.4309\n",
      "Epoch 82 Batch 250 Loss 0.2902 Accuracy 0.4306\n",
      "Epoch 82 Batch 300 Loss 0.2929 Accuracy 0.4314\n",
      "Epoch 82 Batch 350 Loss 0.2954 Accuracy 0.4316\n",
      "Epoch 82 Batch 400 Loss 0.2975 Accuracy 0.4314\n",
      "Epoch 82 Batch 450 Loss 0.3002 Accuracy 0.4313\n",
      "Epoch 82 Batch 500 Loss 0.3025 Accuracy 0.4299\n",
      "Epoch 82 Batch 550 Loss 0.3050 Accuracy 0.4298\n",
      "Epoch 82 Batch 600 Loss 0.3079 Accuracy 0.4299\n",
      "Epoch 82 Batch 650 Loss 0.3103 Accuracy 0.4298\n",
      "Epoch 82 Batch 700 Loss 0.3137 Accuracy 0.4296\n",
      "Epoch 82 Loss 0.3138 Accuracy 0.4296\n",
      "Time taken for 1 epoch: 35.66345572471619 secs\n",
      "\n",
      "Epoch 83 Batch 0 Loss 0.2620 Accuracy 0.4552\n",
      "Epoch 83 Batch 50 Loss 0.2741 Accuracy 0.4273\n",
      "Epoch 83 Batch 100 Loss 0.2790 Accuracy 0.4303\n",
      "Epoch 83 Batch 150 Loss 0.2855 Accuracy 0.4312\n",
      "Epoch 83 Batch 200 Loss 0.2882 Accuracy 0.4317\n",
      "Epoch 83 Batch 250 Loss 0.2915 Accuracy 0.4301\n",
      "Epoch 83 Batch 300 Loss 0.2952 Accuracy 0.4301\n",
      "Epoch 83 Batch 350 Loss 0.2970 Accuracy 0.4305\n",
      "Epoch 83 Batch 400 Loss 0.2986 Accuracy 0.4305\n",
      "Epoch 83 Batch 450 Loss 0.3015 Accuracy 0.4295\n",
      "Epoch 83 Batch 500 Loss 0.3032 Accuracy 0.4291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 Batch 550 Loss 0.3053 Accuracy 0.4291\n",
      "Epoch 83 Batch 600 Loss 0.3077 Accuracy 0.4289\n",
      "Epoch 83 Batch 650 Loss 0.3106 Accuracy 0.4289\n",
      "Epoch 83 Batch 700 Loss 0.3128 Accuracy 0.4293\n",
      "Epoch 83 Loss 0.3128 Accuracy 0.4293\n",
      "Time taken for 1 epoch: 36.6643340587616 secs\n",
      "\n",
      "Epoch 84 Batch 0 Loss 0.2342 Accuracy 0.4491\n",
      "Epoch 84 Batch 50 Loss 0.2801 Accuracy 0.4281\n",
      "Epoch 84 Batch 100 Loss 0.2800 Accuracy 0.4292\n",
      "Epoch 84 Batch 150 Loss 0.2835 Accuracy 0.4314\n",
      "Epoch 84 Batch 200 Loss 0.2860 Accuracy 0.4333\n",
      "Epoch 84 Batch 250 Loss 0.2875 Accuracy 0.4315\n",
      "Epoch 84 Batch 300 Loss 0.2910 Accuracy 0.4315\n",
      "Epoch 84 Batch 350 Loss 0.2929 Accuracy 0.4322\n",
      "Epoch 84 Batch 400 Loss 0.2958 Accuracy 0.4317\n",
      "Epoch 84 Batch 450 Loss 0.2989 Accuracy 0.4322\n",
      "Epoch 84 Batch 500 Loss 0.3015 Accuracy 0.4320\n",
      "Epoch 84 Batch 550 Loss 0.3032 Accuracy 0.4320\n",
      "Epoch 84 Batch 600 Loss 0.3053 Accuracy 0.4314\n",
      "Epoch 84 Batch 650 Loss 0.3079 Accuracy 0.4308\n",
      "Epoch 84 Batch 700 Loss 0.3109 Accuracy 0.4303\n",
      "Epoch 84 Loss 0.3110 Accuracy 0.4303\n",
      "Time taken for 1 epoch: 36.19254183769226 secs\n",
      "\n",
      "Epoch 85 Batch 0 Loss 0.2777 Accuracy 0.4147\n",
      "Epoch 85 Batch 50 Loss 0.2765 Accuracy 0.4271\n",
      "Epoch 85 Batch 100 Loss 0.2823 Accuracy 0.4294\n",
      "Epoch 85 Batch 150 Loss 0.2862 Accuracy 0.4302\n",
      "Epoch 85 Batch 200 Loss 0.2897 Accuracy 0.4300\n",
      "Epoch 85 Batch 250 Loss 0.2912 Accuracy 0.4303\n",
      "Epoch 85 Batch 300 Loss 0.2934 Accuracy 0.4300\n",
      "Epoch 85 Batch 350 Loss 0.2950 Accuracy 0.4310\n",
      "Epoch 85 Batch 400 Loss 0.2983 Accuracy 0.4306\n",
      "Epoch 85 Batch 450 Loss 0.3006 Accuracy 0.4306\n",
      "Epoch 85 Batch 500 Loss 0.3025 Accuracy 0.4303\n",
      "Epoch 85 Batch 550 Loss 0.3048 Accuracy 0.4300\n",
      "Epoch 85 Batch 600 Loss 0.3069 Accuracy 0.4299\n",
      "Epoch 85 Batch 650 Loss 0.3095 Accuracy 0.4300\n",
      "Epoch 85 Batch 700 Loss 0.3118 Accuracy 0.4302\n",
      "Saving checkpoint for epoch 85 at ./checkpoints/train/ckpt-29\n",
      "Epoch 85 Loss 0.3118 Accuracy 0.4301\n",
      "Time taken for 1 epoch: 36.377341985702515 secs\n",
      "\n",
      "Epoch 86 Batch 0 Loss 0.2646 Accuracy 0.4589\n",
      "Epoch 86 Batch 50 Loss 0.2732 Accuracy 0.4334\n",
      "Epoch 86 Batch 100 Loss 0.2759 Accuracy 0.4328\n",
      "Epoch 86 Batch 150 Loss 0.2813 Accuracy 0.4311\n",
      "Epoch 86 Batch 200 Loss 0.2856 Accuracy 0.4307\n",
      "Epoch 86 Batch 250 Loss 0.2891 Accuracy 0.4302\n",
      "Epoch 86 Batch 300 Loss 0.2917 Accuracy 0.4297\n",
      "Epoch 86 Batch 350 Loss 0.2940 Accuracy 0.4294\n",
      "Epoch 86 Batch 400 Loss 0.2963 Accuracy 0.4299\n",
      "Epoch 86 Batch 450 Loss 0.2987 Accuracy 0.4300\n",
      "Epoch 86 Batch 500 Loss 0.3014 Accuracy 0.4296\n",
      "Epoch 86 Batch 550 Loss 0.3035 Accuracy 0.4292\n",
      "Epoch 86 Batch 600 Loss 0.3058 Accuracy 0.4297\n",
      "Epoch 86 Batch 650 Loss 0.3076 Accuracy 0.4296\n",
      "Epoch 86 Batch 700 Loss 0.3097 Accuracy 0.4293\n",
      "Epoch 86 Loss 0.3099 Accuracy 0.4294\n",
      "Time taken for 1 epoch: 35.94692325592041 secs\n",
      "\n",
      "Epoch 87 Batch 0 Loss 0.2930 Accuracy 0.4772\n",
      "Epoch 87 Batch 50 Loss 0.2765 Accuracy 0.4317\n",
      "Epoch 87 Batch 100 Loss 0.2789 Accuracy 0.4323\n",
      "Epoch 87 Batch 150 Loss 0.2828 Accuracy 0.4333\n",
      "Epoch 87 Batch 200 Loss 0.2842 Accuracy 0.4319\n",
      "Epoch 87 Batch 250 Loss 0.2861 Accuracy 0.4314\n",
      "Epoch 87 Batch 300 Loss 0.2887 Accuracy 0.4314\n",
      "Epoch 87 Batch 350 Loss 0.2905 Accuracy 0.4315\n",
      "Epoch 87 Batch 400 Loss 0.2932 Accuracy 0.4312\n",
      "Epoch 87 Batch 450 Loss 0.2962 Accuracy 0.4313\n",
      "Epoch 87 Batch 500 Loss 0.2980 Accuracy 0.4311\n",
      "Epoch 87 Batch 550 Loss 0.3009 Accuracy 0.4307\n",
      "Epoch 87 Batch 600 Loss 0.3032 Accuracy 0.4301\n",
      "Epoch 87 Batch 650 Loss 0.3055 Accuracy 0.4299\n",
      "Epoch 87 Batch 700 Loss 0.3080 Accuracy 0.4296\n",
      "Epoch 87 Loss 0.3080 Accuracy 0.4297\n",
      "Time taken for 1 epoch: 35.878493309020996 secs\n",
      "\n",
      "Epoch 88 Batch 0 Loss 0.2843 Accuracy 0.4776\n",
      "Epoch 88 Batch 50 Loss 0.2714 Accuracy 0.4260\n",
      "Epoch 88 Batch 100 Loss 0.2734 Accuracy 0.4298\n",
      "Epoch 88 Batch 150 Loss 0.2759 Accuracy 0.4303\n",
      "Epoch 88 Batch 200 Loss 0.2818 Accuracy 0.4307\n",
      "Epoch 88 Batch 250 Loss 0.2850 Accuracy 0.4313\n",
      "Epoch 88 Batch 300 Loss 0.2877 Accuracy 0.4321\n",
      "Epoch 88 Batch 350 Loss 0.2902 Accuracy 0.4321\n",
      "Epoch 88 Batch 400 Loss 0.2918 Accuracy 0.4316\n",
      "Epoch 88 Batch 450 Loss 0.2941 Accuracy 0.4316\n",
      "Epoch 88 Batch 500 Loss 0.2965 Accuracy 0.4311\n",
      "Epoch 88 Batch 550 Loss 0.2992 Accuracy 0.4311\n",
      "Epoch 88 Batch 600 Loss 0.3020 Accuracy 0.4310\n",
      "Epoch 88 Batch 650 Loss 0.3048 Accuracy 0.4307\n",
      "Epoch 88 Batch 700 Loss 0.3073 Accuracy 0.4303\n",
      "Epoch 88 Loss 0.3074 Accuracy 0.4302\n",
      "Time taken for 1 epoch: 35.57712507247925 secs\n",
      "\n",
      "Epoch 89 Batch 0 Loss 0.2921 Accuracy 0.4803\n",
      "Epoch 89 Batch 50 Loss 0.2767 Accuracy 0.4367\n",
      "Epoch 89 Batch 100 Loss 0.2783 Accuracy 0.4328\n",
      "Epoch 89 Batch 150 Loss 0.2816 Accuracy 0.4349\n",
      "Epoch 89 Batch 200 Loss 0.2846 Accuracy 0.4335\n",
      "Epoch 89 Batch 250 Loss 0.2874 Accuracy 0.4327\n",
      "Epoch 89 Batch 300 Loss 0.2898 Accuracy 0.4326\n",
      "Epoch 89 Batch 350 Loss 0.2912 Accuracy 0.4327\n",
      "Epoch 89 Batch 400 Loss 0.2930 Accuracy 0.4333\n",
      "Epoch 89 Batch 450 Loss 0.2951 Accuracy 0.4327\n",
      "Epoch 89 Batch 500 Loss 0.2975 Accuracy 0.4321\n",
      "Epoch 89 Batch 550 Loss 0.3000 Accuracy 0.4317\n",
      "Epoch 89 Batch 600 Loss 0.3022 Accuracy 0.4314\n",
      "Epoch 89 Batch 650 Loss 0.3041 Accuracy 0.4313\n",
      "Epoch 89 Batch 700 Loss 0.3064 Accuracy 0.4307\n",
      "Epoch 89 Loss 0.3065 Accuracy 0.4308\n",
      "Time taken for 1 epoch: 35.59659385681152 secs\n",
      "\n",
      "Epoch 90 Batch 0 Loss 0.3362 Accuracy 0.4654\n",
      "Epoch 90 Batch 50 Loss 0.2708 Accuracy 0.4332\n",
      "Epoch 90 Batch 100 Loss 0.2740 Accuracy 0.4321\n",
      "Epoch 90 Batch 150 Loss 0.2790 Accuracy 0.4315\n",
      "Epoch 90 Batch 200 Loss 0.2809 Accuracy 0.4316\n",
      "Epoch 90 Batch 250 Loss 0.2827 Accuracy 0.4319\n",
      "Epoch 90 Batch 300 Loss 0.2850 Accuracy 0.4322\n",
      "Epoch 90 Batch 350 Loss 0.2873 Accuracy 0.4318\n",
      "Epoch 90 Batch 400 Loss 0.2897 Accuracy 0.4309\n",
      "Epoch 90 Batch 450 Loss 0.2927 Accuracy 0.4310\n",
      "Epoch 90 Batch 500 Loss 0.2944 Accuracy 0.4306\n",
      "Epoch 90 Batch 550 Loss 0.2970 Accuracy 0.4309\n",
      "Epoch 90 Batch 600 Loss 0.3000 Accuracy 0.4305\n",
      "Epoch 90 Batch 650 Loss 0.3022 Accuracy 0.4310\n",
      "Epoch 90 Batch 700 Loss 0.3045 Accuracy 0.4306\n",
      "Saving checkpoint for epoch 90 at ./checkpoints/train/ckpt-30\n",
      "Epoch 90 Loss 0.3048 Accuracy 0.4305\n",
      "Time taken for 1 epoch: 36.697019815444946 secs\n",
      "\n",
      "Epoch 91 Batch 0 Loss 0.2735 Accuracy 0.4227\n",
      "Epoch 91 Batch 50 Loss 0.2782 Accuracy 0.4297\n",
      "Epoch 91 Batch 100 Loss 0.2798 Accuracy 0.4304\n",
      "Epoch 91 Batch 150 Loss 0.2803 Accuracy 0.4322\n",
      "Epoch 91 Batch 200 Loss 0.2814 Accuracy 0.4316\n",
      "Epoch 91 Batch 250 Loss 0.2832 Accuracy 0.4317\n",
      "Epoch 91 Batch 300 Loss 0.2852 Accuracy 0.4324\n",
      "Epoch 91 Batch 350 Loss 0.2874 Accuracy 0.4337\n",
      "Epoch 91 Batch 400 Loss 0.2904 Accuracy 0.4339\n",
      "Epoch 91 Batch 450 Loss 0.2925 Accuracy 0.4332\n",
      "Epoch 91 Batch 500 Loss 0.2950 Accuracy 0.4320\n",
      "Epoch 91 Batch 550 Loss 0.2974 Accuracy 0.4311\n",
      "Epoch 91 Batch 600 Loss 0.2997 Accuracy 0.4308\n",
      "Epoch 91 Batch 650 Loss 0.3022 Accuracy 0.4310\n",
      "Epoch 91 Batch 700 Loss 0.3046 Accuracy 0.4311\n",
      "Epoch 91 Loss 0.3046 Accuracy 0.4311\n",
      "Time taken for 1 epoch: 36.060423851013184 secs\n",
      "\n",
      "Epoch 92 Batch 0 Loss 0.2378 Accuracy 0.4519\n",
      "Epoch 92 Batch 50 Loss 0.2664 Accuracy 0.4379\n",
      "Epoch 92 Batch 100 Loss 0.2711 Accuracy 0.4408\n",
      "Epoch 92 Batch 150 Loss 0.2752 Accuracy 0.4349\n",
      "Epoch 92 Batch 200 Loss 0.2768 Accuracy 0.4333\n",
      "Epoch 92 Batch 250 Loss 0.2801 Accuracy 0.4325\n",
      "Epoch 92 Batch 300 Loss 0.2818 Accuracy 0.4326\n",
      "Epoch 92 Batch 350 Loss 0.2851 Accuracy 0.4330\n",
      "Epoch 92 Batch 400 Loss 0.2875 Accuracy 0.4327\n",
      "Epoch 92 Batch 450 Loss 0.2898 Accuracy 0.4321\n",
      "Epoch 92 Batch 500 Loss 0.2922 Accuracy 0.4318\n",
      "Epoch 92 Batch 550 Loss 0.2949 Accuracy 0.4312\n",
      "Epoch 92 Batch 600 Loss 0.2972 Accuracy 0.4308\n",
      "Epoch 92 Batch 650 Loss 0.3007 Accuracy 0.4302\n",
      "Epoch 92 Batch 700 Loss 0.3024 Accuracy 0.4304\n",
      "Epoch 92 Loss 0.3025 Accuracy 0.4305\n",
      "Time taken for 1 epoch: 35.69643759727478 secs\n",
      "\n",
      "Epoch 93 Batch 0 Loss 0.2799 Accuracy 0.4460\n",
      "Epoch 93 Batch 50 Loss 0.2695 Accuracy 0.4274\n",
      "Epoch 93 Batch 100 Loss 0.2711 Accuracy 0.4325\n",
      "Epoch 93 Batch 150 Loss 0.2736 Accuracy 0.4339\n",
      "Epoch 93 Batch 200 Loss 0.2771 Accuracy 0.4327\n",
      "Epoch 93 Batch 250 Loss 0.2793 Accuracy 0.4324\n",
      "Epoch 93 Batch 300 Loss 0.2822 Accuracy 0.4322\n",
      "Epoch 93 Batch 350 Loss 0.2839 Accuracy 0.4327\n",
      "Epoch 93 Batch 400 Loss 0.2856 Accuracy 0.4321\n",
      "Epoch 93 Batch 450 Loss 0.2877 Accuracy 0.4325\n",
      "Epoch 93 Batch 500 Loss 0.2906 Accuracy 0.4325\n",
      "Epoch 93 Batch 550 Loss 0.2932 Accuracy 0.4327\n",
      "Epoch 93 Batch 600 Loss 0.2962 Accuracy 0.4322\n",
      "Epoch 93 Batch 650 Loss 0.2984 Accuracy 0.4314\n",
      "Epoch 93 Batch 700 Loss 0.3006 Accuracy 0.4312\n",
      "Epoch 93 Loss 0.3007 Accuracy 0.4312\n",
      "Time taken for 1 epoch: 35.99293780326843 secs\n",
      "\n",
      "Epoch 94 Batch 0 Loss 0.2641 Accuracy 0.4433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 Batch 50 Loss 0.2705 Accuracy 0.4354\n",
      "Epoch 94 Batch 100 Loss 0.2730 Accuracy 0.4353\n",
      "Epoch 94 Batch 150 Loss 0.2741 Accuracy 0.4346\n",
      "Epoch 94 Batch 200 Loss 0.2755 Accuracy 0.4342\n",
      "Epoch 94 Batch 250 Loss 0.2786 Accuracy 0.4341\n",
      "Epoch 94 Batch 300 Loss 0.2806 Accuracy 0.4339\n",
      "Epoch 94 Batch 350 Loss 0.2836 Accuracy 0.4333\n",
      "Epoch 94 Batch 400 Loss 0.2854 Accuracy 0.4337\n",
      "Epoch 94 Batch 450 Loss 0.2877 Accuracy 0.4329\n",
      "Epoch 94 Batch 500 Loss 0.2905 Accuracy 0.4328\n",
      "Epoch 94 Batch 550 Loss 0.2924 Accuracy 0.4324\n",
      "Epoch 94 Batch 600 Loss 0.2949 Accuracy 0.4322\n",
      "Epoch 94 Batch 650 Loss 0.2976 Accuracy 0.4318\n",
      "Epoch 94 Batch 700 Loss 0.2995 Accuracy 0.4312\n",
      "Epoch 94 Loss 0.2996 Accuracy 0.4312\n",
      "Time taken for 1 epoch: 36.27364444732666 secs\n",
      "\n",
      "Epoch 95 Batch 0 Loss 0.3045 Accuracy 0.4439\n",
      "Epoch 95 Batch 50 Loss 0.2660 Accuracy 0.4367\n",
      "Epoch 95 Batch 100 Loss 0.2688 Accuracy 0.4330\n",
      "Epoch 95 Batch 150 Loss 0.2709 Accuracy 0.4347\n",
      "Epoch 95 Batch 200 Loss 0.2745 Accuracy 0.4354\n",
      "Epoch 95 Batch 250 Loss 0.2774 Accuracy 0.4343\n",
      "Epoch 95 Batch 300 Loss 0.2800 Accuracy 0.4340\n",
      "Epoch 95 Batch 350 Loss 0.2827 Accuracy 0.4328\n",
      "Epoch 95 Batch 400 Loss 0.2846 Accuracy 0.4321\n",
      "Epoch 95 Batch 450 Loss 0.2863 Accuracy 0.4327\n",
      "Epoch 95 Batch 500 Loss 0.2888 Accuracy 0.4324\n",
      "Epoch 95 Batch 550 Loss 0.2919 Accuracy 0.4324\n",
      "Epoch 95 Batch 600 Loss 0.2938 Accuracy 0.4324\n",
      "Epoch 95 Batch 650 Loss 0.2960 Accuracy 0.4322\n",
      "Epoch 95 Batch 700 Loss 0.2985 Accuracy 0.4323\n",
      "Saving checkpoint for epoch 95 at ./checkpoints/train/ckpt-31\n",
      "Epoch 95 Loss 0.2985 Accuracy 0.4323\n",
      "Time taken for 1 epoch: 37.36570739746094 secs\n",
      "\n",
      "Epoch 96 Batch 0 Loss 0.2362 Accuracy 0.4291\n",
      "Epoch 96 Batch 50 Loss 0.2701 Accuracy 0.4374\n",
      "Epoch 96 Batch 100 Loss 0.2707 Accuracy 0.4340\n",
      "Epoch 96 Batch 150 Loss 0.2732 Accuracy 0.4365\n",
      "Epoch 96 Batch 200 Loss 0.2781 Accuracy 0.4348\n",
      "Epoch 96 Batch 250 Loss 0.2799 Accuracy 0.4341\n",
      "Epoch 96 Batch 300 Loss 0.2811 Accuracy 0.4341\n",
      "Epoch 96 Batch 350 Loss 0.2833 Accuracy 0.4336\n",
      "Epoch 96 Batch 400 Loss 0.2858 Accuracy 0.4339\n",
      "Epoch 96 Batch 450 Loss 0.2878 Accuracy 0.4346\n",
      "Epoch 96 Batch 500 Loss 0.2894 Accuracy 0.4341\n",
      "Epoch 96 Batch 550 Loss 0.2920 Accuracy 0.4334\n",
      "Epoch 96 Batch 600 Loss 0.2945 Accuracy 0.4330\n",
      "Epoch 96 Batch 650 Loss 0.2965 Accuracy 0.4321\n",
      "Epoch 96 Batch 700 Loss 0.2988 Accuracy 0.4314\n",
      "Epoch 96 Loss 0.2989 Accuracy 0.4315\n",
      "Time taken for 1 epoch: 37.312782526016235 secs\n",
      "\n",
      "Epoch 97 Batch 0 Loss 0.2770 Accuracy 0.4392\n",
      "Epoch 97 Batch 50 Loss 0.2644 Accuracy 0.4350\n",
      "Epoch 97 Batch 100 Loss 0.2658 Accuracy 0.4357\n",
      "Epoch 97 Batch 150 Loss 0.2701 Accuracy 0.4355\n",
      "Epoch 97 Batch 200 Loss 0.2734 Accuracy 0.4336\n",
      "Epoch 97 Batch 250 Loss 0.2756 Accuracy 0.4337\n",
      "Epoch 97 Batch 300 Loss 0.2791 Accuracy 0.4346\n",
      "Epoch 97 Batch 350 Loss 0.2821 Accuracy 0.4339\n",
      "Epoch 97 Batch 400 Loss 0.2845 Accuracy 0.4334\n",
      "Epoch 97 Batch 450 Loss 0.2866 Accuracy 0.4330\n",
      "Epoch 97 Batch 500 Loss 0.2888 Accuracy 0.4329\n",
      "Epoch 97 Batch 550 Loss 0.2911 Accuracy 0.4328\n",
      "Epoch 97 Batch 600 Loss 0.2935 Accuracy 0.4321\n",
      "Epoch 97 Batch 650 Loss 0.2954 Accuracy 0.4320\n",
      "Epoch 97 Batch 700 Loss 0.2977 Accuracy 0.4315\n",
      "Epoch 97 Loss 0.2978 Accuracy 0.4315\n",
      "Time taken for 1 epoch: 35.93181228637695 secs\n",
      "\n",
      "Epoch 98 Batch 0 Loss 0.2402 Accuracy 0.3886\n",
      "Epoch 98 Batch 50 Loss 0.2590 Accuracy 0.4372\n",
      "Epoch 98 Batch 100 Loss 0.2648 Accuracy 0.4369\n",
      "Epoch 98 Batch 150 Loss 0.2668 Accuracy 0.4371\n",
      "Epoch 98 Batch 200 Loss 0.2713 Accuracy 0.4369\n",
      "Epoch 98 Batch 250 Loss 0.2731 Accuracy 0.4358\n",
      "Epoch 98 Batch 300 Loss 0.2755 Accuracy 0.4357\n",
      "Epoch 98 Batch 350 Loss 0.2780 Accuracy 0.4347\n",
      "Epoch 98 Batch 400 Loss 0.2802 Accuracy 0.4345\n",
      "Epoch 98 Batch 450 Loss 0.2824 Accuracy 0.4340\n",
      "Epoch 98 Batch 500 Loss 0.2846 Accuracy 0.4336\n",
      "Epoch 98 Batch 550 Loss 0.2876 Accuracy 0.4335\n",
      "Epoch 98 Batch 600 Loss 0.2900 Accuracy 0.4325\n",
      "Epoch 98 Batch 650 Loss 0.2925 Accuracy 0.4318\n",
      "Epoch 98 Batch 700 Loss 0.2955 Accuracy 0.4311\n",
      "Epoch 98 Loss 0.2957 Accuracy 0.4311\n",
      "Time taken for 1 epoch: 35.98072409629822 secs\n",
      "\n",
      "Epoch 99 Batch 0 Loss 0.2448 Accuracy 0.3942\n",
      "Epoch 99 Batch 50 Loss 0.2611 Accuracy 0.4355\n",
      "Epoch 99 Batch 100 Loss 0.2646 Accuracy 0.4356\n",
      "Epoch 99 Batch 150 Loss 0.2694 Accuracy 0.4317\n",
      "Epoch 99 Batch 200 Loss 0.2711 Accuracy 0.4314\n",
      "Epoch 99 Batch 250 Loss 0.2724 Accuracy 0.4324\n",
      "Epoch 99 Batch 300 Loss 0.2745 Accuracy 0.4333\n",
      "Epoch 99 Batch 350 Loss 0.2774 Accuracy 0.4329\n",
      "Epoch 99 Batch 400 Loss 0.2792 Accuracy 0.4327\n",
      "Epoch 99 Batch 450 Loss 0.2813 Accuracy 0.4326\n",
      "Epoch 99 Batch 500 Loss 0.2835 Accuracy 0.4322\n",
      "Epoch 99 Batch 550 Loss 0.2863 Accuracy 0.4319\n",
      "Epoch 99 Batch 600 Loss 0.2889 Accuracy 0.4316\n",
      "Epoch 99 Batch 650 Loss 0.2912 Accuracy 0.4314\n",
      "Epoch 99 Batch 700 Loss 0.2934 Accuracy 0.4317\n",
      "Epoch 99 Loss 0.2935 Accuracy 0.4317\n",
      "Time taken for 1 epoch: 36.31936812400818 secs\n",
      "\n",
      "Epoch 100 Batch 0 Loss 0.3308 Accuracy 0.4453\n",
      "Epoch 100 Batch 50 Loss 0.2617 Accuracy 0.4391\n",
      "Epoch 100 Batch 100 Loss 0.2645 Accuracy 0.4386\n",
      "Epoch 100 Batch 150 Loss 0.2690 Accuracy 0.4375\n",
      "Epoch 100 Batch 200 Loss 0.2712 Accuracy 0.4368\n",
      "Epoch 100 Batch 250 Loss 0.2737 Accuracy 0.4339\n",
      "Epoch 100 Batch 300 Loss 0.2768 Accuracy 0.4324\n",
      "Epoch 100 Batch 350 Loss 0.2785 Accuracy 0.4330\n",
      "Epoch 100 Batch 400 Loss 0.2803 Accuracy 0.4329\n",
      "Epoch 100 Batch 450 Loss 0.2826 Accuracy 0.4328\n",
      "Epoch 100 Batch 500 Loss 0.2846 Accuracy 0.4327\n",
      "Epoch 100 Batch 550 Loss 0.2867 Accuracy 0.4325\n",
      "Epoch 100 Batch 600 Loss 0.2891 Accuracy 0.4322\n",
      "Epoch 100 Batch 650 Loss 0.2918 Accuracy 0.4321\n",
      "Epoch 100 Batch 700 Loss 0.2939 Accuracy 0.4316\n",
      "Saving checkpoint for epoch 100 at ./checkpoints/train/ckpt-32\n",
      "Epoch 100 Loss 0.2938 Accuracy 0.4315\n",
      "Time taken for 1 epoch: 35.844682455062866 secs\n",
      "\n",
      "Epoch 101 Batch 0 Loss 0.2096 Accuracy 0.4174\n",
      "Epoch 101 Batch 50 Loss 0.2563 Accuracy 0.4331\n",
      "Epoch 101 Batch 100 Loss 0.2625 Accuracy 0.4307\n",
      "Epoch 101 Batch 150 Loss 0.2668 Accuracy 0.4326\n",
      "Epoch 101 Batch 200 Loss 0.2705 Accuracy 0.4321\n",
      "Epoch 101 Batch 250 Loss 0.2722 Accuracy 0.4329\n",
      "Epoch 101 Batch 300 Loss 0.2747 Accuracy 0.4330\n",
      "Epoch 101 Batch 350 Loss 0.2770 Accuracy 0.4334\n",
      "Epoch 101 Batch 400 Loss 0.2794 Accuracy 0.4331\n",
      "Epoch 101 Batch 450 Loss 0.2815 Accuracy 0.4328\n",
      "Epoch 101 Batch 500 Loss 0.2836 Accuracy 0.4329\n",
      "Epoch 101 Batch 550 Loss 0.2854 Accuracy 0.4323\n",
      "Epoch 101 Batch 600 Loss 0.2877 Accuracy 0.4321\n",
      "Epoch 101 Batch 650 Loss 0.2900 Accuracy 0.4318\n",
      "Epoch 101 Batch 700 Loss 0.2923 Accuracy 0.4316\n",
      "Epoch 101 Loss 0.2924 Accuracy 0.4316\n",
      "Time taken for 1 epoch: 36.10759687423706 secs\n",
      "\n",
      "Epoch 102 Batch 0 Loss 0.2616 Accuracy 0.3951\n",
      "Epoch 102 Batch 50 Loss 0.2638 Accuracy 0.4376\n",
      "Epoch 102 Batch 100 Loss 0.2668 Accuracy 0.4304\n",
      "Epoch 102 Batch 150 Loss 0.2697 Accuracy 0.4302\n",
      "Epoch 102 Batch 200 Loss 0.2709 Accuracy 0.4314\n",
      "Epoch 102 Batch 250 Loss 0.2734 Accuracy 0.4316\n",
      "Epoch 102 Batch 300 Loss 0.2752 Accuracy 0.4313\n",
      "Epoch 102 Batch 350 Loss 0.2778 Accuracy 0.4310\n",
      "Epoch 102 Batch 400 Loss 0.2795 Accuracy 0.4319\n",
      "Epoch 102 Batch 450 Loss 0.2817 Accuracy 0.4326\n",
      "Epoch 102 Batch 500 Loss 0.2842 Accuracy 0.4325\n",
      "Epoch 102 Batch 550 Loss 0.2863 Accuracy 0.4325\n",
      "Epoch 102 Batch 600 Loss 0.2881 Accuracy 0.4327\n",
      "Epoch 102 Batch 650 Loss 0.2900 Accuracy 0.4330\n",
      "Epoch 102 Batch 700 Loss 0.2918 Accuracy 0.4328\n",
      "Epoch 102 Loss 0.2918 Accuracy 0.4328\n",
      "Time taken for 1 epoch: 36.57697629928589 secs\n",
      "\n",
      "Epoch 103 Batch 0 Loss 0.2311 Accuracy 0.4164\n",
      "Epoch 103 Batch 50 Loss 0.2600 Accuracy 0.4328\n",
      "Epoch 103 Batch 100 Loss 0.2631 Accuracy 0.4352\n",
      "Epoch 103 Batch 150 Loss 0.2651 Accuracy 0.4353\n",
      "Epoch 103 Batch 200 Loss 0.2685 Accuracy 0.4329\n",
      "Epoch 103 Batch 250 Loss 0.2713 Accuracy 0.4318\n",
      "Epoch 103 Batch 300 Loss 0.2738 Accuracy 0.4327\n",
      "Epoch 103 Batch 350 Loss 0.2760 Accuracy 0.4332\n",
      "Epoch 103 Batch 400 Loss 0.2784 Accuracy 0.4337\n",
      "Epoch 103 Batch 450 Loss 0.2804 Accuracy 0.4337\n",
      "Epoch 103 Batch 500 Loss 0.2829 Accuracy 0.4339\n",
      "Epoch 103 Batch 550 Loss 0.2843 Accuracy 0.4338\n",
      "Epoch 103 Batch 600 Loss 0.2859 Accuracy 0.4335\n",
      "Epoch 103 Batch 650 Loss 0.2880 Accuracy 0.4332\n",
      "Epoch 103 Batch 700 Loss 0.2903 Accuracy 0.4326\n",
      "Epoch 103 Loss 0.2905 Accuracy 0.4326\n",
      "Time taken for 1 epoch: 36.61862254142761 secs\n",
      "\n",
      "Epoch 104 Batch 0 Loss 0.2958 Accuracy 0.4239\n",
      "Epoch 104 Batch 50 Loss 0.2623 Accuracy 0.4328\n",
      "Epoch 104 Batch 100 Loss 0.2626 Accuracy 0.4322\n",
      "Epoch 104 Batch 150 Loss 0.2642 Accuracy 0.4341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104 Batch 200 Loss 0.2666 Accuracy 0.4345\n",
      "Epoch 104 Batch 250 Loss 0.2687 Accuracy 0.4355\n",
      "Epoch 104 Batch 300 Loss 0.2706 Accuracy 0.4368\n",
      "Epoch 104 Batch 350 Loss 0.2724 Accuracy 0.4363\n",
      "Epoch 104 Batch 400 Loss 0.2743 Accuracy 0.4357\n",
      "Epoch 104 Batch 450 Loss 0.2768 Accuracy 0.4347\n",
      "Epoch 104 Batch 500 Loss 0.2787 Accuracy 0.4347\n",
      "Epoch 104 Batch 550 Loss 0.2819 Accuracy 0.4350\n",
      "Epoch 104 Batch 600 Loss 0.2843 Accuracy 0.4345\n",
      "Epoch 104 Batch 650 Loss 0.2869 Accuracy 0.4341\n",
      "Epoch 104 Batch 700 Loss 0.2892 Accuracy 0.4334\n",
      "Epoch 104 Loss 0.2893 Accuracy 0.4334\n",
      "Time taken for 1 epoch: 36.536051750183105 secs\n",
      "\n",
      "Epoch 105 Batch 0 Loss 0.2697 Accuracy 0.4349\n",
      "Epoch 105 Batch 50 Loss 0.2618 Accuracy 0.4389\n",
      "Epoch 105 Batch 100 Loss 0.2606 Accuracy 0.4361\n",
      "Epoch 105 Batch 150 Loss 0.2629 Accuracy 0.4347\n",
      "Epoch 105 Batch 200 Loss 0.2655 Accuracy 0.4335\n",
      "Epoch 105 Batch 250 Loss 0.2679 Accuracy 0.4337\n",
      "Epoch 105 Batch 300 Loss 0.2707 Accuracy 0.4332\n",
      "Epoch 105 Batch 350 Loss 0.2727 Accuracy 0.4338\n",
      "Epoch 105 Batch 400 Loss 0.2750 Accuracy 0.4343\n",
      "Epoch 105 Batch 450 Loss 0.2773 Accuracy 0.4342\n",
      "Epoch 105 Batch 500 Loss 0.2795 Accuracy 0.4337\n",
      "Epoch 105 Batch 550 Loss 0.2818 Accuracy 0.4334\n",
      "Epoch 105 Batch 600 Loss 0.2838 Accuracy 0.4332\n",
      "Epoch 105 Batch 650 Loss 0.2863 Accuracy 0.4331\n",
      "Epoch 105 Batch 700 Loss 0.2881 Accuracy 0.4326\n",
      "Saving checkpoint for epoch 105 at ./checkpoints/train/ckpt-33\n",
      "Epoch 105 Loss 0.2881 Accuracy 0.4326\n",
      "Time taken for 1 epoch: 37.189645528793335 secs\n",
      "\n",
      "Epoch 106 Batch 0 Loss 0.2485 Accuracy 0.4120\n",
      "Epoch 106 Batch 50 Loss 0.2562 Accuracy 0.4378\n",
      "Epoch 106 Batch 100 Loss 0.2595 Accuracy 0.4374\n",
      "Epoch 106 Batch 150 Loss 0.2661 Accuracy 0.4367\n",
      "Epoch 106 Batch 200 Loss 0.2689 Accuracy 0.4348\n",
      "Epoch 106 Batch 250 Loss 0.2701 Accuracy 0.4349\n",
      "Epoch 106 Batch 300 Loss 0.2719 Accuracy 0.4352\n",
      "Epoch 106 Batch 350 Loss 0.2737 Accuracy 0.4345\n",
      "Epoch 106 Batch 400 Loss 0.2757 Accuracy 0.4336\n",
      "Epoch 106 Batch 450 Loss 0.2783 Accuracy 0.4333\n",
      "Epoch 106 Batch 500 Loss 0.2806 Accuracy 0.4333\n",
      "Epoch 106 Batch 550 Loss 0.2821 Accuracy 0.4330\n",
      "Epoch 106 Batch 600 Loss 0.2845 Accuracy 0.4331\n",
      "Epoch 106 Batch 650 Loss 0.2872 Accuracy 0.4330\n",
      "Epoch 106 Batch 700 Loss 0.2890 Accuracy 0.4329\n",
      "Epoch 106 Loss 0.2892 Accuracy 0.4329\n",
      "Time taken for 1 epoch: 36.560935974121094 secs\n",
      "\n",
      "Epoch 107 Batch 0 Loss 0.2501 Accuracy 0.4658\n",
      "Epoch 107 Batch 50 Loss 0.2510 Accuracy 0.4399\n",
      "Epoch 107 Batch 100 Loss 0.2530 Accuracy 0.4373\n",
      "Epoch 107 Batch 150 Loss 0.2564 Accuracy 0.4378\n",
      "Epoch 107 Batch 200 Loss 0.2601 Accuracy 0.4356\n",
      "Epoch 107 Batch 250 Loss 0.2634 Accuracy 0.4342\n",
      "Epoch 107 Batch 300 Loss 0.2662 Accuracy 0.4347\n",
      "Epoch 107 Batch 350 Loss 0.2687 Accuracy 0.4345\n",
      "Epoch 107 Batch 400 Loss 0.2713 Accuracy 0.4339\n",
      "Epoch 107 Batch 450 Loss 0.2740 Accuracy 0.4330\n",
      "Epoch 107 Batch 500 Loss 0.2766 Accuracy 0.4331\n",
      "Epoch 107 Batch 550 Loss 0.2789 Accuracy 0.4334\n",
      "Epoch 107 Batch 600 Loss 0.2809 Accuracy 0.4329\n",
      "Epoch 107 Batch 650 Loss 0.2833 Accuracy 0.4327\n",
      "Epoch 107 Batch 700 Loss 0.2856 Accuracy 0.4332\n",
      "Epoch 107 Loss 0.2857 Accuracy 0.4333\n",
      "Time taken for 1 epoch: 36.8852162361145 secs\n",
      "\n",
      "Epoch 108 Batch 0 Loss 0.2291 Accuracy 0.4669\n",
      "Epoch 108 Batch 50 Loss 0.2512 Accuracy 0.4325\n",
      "Epoch 108 Batch 100 Loss 0.2556 Accuracy 0.4378\n",
      "Epoch 108 Batch 150 Loss 0.2616 Accuracy 0.4364\n",
      "Epoch 108 Batch 200 Loss 0.2623 Accuracy 0.4367\n",
      "Epoch 108 Batch 250 Loss 0.2638 Accuracy 0.4361\n",
      "Epoch 108 Batch 300 Loss 0.2668 Accuracy 0.4358\n",
      "Epoch 108 Batch 350 Loss 0.2685 Accuracy 0.4357\n",
      "Epoch 108 Batch 400 Loss 0.2714 Accuracy 0.4352\n",
      "Epoch 108 Batch 450 Loss 0.2742 Accuracy 0.4352\n",
      "Epoch 108 Batch 500 Loss 0.2763 Accuracy 0.4350\n",
      "Epoch 108 Batch 550 Loss 0.2782 Accuracy 0.4341\n",
      "Epoch 108 Batch 600 Loss 0.2801 Accuracy 0.4340\n",
      "Epoch 108 Batch 650 Loss 0.2823 Accuracy 0.4334\n",
      "Epoch 108 Batch 700 Loss 0.2850 Accuracy 0.4331\n",
      "Epoch 108 Loss 0.2850 Accuracy 0.4332\n",
      "Time taken for 1 epoch: 36.3728244304657 secs\n",
      "\n",
      "Epoch 109 Batch 0 Loss 0.2586 Accuracy 0.4856\n",
      "Epoch 109 Batch 50 Loss 0.2507 Accuracy 0.4412\n",
      "Epoch 109 Batch 100 Loss 0.2585 Accuracy 0.4382\n",
      "Epoch 109 Batch 150 Loss 0.2617 Accuracy 0.4374\n",
      "Epoch 109 Batch 200 Loss 0.2634 Accuracy 0.4371\n",
      "Epoch 109 Batch 250 Loss 0.2658 Accuracy 0.4348\n",
      "Epoch 109 Batch 300 Loss 0.2676 Accuracy 0.4349\n",
      "Epoch 109 Batch 350 Loss 0.2699 Accuracy 0.4345\n",
      "Epoch 109 Batch 400 Loss 0.2717 Accuracy 0.4340\n",
      "Epoch 109 Batch 450 Loss 0.2741 Accuracy 0.4344\n",
      "Epoch 109 Batch 500 Loss 0.2770 Accuracy 0.4338\n",
      "Epoch 109 Batch 550 Loss 0.2790 Accuracy 0.4337\n",
      "Epoch 109 Batch 600 Loss 0.2810 Accuracy 0.4338\n",
      "Epoch 109 Batch 650 Loss 0.2827 Accuracy 0.4332\n",
      "Epoch 109 Batch 700 Loss 0.2848 Accuracy 0.4330\n",
      "Epoch 109 Loss 0.2848 Accuracy 0.4330\n",
      "Time taken for 1 epoch: 36.17637658119202 secs\n",
      "\n",
      "Epoch 110 Batch 0 Loss 0.2525 Accuracy 0.4338\n",
      "Epoch 110 Batch 50 Loss 0.2512 Accuracy 0.4440\n",
      "Epoch 110 Batch 100 Loss 0.2543 Accuracy 0.4426\n",
      "Epoch 110 Batch 150 Loss 0.2574 Accuracy 0.4374\n",
      "Epoch 110 Batch 200 Loss 0.2602 Accuracy 0.4364\n",
      "Epoch 110 Batch 250 Loss 0.2619 Accuracy 0.4370\n",
      "Epoch 110 Batch 300 Loss 0.2651 Accuracy 0.4368\n",
      "Epoch 110 Batch 350 Loss 0.2688 Accuracy 0.4357\n",
      "Epoch 110 Batch 400 Loss 0.2710 Accuracy 0.4359\n",
      "Epoch 110 Batch 450 Loss 0.2729 Accuracy 0.4362\n",
      "Epoch 110 Batch 500 Loss 0.2745 Accuracy 0.4359\n",
      "Epoch 110 Batch 550 Loss 0.2765 Accuracy 0.4357\n",
      "Epoch 110 Batch 600 Loss 0.2789 Accuracy 0.4344\n",
      "Epoch 110 Batch 650 Loss 0.2816 Accuracy 0.4340\n",
      "Epoch 110 Batch 700 Loss 0.2831 Accuracy 0.4338\n",
      "Saving checkpoint for epoch 110 at ./checkpoints/train/ckpt-34\n",
      "Epoch 110 Loss 0.2834 Accuracy 0.4338\n",
      "Time taken for 1 epoch: 36.52182698249817 secs\n",
      "\n",
      "Epoch 111 Batch 0 Loss 0.2354 Accuracy 0.4514\n",
      "Epoch 111 Batch 50 Loss 0.2547 Accuracy 0.4365\n",
      "Epoch 111 Batch 100 Loss 0.2556 Accuracy 0.4353\n",
      "Epoch 111 Batch 150 Loss 0.2573 Accuracy 0.4355\n",
      "Epoch 111 Batch 200 Loss 0.2600 Accuracy 0.4348\n",
      "Epoch 111 Batch 250 Loss 0.2634 Accuracy 0.4347\n",
      "Epoch 111 Batch 300 Loss 0.2655 Accuracy 0.4354\n",
      "Epoch 111 Batch 350 Loss 0.2679 Accuracy 0.4350\n",
      "Epoch 111 Batch 400 Loss 0.2702 Accuracy 0.4345\n",
      "Epoch 111 Batch 450 Loss 0.2723 Accuracy 0.4344\n",
      "Epoch 111 Batch 500 Loss 0.2743 Accuracy 0.4341\n",
      "Epoch 111 Batch 550 Loss 0.2764 Accuracy 0.4337\n",
      "Epoch 111 Batch 600 Loss 0.2789 Accuracy 0.4339\n",
      "Epoch 111 Batch 650 Loss 0.2815 Accuracy 0.4337\n",
      "Epoch 111 Batch 700 Loss 0.2835 Accuracy 0.4330\n",
      "Epoch 111 Loss 0.2836 Accuracy 0.4331\n",
      "Time taken for 1 epoch: 36.00977182388306 secs\n",
      "\n",
      "Epoch 112 Batch 0 Loss 0.2673 Accuracy 0.4293\n",
      "Epoch 112 Batch 50 Loss 0.2486 Accuracy 0.4351\n",
      "Epoch 112 Batch 100 Loss 0.2533 Accuracy 0.4364\n",
      "Epoch 112 Batch 150 Loss 0.2580 Accuracy 0.4349\n",
      "Epoch 112 Batch 200 Loss 0.2608 Accuracy 0.4355\n",
      "Epoch 112 Batch 250 Loss 0.2631 Accuracy 0.4362\n",
      "Epoch 112 Batch 300 Loss 0.2655 Accuracy 0.4361\n",
      "Epoch 112 Batch 350 Loss 0.2668 Accuracy 0.4367\n",
      "Epoch 112 Batch 400 Loss 0.2682 Accuracy 0.4361\n",
      "Epoch 112 Batch 450 Loss 0.2703 Accuracy 0.4355\n",
      "Epoch 112 Batch 500 Loss 0.2727 Accuracy 0.4352\n",
      "Epoch 112 Batch 550 Loss 0.2753 Accuracy 0.4345\n",
      "Epoch 112 Batch 600 Loss 0.2775 Accuracy 0.4338\n",
      "Epoch 112 Batch 650 Loss 0.2799 Accuracy 0.4334\n",
      "Epoch 112 Batch 700 Loss 0.2820 Accuracy 0.4332\n",
      "Epoch 112 Loss 0.2821 Accuracy 0.4333\n",
      "Time taken for 1 epoch: 35.6546733379364 secs\n",
      "\n",
      "Epoch 113 Batch 0 Loss 0.2667 Accuracy 0.4046\n",
      "Epoch 113 Batch 50 Loss 0.2516 Accuracy 0.4370\n",
      "Epoch 113 Batch 100 Loss 0.2554 Accuracy 0.4362\n",
      "Epoch 113 Batch 150 Loss 0.2562 Accuracy 0.4349\n",
      "Epoch 113 Batch 200 Loss 0.2586 Accuracy 0.4351\n",
      "Epoch 113 Batch 250 Loss 0.2601 Accuracy 0.4354\n",
      "Epoch 113 Batch 300 Loss 0.2626 Accuracy 0.4352\n",
      "Epoch 113 Batch 350 Loss 0.2650 Accuracy 0.4354\n",
      "Epoch 113 Batch 400 Loss 0.2676 Accuracy 0.4346\n",
      "Epoch 113 Batch 450 Loss 0.2700 Accuracy 0.4339\n",
      "Epoch 113 Batch 500 Loss 0.2722 Accuracy 0.4340\n",
      "Epoch 113 Batch 550 Loss 0.2741 Accuracy 0.4334\n",
      "Epoch 113 Batch 600 Loss 0.2758 Accuracy 0.4336\n",
      "Epoch 113 Batch 650 Loss 0.2782 Accuracy 0.4339\n",
      "Epoch 113 Batch 700 Loss 0.2806 Accuracy 0.4337\n",
      "Epoch 113 Loss 0.2807 Accuracy 0.4337\n",
      "Time taken for 1 epoch: 35.99691915512085 secs\n",
      "\n",
      "Epoch 114 Batch 0 Loss 0.2507 Accuracy 0.4611\n",
      "Epoch 114 Batch 50 Loss 0.2501 Accuracy 0.4440\n",
      "Epoch 114 Batch 100 Loss 0.2566 Accuracy 0.4395\n",
      "Epoch 114 Batch 150 Loss 0.2574 Accuracy 0.4369\n",
      "Epoch 114 Batch 200 Loss 0.2610 Accuracy 0.4370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114 Batch 250 Loss 0.2625 Accuracy 0.4363\n",
      "Epoch 114 Batch 300 Loss 0.2653 Accuracy 0.4358\n",
      "Epoch 114 Batch 350 Loss 0.2664 Accuracy 0.4356\n",
      "Epoch 114 Batch 400 Loss 0.2685 Accuracy 0.4362\n",
      "Epoch 114 Batch 450 Loss 0.2710 Accuracy 0.4359\n",
      "Epoch 114 Batch 500 Loss 0.2732 Accuracy 0.4350\n",
      "Epoch 114 Batch 550 Loss 0.2747 Accuracy 0.4345\n",
      "Epoch 114 Batch 600 Loss 0.2768 Accuracy 0.4346\n",
      "Epoch 114 Batch 650 Loss 0.2791 Accuracy 0.4345\n",
      "Epoch 114 Batch 700 Loss 0.2808 Accuracy 0.4343\n",
      "Epoch 114 Loss 0.2808 Accuracy 0.4343\n",
      "Time taken for 1 epoch: 35.241804361343384 secs\n",
      "\n",
      "Epoch 115 Batch 0 Loss 0.2381 Accuracy 0.4395\n",
      "Epoch 115 Batch 50 Loss 0.2496 Accuracy 0.4297\n",
      "Epoch 115 Batch 100 Loss 0.2494 Accuracy 0.4323\n",
      "Epoch 115 Batch 150 Loss 0.2550 Accuracy 0.4342\n",
      "Epoch 115 Batch 200 Loss 0.2561 Accuracy 0.4344\n",
      "Epoch 115 Batch 250 Loss 0.2600 Accuracy 0.4342\n",
      "Epoch 115 Batch 300 Loss 0.2609 Accuracy 0.4353\n",
      "Epoch 115 Batch 350 Loss 0.2638 Accuracy 0.4354\n",
      "Epoch 115 Batch 400 Loss 0.2657 Accuracy 0.4348\n",
      "Epoch 115 Batch 450 Loss 0.2675 Accuracy 0.4345\n",
      "Epoch 115 Batch 500 Loss 0.2694 Accuracy 0.4347\n",
      "Epoch 115 Batch 550 Loss 0.2711 Accuracy 0.4347\n",
      "Epoch 115 Batch 600 Loss 0.2731 Accuracy 0.4346\n",
      "Epoch 115 Batch 650 Loss 0.2753 Accuracy 0.4340\n",
      "Epoch 115 Batch 700 Loss 0.2772 Accuracy 0.4342\n",
      "Saving checkpoint for epoch 115 at ./checkpoints/train/ckpt-35\n",
      "Epoch 115 Loss 0.2773 Accuracy 0.4343\n",
      "Time taken for 1 epoch: 35.398555517196655 secs\n",
      "\n",
      "Epoch 116 Batch 0 Loss 0.2217 Accuracy 0.4223\n",
      "Epoch 116 Batch 50 Loss 0.2481 Accuracy 0.4329\n",
      "Epoch 116 Batch 100 Loss 0.2489 Accuracy 0.4337\n",
      "Epoch 116 Batch 150 Loss 0.2528 Accuracy 0.4364\n",
      "Epoch 116 Batch 200 Loss 0.2562 Accuracy 0.4352\n",
      "Epoch 116 Batch 250 Loss 0.2588 Accuracy 0.4352\n",
      "Epoch 116 Batch 300 Loss 0.2619 Accuracy 0.4347\n",
      "Epoch 116 Batch 350 Loss 0.2633 Accuracy 0.4346\n",
      "Epoch 116 Batch 400 Loss 0.2658 Accuracy 0.4352\n",
      "Epoch 116 Batch 450 Loss 0.2684 Accuracy 0.4359\n",
      "Epoch 116 Batch 500 Loss 0.2700 Accuracy 0.4358\n",
      "Epoch 116 Batch 550 Loss 0.2722 Accuracy 0.4353\n",
      "Epoch 116 Batch 600 Loss 0.2746 Accuracy 0.4350\n",
      "Epoch 116 Batch 650 Loss 0.2770 Accuracy 0.4344\n",
      "Epoch 116 Batch 700 Loss 0.2791 Accuracy 0.4338\n",
      "Epoch 116 Loss 0.2791 Accuracy 0.4339\n",
      "Time taken for 1 epoch: 35.24377751350403 secs\n",
      "\n",
      "Epoch 117 Batch 0 Loss 0.2511 Accuracy 0.4275\n",
      "Epoch 117 Batch 50 Loss 0.2459 Accuracy 0.4395\n",
      "Epoch 117 Batch 100 Loss 0.2466 Accuracy 0.4362\n",
      "Epoch 117 Batch 150 Loss 0.2516 Accuracy 0.4356\n",
      "Epoch 117 Batch 200 Loss 0.2563 Accuracy 0.4367\n",
      "Epoch 117 Batch 250 Loss 0.2583 Accuracy 0.4358\n",
      "Epoch 117 Batch 300 Loss 0.2610 Accuracy 0.4358\n",
      "Epoch 117 Batch 350 Loss 0.2631 Accuracy 0.4355\n",
      "Epoch 117 Batch 400 Loss 0.2649 Accuracy 0.4351\n",
      "Epoch 117 Batch 450 Loss 0.2669 Accuracy 0.4342\n",
      "Epoch 117 Batch 500 Loss 0.2687 Accuracy 0.4350\n",
      "Epoch 117 Batch 550 Loss 0.2709 Accuracy 0.4351\n",
      "Epoch 117 Batch 600 Loss 0.2731 Accuracy 0.4349\n",
      "Epoch 117 Batch 650 Loss 0.2754 Accuracy 0.4347\n",
      "Epoch 117 Batch 700 Loss 0.2778 Accuracy 0.4340\n",
      "Epoch 117 Loss 0.2779 Accuracy 0.4340\n",
      "Time taken for 1 epoch: 35.20745849609375 secs\n",
      "\n",
      "Epoch 118 Batch 0 Loss 0.2348 Accuracy 0.4341\n",
      "Epoch 118 Batch 50 Loss 0.2449 Accuracy 0.4284\n",
      "Epoch 118 Batch 100 Loss 0.2521 Accuracy 0.4339\n",
      "Epoch 118 Batch 150 Loss 0.2562 Accuracy 0.4334\n",
      "Epoch 118 Batch 200 Loss 0.2567 Accuracy 0.4335\n",
      "Epoch 118 Batch 250 Loss 0.2578 Accuracy 0.4351\n",
      "Epoch 118 Batch 300 Loss 0.2603 Accuracy 0.4352\n",
      "Epoch 118 Batch 350 Loss 0.2628 Accuracy 0.4347\n",
      "Epoch 118 Batch 400 Loss 0.2649 Accuracy 0.4360\n",
      "Epoch 118 Batch 450 Loss 0.2672 Accuracy 0.4355\n",
      "Epoch 118 Batch 500 Loss 0.2693 Accuracy 0.4353\n",
      "Epoch 118 Batch 550 Loss 0.2713 Accuracy 0.4348\n",
      "Epoch 118 Batch 600 Loss 0.2738 Accuracy 0.4347\n",
      "Epoch 118 Batch 650 Loss 0.2762 Accuracy 0.4349\n",
      "Epoch 118 Batch 700 Loss 0.2783 Accuracy 0.4343\n",
      "Epoch 118 Loss 0.2784 Accuracy 0.4344\n",
      "Time taken for 1 epoch: 35.2008101940155 secs\n",
      "\n",
      "Epoch 119 Batch 0 Loss 0.2394 Accuracy 0.4362\n",
      "Epoch 119 Batch 50 Loss 0.2477 Accuracy 0.4372\n",
      "Epoch 119 Batch 100 Loss 0.2480 Accuracy 0.4348\n",
      "Epoch 119 Batch 150 Loss 0.2498 Accuracy 0.4377\n",
      "Epoch 119 Batch 200 Loss 0.2531 Accuracy 0.4370\n",
      "Epoch 119 Batch 250 Loss 0.2551 Accuracy 0.4360\n",
      "Epoch 119 Batch 300 Loss 0.2592 Accuracy 0.4351\n",
      "Epoch 119 Batch 350 Loss 0.2619 Accuracy 0.4356\n",
      "Epoch 119 Batch 400 Loss 0.2640 Accuracy 0.4357\n",
      "Epoch 119 Batch 450 Loss 0.2653 Accuracy 0.4354\n",
      "Epoch 119 Batch 500 Loss 0.2672 Accuracy 0.4350\n",
      "Epoch 119 Batch 550 Loss 0.2693 Accuracy 0.4349\n",
      "Epoch 119 Batch 600 Loss 0.2710 Accuracy 0.4344\n",
      "Epoch 119 Batch 650 Loss 0.2728 Accuracy 0.4344\n",
      "Epoch 119 Batch 700 Loss 0.2756 Accuracy 0.4343\n",
      "Epoch 119 Loss 0.2758 Accuracy 0.4343\n",
      "Time taken for 1 epoch: 35.19543170928955 secs\n",
      "\n",
      "Epoch 120 Batch 0 Loss 0.2802 Accuracy 0.4211\n",
      "Epoch 120 Batch 50 Loss 0.2484 Accuracy 0.4420\n",
      "Epoch 120 Batch 100 Loss 0.2516 Accuracy 0.4404\n",
      "Epoch 120 Batch 150 Loss 0.2534 Accuracy 0.4393\n",
      "Epoch 120 Batch 200 Loss 0.2551 Accuracy 0.4389\n",
      "Epoch 120 Batch 250 Loss 0.2574 Accuracy 0.4381\n",
      "Epoch 120 Batch 300 Loss 0.2592 Accuracy 0.4379\n",
      "Epoch 120 Batch 350 Loss 0.2613 Accuracy 0.4369\n",
      "Epoch 120 Batch 400 Loss 0.2632 Accuracy 0.4365\n",
      "Epoch 120 Batch 450 Loss 0.2652 Accuracy 0.4358\n",
      "Epoch 120 Batch 500 Loss 0.2666 Accuracy 0.4358\n",
      "Epoch 120 Batch 550 Loss 0.2685 Accuracy 0.4355\n",
      "Epoch 120 Batch 600 Loss 0.2710 Accuracy 0.4350\n",
      "Epoch 120 Batch 650 Loss 0.2726 Accuracy 0.4352\n",
      "Epoch 120 Batch 700 Loss 0.2747 Accuracy 0.4347\n",
      "Saving checkpoint for epoch 120 at ./checkpoints/train/ckpt-36\n",
      "Epoch 120 Loss 0.2748 Accuracy 0.4347\n",
      "Time taken for 1 epoch: 35.332502365112305 secs\n",
      "\n",
      "Epoch 121 Batch 0 Loss 0.2549 Accuracy 0.3984\n",
      "Epoch 121 Batch 50 Loss 0.2469 Accuracy 0.4315\n",
      "Epoch 121 Batch 100 Loss 0.2510 Accuracy 0.4306\n",
      "Epoch 121 Batch 150 Loss 0.2526 Accuracy 0.4327\n",
      "Epoch 121 Batch 200 Loss 0.2540 Accuracy 0.4340\n",
      "Epoch 121 Batch 250 Loss 0.2565 Accuracy 0.4338\n",
      "Epoch 121 Batch 300 Loss 0.2585 Accuracy 0.4339\n",
      "Epoch 121 Batch 350 Loss 0.2602 Accuracy 0.4350\n",
      "Epoch 121 Batch 400 Loss 0.2620 Accuracy 0.4356\n",
      "Epoch 121 Batch 450 Loss 0.2638 Accuracy 0.4355\n",
      "Epoch 121 Batch 500 Loss 0.2652 Accuracy 0.4353\n",
      "Epoch 121 Batch 550 Loss 0.2682 Accuracy 0.4352\n",
      "Epoch 121 Batch 600 Loss 0.2702 Accuracy 0.4346\n",
      "Epoch 121 Batch 650 Loss 0.2724 Accuracy 0.4346\n",
      "Epoch 121 Batch 700 Loss 0.2746 Accuracy 0.4341\n",
      "Epoch 121 Loss 0.2747 Accuracy 0.4340\n",
      "Time taken for 1 epoch: 35.1871292591095 secs\n",
      "\n",
      "Epoch 122 Batch 0 Loss 0.2892 Accuracy 0.4254\n",
      "Epoch 122 Batch 50 Loss 0.2462 Accuracy 0.4357\n",
      "Epoch 122 Batch 100 Loss 0.2490 Accuracy 0.4357\n",
      "Epoch 122 Batch 150 Loss 0.2502 Accuracy 0.4338\n",
      "Epoch 122 Batch 200 Loss 0.2521 Accuracy 0.4343\n",
      "Epoch 122 Batch 250 Loss 0.2544 Accuracy 0.4357\n",
      "Epoch 122 Batch 300 Loss 0.2561 Accuracy 0.4357\n",
      "Epoch 122 Batch 350 Loss 0.2582 Accuracy 0.4361\n",
      "Epoch 122 Batch 400 Loss 0.2601 Accuracy 0.4360\n",
      "Epoch 122 Batch 450 Loss 0.2611 Accuracy 0.4357\n",
      "Epoch 122 Batch 500 Loss 0.2636 Accuracy 0.4352\n",
      "Epoch 122 Batch 550 Loss 0.2657 Accuracy 0.4353\n",
      "Epoch 122 Batch 600 Loss 0.2677 Accuracy 0.4348\n",
      "Epoch 122 Batch 650 Loss 0.2702 Accuracy 0.4340\n",
      "Epoch 122 Batch 700 Loss 0.2726 Accuracy 0.4339\n",
      "Epoch 122 Loss 0.2726 Accuracy 0.4340\n",
      "Time taken for 1 epoch: 35.19738006591797 secs\n",
      "\n",
      "Epoch 123 Batch 0 Loss 0.2405 Accuracy 0.4727\n",
      "Epoch 123 Batch 50 Loss 0.2424 Accuracy 0.4395\n",
      "Epoch 123 Batch 100 Loss 0.2453 Accuracy 0.4397\n",
      "Epoch 123 Batch 150 Loss 0.2482 Accuracy 0.4410\n",
      "Epoch 123 Batch 200 Loss 0.2507 Accuracy 0.4385\n",
      "Epoch 123 Batch 250 Loss 0.2539 Accuracy 0.4369\n",
      "Epoch 123 Batch 300 Loss 0.2567 Accuracy 0.4354\n",
      "Epoch 123 Batch 350 Loss 0.2580 Accuracy 0.4356\n",
      "Epoch 123 Batch 400 Loss 0.2604 Accuracy 0.4350\n",
      "Epoch 123 Batch 450 Loss 0.2624 Accuracy 0.4352\n",
      "Epoch 123 Batch 500 Loss 0.2646 Accuracy 0.4343\n",
      "Epoch 123 Batch 550 Loss 0.2665 Accuracy 0.4343\n",
      "Epoch 123 Batch 600 Loss 0.2686 Accuracy 0.4343\n",
      "Epoch 123 Batch 650 Loss 0.2709 Accuracy 0.4343\n",
      "Epoch 123 Batch 700 Loss 0.2725 Accuracy 0.4343\n",
      "Epoch 123 Loss 0.2725 Accuracy 0.4343\n",
      "Time taken for 1 epoch: 35.16838884353638 secs\n",
      "\n",
      "Epoch 124 Batch 0 Loss 0.2625 Accuracy 0.4633\n",
      "Epoch 124 Batch 50 Loss 0.2461 Accuracy 0.4408\n",
      "Epoch 124 Batch 100 Loss 0.2456 Accuracy 0.4376\n",
      "Epoch 124 Batch 150 Loss 0.2487 Accuracy 0.4391\n",
      "Epoch 124 Batch 200 Loss 0.2508 Accuracy 0.4364\n",
      "Epoch 124 Batch 250 Loss 0.2529 Accuracy 0.4373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124 Batch 300 Loss 0.2552 Accuracy 0.4377\n",
      "Epoch 124 Batch 350 Loss 0.2570 Accuracy 0.4376\n",
      "Epoch 124 Batch 400 Loss 0.2588 Accuracy 0.4376\n",
      "Epoch 124 Batch 450 Loss 0.2605 Accuracy 0.4370\n",
      "Epoch 124 Batch 500 Loss 0.2626 Accuracy 0.4369\n",
      "Epoch 124 Batch 550 Loss 0.2650 Accuracy 0.4364\n",
      "Epoch 124 Batch 600 Loss 0.2669 Accuracy 0.4363\n",
      "Epoch 124 Batch 650 Loss 0.2695 Accuracy 0.4358\n",
      "Epoch 124 Batch 700 Loss 0.2718 Accuracy 0.4353\n",
      "Epoch 124 Loss 0.2718 Accuracy 0.4353\n",
      "Time taken for 1 epoch: 35.16764259338379 secs\n",
      "\n",
      "Epoch 125 Batch 0 Loss 0.2273 Accuracy 0.4016\n",
      "Epoch 125 Batch 50 Loss 0.2421 Accuracy 0.4356\n",
      "Epoch 125 Batch 100 Loss 0.2426 Accuracy 0.4378\n",
      "Epoch 125 Batch 150 Loss 0.2460 Accuracy 0.4376\n",
      "Epoch 125 Batch 200 Loss 0.2493 Accuracy 0.4366\n",
      "Epoch 125 Batch 250 Loss 0.2525 Accuracy 0.4365\n",
      "Epoch 125 Batch 300 Loss 0.2545 Accuracy 0.4369\n",
      "Epoch 125 Batch 350 Loss 0.2570 Accuracy 0.4368\n",
      "Epoch 125 Batch 400 Loss 0.2577 Accuracy 0.4376\n",
      "Epoch 125 Batch 450 Loss 0.2605 Accuracy 0.4366\n",
      "Epoch 125 Batch 500 Loss 0.2626 Accuracy 0.4358\n",
      "Epoch 125 Batch 550 Loss 0.2648 Accuracy 0.4356\n",
      "Epoch 125 Batch 600 Loss 0.2672 Accuracy 0.4356\n",
      "Epoch 125 Batch 650 Loss 0.2692 Accuracy 0.4349\n",
      "Epoch 125 Batch 700 Loss 0.2713 Accuracy 0.4346\n",
      "Saving checkpoint for epoch 125 at ./checkpoints/train/ckpt-37\n",
      "Epoch 125 Loss 0.2714 Accuracy 0.4346\n",
      "Time taken for 1 epoch: 35.345152854919434 secs\n",
      "\n",
      "Epoch 126 Batch 0 Loss 0.2118 Accuracy 0.4415\n",
      "Epoch 126 Batch 50 Loss 0.2400 Accuracy 0.4321\n",
      "Epoch 126 Batch 100 Loss 0.2452 Accuracy 0.4307\n",
      "Epoch 126 Batch 150 Loss 0.2467 Accuracy 0.4351\n",
      "Epoch 126 Batch 200 Loss 0.2492 Accuracy 0.4337\n",
      "Epoch 126 Batch 250 Loss 0.2504 Accuracy 0.4351\n",
      "Epoch 126 Batch 300 Loss 0.2528 Accuracy 0.4358\n",
      "Epoch 126 Batch 350 Loss 0.2545 Accuracy 0.4359\n",
      "Epoch 126 Batch 400 Loss 0.2563 Accuracy 0.4359\n",
      "Epoch 126 Batch 450 Loss 0.2583 Accuracy 0.4358\n",
      "Epoch 126 Batch 500 Loss 0.2605 Accuracy 0.4356\n",
      "Epoch 126 Batch 550 Loss 0.2626 Accuracy 0.4355\n",
      "Epoch 126 Batch 600 Loss 0.2646 Accuracy 0.4354\n",
      "Epoch 126 Batch 650 Loss 0.2668 Accuracy 0.4353\n",
      "Epoch 126 Batch 700 Loss 0.2690 Accuracy 0.4353\n",
      "Epoch 126 Loss 0.2692 Accuracy 0.4352\n",
      "Time taken for 1 epoch: 35.25312805175781 secs\n",
      "\n",
      "Epoch 127 Batch 0 Loss 0.2440 Accuracy 0.3986\n",
      "Epoch 127 Batch 50 Loss 0.2407 Accuracy 0.4381\n",
      "Epoch 127 Batch 100 Loss 0.2452 Accuracy 0.4370\n",
      "Epoch 127 Batch 150 Loss 0.2468 Accuracy 0.4391\n",
      "Epoch 127 Batch 200 Loss 0.2500 Accuracy 0.4379\n",
      "Epoch 127 Batch 250 Loss 0.2523 Accuracy 0.4374\n",
      "Epoch 127 Batch 300 Loss 0.2528 Accuracy 0.4369\n",
      "Epoch 127 Batch 350 Loss 0.2547 Accuracy 0.4373\n",
      "Epoch 127 Batch 400 Loss 0.2562 Accuracy 0.4370\n",
      "Epoch 127 Batch 450 Loss 0.2590 Accuracy 0.4367\n",
      "Epoch 127 Batch 500 Loss 0.2607 Accuracy 0.4369\n",
      "Epoch 127 Batch 550 Loss 0.2618 Accuracy 0.4365\n",
      "Epoch 127 Batch 600 Loss 0.2643 Accuracy 0.4360\n",
      "Epoch 127 Batch 650 Loss 0.2668 Accuracy 0.4358\n",
      "Epoch 127 Batch 700 Loss 0.2686 Accuracy 0.4359\n",
      "Epoch 127 Loss 0.2688 Accuracy 0.4359\n",
      "Time taken for 1 epoch: 35.18027925491333 secs\n",
      "\n",
      "Epoch 128 Batch 0 Loss 0.2243 Accuracy 0.4337\n",
      "Epoch 128 Batch 50 Loss 0.2419 Accuracy 0.4359\n",
      "Epoch 128 Batch 100 Loss 0.2422 Accuracy 0.4400\n",
      "Epoch 128 Batch 150 Loss 0.2443 Accuracy 0.4393\n",
      "Epoch 128 Batch 200 Loss 0.2462 Accuracy 0.4383\n",
      "Epoch 128 Batch 250 Loss 0.2486 Accuracy 0.4379\n",
      "Epoch 128 Batch 300 Loss 0.2502 Accuracy 0.4377\n",
      "Epoch 128 Batch 350 Loss 0.2517 Accuracy 0.4377\n",
      "Epoch 128 Batch 400 Loss 0.2544 Accuracy 0.4369\n",
      "Epoch 128 Batch 450 Loss 0.2562 Accuracy 0.4368\n",
      "Epoch 128 Batch 500 Loss 0.2590 Accuracy 0.4363\n",
      "Epoch 128 Batch 550 Loss 0.2611 Accuracy 0.4368\n",
      "Epoch 128 Batch 600 Loss 0.2631 Accuracy 0.4365\n",
      "Epoch 128 Batch 650 Loss 0.2651 Accuracy 0.4360\n",
      "Epoch 128 Batch 700 Loss 0.2677 Accuracy 0.4360\n",
      "Epoch 128 Loss 0.2677 Accuracy 0.4360\n",
      "Time taken for 1 epoch: 35.217556953430176 secs\n",
      "\n",
      "Epoch 129 Batch 0 Loss 0.2268 Accuracy 0.4248\n",
      "Epoch 129 Batch 50 Loss 0.2402 Accuracy 0.4431\n",
      "Epoch 129 Batch 100 Loss 0.2422 Accuracy 0.4409\n",
      "Epoch 129 Batch 150 Loss 0.2428 Accuracy 0.4402\n",
      "Epoch 129 Batch 200 Loss 0.2476 Accuracy 0.4398\n",
      "Epoch 129 Batch 250 Loss 0.2494 Accuracy 0.4403\n",
      "Epoch 129 Batch 300 Loss 0.2511 Accuracy 0.4400\n",
      "Epoch 129 Batch 350 Loss 0.2535 Accuracy 0.4386\n",
      "Epoch 129 Batch 400 Loss 0.2548 Accuracy 0.4378\n",
      "Epoch 129 Batch 450 Loss 0.2567 Accuracy 0.4369\n",
      "Epoch 129 Batch 500 Loss 0.2586 Accuracy 0.4364\n",
      "Epoch 129 Batch 550 Loss 0.2609 Accuracy 0.4366\n",
      "Epoch 129 Batch 600 Loss 0.2632 Accuracy 0.4364\n",
      "Epoch 129 Batch 650 Loss 0.2652 Accuracy 0.4359\n",
      "Epoch 129 Batch 700 Loss 0.2673 Accuracy 0.4357\n",
      "Epoch 129 Loss 0.2674 Accuracy 0.4356\n",
      "Time taken for 1 epoch: 35.20446157455444 secs\n",
      "\n",
      "Epoch 130 Batch 0 Loss 0.2068 Accuracy 0.4426\n",
      "Epoch 130 Batch 50 Loss 0.2406 Accuracy 0.4351\n",
      "Epoch 130 Batch 100 Loss 0.2415 Accuracy 0.4370\n",
      "Epoch 130 Batch 150 Loss 0.2446 Accuracy 0.4377\n",
      "Epoch 130 Batch 200 Loss 0.2480 Accuracy 0.4363\n",
      "Epoch 130 Batch 250 Loss 0.2501 Accuracy 0.4362\n",
      "Epoch 130 Batch 300 Loss 0.2519 Accuracy 0.4366\n",
      "Epoch 130 Batch 350 Loss 0.2534 Accuracy 0.4365\n",
      "Epoch 130 Batch 400 Loss 0.2550 Accuracy 0.4369\n",
      "Epoch 130 Batch 450 Loss 0.2566 Accuracy 0.4369\n",
      "Epoch 130 Batch 500 Loss 0.2587 Accuracy 0.4368\n",
      "Epoch 130 Batch 550 Loss 0.2608 Accuracy 0.4363\n",
      "Epoch 130 Batch 600 Loss 0.2632 Accuracy 0.4363\n",
      "Epoch 130 Batch 650 Loss 0.2651 Accuracy 0.4358\n",
      "Epoch 130 Batch 700 Loss 0.2672 Accuracy 0.4352\n",
      "Saving checkpoint for epoch 130 at ./checkpoints/train/ckpt-38\n",
      "Epoch 130 Loss 0.2672 Accuracy 0.4351\n",
      "Time taken for 1 epoch: 35.328930616378784 secs\n",
      "\n",
      "Epoch 131 Batch 0 Loss 0.2086 Accuracy 0.4554\n",
      "Epoch 131 Batch 50 Loss 0.2443 Accuracy 0.4440\n",
      "Epoch 131 Batch 100 Loss 0.2436 Accuracy 0.4379\n",
      "Epoch 131 Batch 150 Loss 0.2459 Accuracy 0.4366\n",
      "Epoch 131 Batch 200 Loss 0.2484 Accuracy 0.4349\n",
      "Epoch 131 Batch 250 Loss 0.2506 Accuracy 0.4356\n",
      "Epoch 131 Batch 300 Loss 0.2522 Accuracy 0.4359\n",
      "Epoch 131 Batch 350 Loss 0.2545 Accuracy 0.4365\n",
      "Epoch 131 Batch 400 Loss 0.2555 Accuracy 0.4365\n",
      "Epoch 131 Batch 450 Loss 0.2570 Accuracy 0.4363\n",
      "Epoch 131 Batch 500 Loss 0.2587 Accuracy 0.4366\n",
      "Epoch 131 Batch 550 Loss 0.2607 Accuracy 0.4361\n",
      "Epoch 131 Batch 600 Loss 0.2629 Accuracy 0.4356\n",
      "Epoch 131 Batch 650 Loss 0.2650 Accuracy 0.4356\n",
      "Epoch 131 Batch 700 Loss 0.2668 Accuracy 0.4356\n",
      "Epoch 131 Loss 0.2669 Accuracy 0.4356\n",
      "Time taken for 1 epoch: 35.18426775932312 secs\n",
      "\n",
      "Epoch 132 Batch 0 Loss 0.2597 Accuracy 0.4342\n",
      "Epoch 132 Batch 50 Loss 0.2344 Accuracy 0.4364\n",
      "Epoch 132 Batch 100 Loss 0.2380 Accuracy 0.4346\n",
      "Epoch 132 Batch 150 Loss 0.2431 Accuracy 0.4355\n",
      "Epoch 132 Batch 200 Loss 0.2452 Accuracy 0.4363\n",
      "Epoch 132 Batch 250 Loss 0.2470 Accuracy 0.4369\n",
      "Epoch 132 Batch 300 Loss 0.2489 Accuracy 0.4368\n",
      "Epoch 132 Batch 350 Loss 0.2505 Accuracy 0.4368\n",
      "Epoch 132 Batch 400 Loss 0.2522 Accuracy 0.4376\n",
      "Epoch 132 Batch 450 Loss 0.2540 Accuracy 0.4375\n",
      "Epoch 132 Batch 500 Loss 0.2557 Accuracy 0.4369\n",
      "Epoch 132 Batch 550 Loss 0.2576 Accuracy 0.4370\n",
      "Epoch 132 Batch 600 Loss 0.2598 Accuracy 0.4364\n",
      "Epoch 132 Batch 650 Loss 0.2623 Accuracy 0.4361\n",
      "Epoch 132 Batch 700 Loss 0.2644 Accuracy 0.4356\n",
      "Epoch 132 Loss 0.2644 Accuracy 0.4356\n",
      "Time taken for 1 epoch: 35.25328183174133 secs\n",
      "\n",
      "Epoch 133 Batch 0 Loss 0.2543 Accuracy 0.4163\n",
      "Epoch 133 Batch 50 Loss 0.2381 Accuracy 0.4299\n",
      "Epoch 133 Batch 100 Loss 0.2394 Accuracy 0.4353\n",
      "Epoch 133 Batch 150 Loss 0.2436 Accuracy 0.4375\n",
      "Epoch 133 Batch 200 Loss 0.2459 Accuracy 0.4377\n",
      "Epoch 133 Batch 250 Loss 0.2472 Accuracy 0.4369\n",
      "Epoch 133 Batch 300 Loss 0.2493 Accuracy 0.4362\n",
      "Epoch 133 Batch 350 Loss 0.2517 Accuracy 0.4356\n",
      "Epoch 133 Batch 400 Loss 0.2531 Accuracy 0.4364\n",
      "Epoch 133 Batch 450 Loss 0.2547 Accuracy 0.4363\n",
      "Epoch 133 Batch 500 Loss 0.2567 Accuracy 0.4362\n",
      "Epoch 133 Batch 550 Loss 0.2593 Accuracy 0.4358\n",
      "Epoch 133 Batch 600 Loss 0.2615 Accuracy 0.4354\n",
      "Epoch 133 Batch 650 Loss 0.2632 Accuracy 0.4359\n",
      "Epoch 133 Batch 700 Loss 0.2650 Accuracy 0.4359\n",
      "Epoch 133 Loss 0.2651 Accuracy 0.4359\n",
      "Time taken for 1 epoch: 35.1758873462677 secs\n",
      "\n",
      "Epoch 134 Batch 0 Loss 0.2230 Accuracy 0.4347\n",
      "Epoch 134 Batch 50 Loss 0.2376 Accuracy 0.4388\n",
      "Epoch 134 Batch 100 Loss 0.2399 Accuracy 0.4401\n",
      "Epoch 134 Batch 150 Loss 0.2423 Accuracy 0.4378\n",
      "Epoch 134 Batch 200 Loss 0.2431 Accuracy 0.4381\n",
      "Epoch 134 Batch 250 Loss 0.2463 Accuracy 0.4392\n",
      "Epoch 134 Batch 300 Loss 0.2490 Accuracy 0.4386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134 Batch 350 Loss 0.2499 Accuracy 0.4393\n",
      "Epoch 134 Batch 400 Loss 0.2513 Accuracy 0.4390\n",
      "Epoch 134 Batch 450 Loss 0.2541 Accuracy 0.4383\n",
      "Epoch 134 Batch 500 Loss 0.2565 Accuracy 0.4374\n",
      "Epoch 134 Batch 550 Loss 0.2585 Accuracy 0.4374\n",
      "Epoch 134 Batch 600 Loss 0.2607 Accuracy 0.4376\n",
      "Epoch 134 Batch 650 Loss 0.2624 Accuracy 0.4371\n",
      "Epoch 134 Batch 700 Loss 0.2649 Accuracy 0.4365\n",
      "Epoch 134 Loss 0.2649 Accuracy 0.4365\n",
      "Time taken for 1 epoch: 35.15655827522278 secs\n",
      "\n",
      "Epoch 135 Batch 0 Loss 0.2239 Accuracy 0.4449\n",
      "Epoch 135 Batch 50 Loss 0.2363 Accuracy 0.4377\n",
      "Epoch 135 Batch 100 Loss 0.2391 Accuracy 0.4389\n",
      "Epoch 135 Batch 150 Loss 0.2422 Accuracy 0.4369\n",
      "Epoch 135 Batch 200 Loss 0.2446 Accuracy 0.4380\n",
      "Epoch 135 Batch 250 Loss 0.2461 Accuracy 0.4371\n",
      "Epoch 135 Batch 300 Loss 0.2475 Accuracy 0.4373\n",
      "Epoch 135 Batch 350 Loss 0.2499 Accuracy 0.4369\n",
      "Epoch 135 Batch 400 Loss 0.2516 Accuracy 0.4371\n",
      "Epoch 135 Batch 450 Loss 0.2540 Accuracy 0.4369\n",
      "Epoch 135 Batch 500 Loss 0.2558 Accuracy 0.4363\n",
      "Epoch 135 Batch 550 Loss 0.2578 Accuracy 0.4363\n",
      "Epoch 135 Batch 600 Loss 0.2599 Accuracy 0.4359\n",
      "Epoch 135 Batch 650 Loss 0.2617 Accuracy 0.4354\n",
      "Epoch 135 Batch 700 Loss 0.2634 Accuracy 0.4354\n",
      "Saving checkpoint for epoch 135 at ./checkpoints/train/ckpt-39\n",
      "Epoch 135 Loss 0.2634 Accuracy 0.4354\n",
      "Time taken for 1 epoch: 35.323994636535645 secs\n",
      "\n",
      "Epoch 136 Batch 0 Loss 0.2627 Accuracy 0.4243\n",
      "Epoch 136 Batch 50 Loss 0.2342 Accuracy 0.4363\n",
      "Epoch 136 Batch 100 Loss 0.2387 Accuracy 0.4367\n",
      "Epoch 136 Batch 150 Loss 0.2402 Accuracy 0.4372\n",
      "Epoch 136 Batch 200 Loss 0.2431 Accuracy 0.4359\n",
      "Epoch 136 Batch 250 Loss 0.2455 Accuracy 0.4363\n",
      "Epoch 136 Batch 300 Loss 0.2483 Accuracy 0.4368\n",
      "Epoch 136 Batch 350 Loss 0.2505 Accuracy 0.4362\n",
      "Epoch 136 Batch 400 Loss 0.2524 Accuracy 0.4372\n",
      "Epoch 136 Batch 450 Loss 0.2541 Accuracy 0.4368\n",
      "Epoch 136 Batch 500 Loss 0.2555 Accuracy 0.4371\n",
      "Epoch 136 Batch 550 Loss 0.2573 Accuracy 0.4377\n",
      "Epoch 136 Batch 600 Loss 0.2587 Accuracy 0.4375\n",
      "Epoch 136 Batch 650 Loss 0.2604 Accuracy 0.4373\n",
      "Epoch 136 Batch 700 Loss 0.2621 Accuracy 0.4370\n",
      "Epoch 136 Loss 0.2622 Accuracy 0.4370\n",
      "Time taken for 1 epoch: 35.19219088554382 secs\n",
      "\n",
      "Epoch 137 Batch 0 Loss 0.2058 Accuracy 0.4269\n",
      "Epoch 137 Batch 50 Loss 0.2354 Accuracy 0.4409\n",
      "Epoch 137 Batch 100 Loss 0.2380 Accuracy 0.4384\n",
      "Epoch 137 Batch 150 Loss 0.2394 Accuracy 0.4381\n",
      "Epoch 137 Batch 200 Loss 0.2428 Accuracy 0.4394\n",
      "Epoch 137 Batch 250 Loss 0.2445 Accuracy 0.4389\n",
      "Epoch 137 Batch 300 Loss 0.2470 Accuracy 0.4389\n",
      "Epoch 137 Batch 350 Loss 0.2485 Accuracy 0.4377\n",
      "Epoch 137 Batch 400 Loss 0.2501 Accuracy 0.4375\n",
      "Epoch 137 Batch 450 Loss 0.2522 Accuracy 0.4376\n",
      "Epoch 137 Batch 500 Loss 0.2543 Accuracy 0.4371\n",
      "Epoch 137 Batch 550 Loss 0.2559 Accuracy 0.4370\n",
      "Epoch 137 Batch 600 Loss 0.2579 Accuracy 0.4364\n",
      "Epoch 137 Batch 650 Loss 0.2595 Accuracy 0.4360\n",
      "Epoch 137 Batch 700 Loss 0.2615 Accuracy 0.4357\n",
      "Epoch 137 Loss 0.2615 Accuracy 0.4357\n",
      "Time taken for 1 epoch: 35.21784591674805 secs\n",
      "\n",
      "Epoch 138 Batch 0 Loss 0.2679 Accuracy 0.3934\n",
      "Epoch 138 Batch 50 Loss 0.2369 Accuracy 0.4386\n",
      "Epoch 138 Batch 100 Loss 0.2370 Accuracy 0.4378\n",
      "Epoch 138 Batch 150 Loss 0.2394 Accuracy 0.4386\n",
      "Epoch 138 Batch 200 Loss 0.2418 Accuracy 0.4374\n",
      "Epoch 138 Batch 250 Loss 0.2450 Accuracy 0.4382\n",
      "Epoch 138 Batch 300 Loss 0.2466 Accuracy 0.4379\n",
      "Epoch 138 Batch 350 Loss 0.2491 Accuracy 0.4378\n",
      "Epoch 138 Batch 400 Loss 0.2503 Accuracy 0.4377\n",
      "Epoch 138 Batch 450 Loss 0.2526 Accuracy 0.4378\n",
      "Epoch 138 Batch 500 Loss 0.2541 Accuracy 0.4374\n",
      "Epoch 138 Batch 550 Loss 0.2561 Accuracy 0.4374\n",
      "Epoch 138 Batch 600 Loss 0.2579 Accuracy 0.4368\n",
      "Epoch 138 Batch 650 Loss 0.2594 Accuracy 0.4358\n",
      "Epoch 138 Batch 700 Loss 0.2611 Accuracy 0.4359\n",
      "Epoch 138 Loss 0.2612 Accuracy 0.4358\n",
      "Time taken for 1 epoch: 35.229883670806885 secs\n",
      "\n",
      "Epoch 139 Batch 0 Loss 0.2232 Accuracy 0.4268\n",
      "Epoch 139 Batch 50 Loss 0.2311 Accuracy 0.4356\n",
      "Epoch 139 Batch 100 Loss 0.2318 Accuracy 0.4326\n",
      "Epoch 139 Batch 150 Loss 0.2330 Accuracy 0.4349\n",
      "Epoch 139 Batch 200 Loss 0.2388 Accuracy 0.4357\n",
      "Epoch 139 Batch 250 Loss 0.2420 Accuracy 0.4350\n",
      "Epoch 139 Batch 300 Loss 0.2446 Accuracy 0.4366\n",
      "Epoch 139 Batch 350 Loss 0.2477 Accuracy 0.4368\n",
      "Epoch 139 Batch 400 Loss 0.2491 Accuracy 0.4369\n",
      "Epoch 139 Batch 450 Loss 0.2512 Accuracy 0.4369\n",
      "Epoch 139 Batch 500 Loss 0.2526 Accuracy 0.4367\n",
      "Epoch 139 Batch 550 Loss 0.2544 Accuracy 0.4364\n",
      "Epoch 139 Batch 600 Loss 0.2563 Accuracy 0.4363\n",
      "Epoch 139 Batch 650 Loss 0.2582 Accuracy 0.4365\n",
      "Epoch 139 Batch 700 Loss 0.2604 Accuracy 0.4366\n",
      "Epoch 139 Loss 0.2604 Accuracy 0.4367\n",
      "Time taken for 1 epoch: 35.00704765319824 secs\n",
      "\n",
      "Epoch 140 Batch 0 Loss 0.2661 Accuracy 0.4131\n",
      "Epoch 140 Batch 50 Loss 0.2251 Accuracy 0.4321\n",
      "Epoch 140 Batch 100 Loss 0.2299 Accuracy 0.4376\n",
      "Epoch 140 Batch 150 Loss 0.2343 Accuracy 0.4394\n",
      "Epoch 140 Batch 200 Loss 0.2378 Accuracy 0.4368\n",
      "Epoch 140 Batch 250 Loss 0.2413 Accuracy 0.4366\n",
      "Epoch 140 Batch 300 Loss 0.2434 Accuracy 0.4375\n",
      "Epoch 140 Batch 350 Loss 0.2444 Accuracy 0.4386\n",
      "Epoch 140 Batch 400 Loss 0.2458 Accuracy 0.4385\n",
      "Epoch 140 Batch 450 Loss 0.2477 Accuracy 0.4379\n",
      "Epoch 140 Batch 500 Loss 0.2500 Accuracy 0.4376\n",
      "Epoch 140 Batch 550 Loss 0.2522 Accuracy 0.4373\n",
      "Epoch 140 Batch 600 Loss 0.2547 Accuracy 0.4374\n",
      "Epoch 140 Batch 650 Loss 0.2560 Accuracy 0.4376\n",
      "Epoch 140 Batch 700 Loss 0.2585 Accuracy 0.4372\n",
      "Saving checkpoint for epoch 140 at ./checkpoints/train/ckpt-40\n",
      "Epoch 140 Loss 0.2587 Accuracy 0.4371\n",
      "Time taken for 1 epoch: 34.539201736450195 secs\n",
      "\n",
      "Epoch 141 Batch 0 Loss 0.2337 Accuracy 0.4631\n",
      "Epoch 141 Batch 50 Loss 0.2334 Accuracy 0.4387\n",
      "Epoch 141 Batch 100 Loss 0.2361 Accuracy 0.4424\n",
      "Epoch 141 Batch 150 Loss 0.2396 Accuracy 0.4393\n",
      "Epoch 141 Batch 200 Loss 0.2418 Accuracy 0.4399\n",
      "Epoch 141 Batch 250 Loss 0.2438 Accuracy 0.4392\n",
      "Epoch 141 Batch 300 Loss 0.2457 Accuracy 0.4391\n",
      "Epoch 141 Batch 350 Loss 0.2482 Accuracy 0.4391\n",
      "Epoch 141 Batch 400 Loss 0.2497 Accuracy 0.4397\n",
      "Epoch 141 Batch 450 Loss 0.2519 Accuracy 0.4401\n",
      "Epoch 141 Batch 500 Loss 0.2536 Accuracy 0.4394\n",
      "Epoch 141 Batch 550 Loss 0.2553 Accuracy 0.4388\n",
      "Epoch 141 Batch 600 Loss 0.2575 Accuracy 0.4381\n",
      "Epoch 141 Batch 650 Loss 0.2598 Accuracy 0.4378\n",
      "Epoch 141 Batch 700 Loss 0.2614 Accuracy 0.4373\n",
      "Epoch 141 Loss 0.2614 Accuracy 0.4374\n",
      "Time taken for 1 epoch: 34.28846883773804 secs\n",
      "\n",
      "Epoch 142 Batch 0 Loss 0.1984 Accuracy 0.5004\n",
      "Epoch 142 Batch 50 Loss 0.2350 Accuracy 0.4353\n",
      "Epoch 142 Batch 100 Loss 0.2326 Accuracy 0.4398\n",
      "Epoch 142 Batch 150 Loss 0.2366 Accuracy 0.4396\n",
      "Epoch 142 Batch 200 Loss 0.2387 Accuracy 0.4384\n",
      "Epoch 142 Batch 250 Loss 0.2418 Accuracy 0.4387\n",
      "Epoch 142 Batch 300 Loss 0.2436 Accuracy 0.4382\n",
      "Epoch 142 Batch 350 Loss 0.2455 Accuracy 0.4386\n",
      "Epoch 142 Batch 400 Loss 0.2471 Accuracy 0.4379\n",
      "Epoch 142 Batch 450 Loss 0.2489 Accuracy 0.4375\n",
      "Epoch 142 Batch 500 Loss 0.2506 Accuracy 0.4378\n",
      "Epoch 142 Batch 550 Loss 0.2524 Accuracy 0.4378\n",
      "Epoch 142 Batch 600 Loss 0.2544 Accuracy 0.4378\n",
      "Epoch 142 Batch 650 Loss 0.2558 Accuracy 0.4379\n",
      "Epoch 142 Batch 700 Loss 0.2572 Accuracy 0.4376\n",
      "Epoch 142 Loss 0.2573 Accuracy 0.4376\n",
      "Time taken for 1 epoch: 34.36987113952637 secs\n",
      "\n",
      "Epoch 143 Batch 0 Loss 0.2126 Accuracy 0.4475\n",
      "Epoch 143 Batch 50 Loss 0.2315 Accuracy 0.4379\n",
      "Epoch 143 Batch 100 Loss 0.2322 Accuracy 0.4391\n",
      "Epoch 143 Batch 150 Loss 0.2338 Accuracy 0.4372\n",
      "Epoch 143 Batch 200 Loss 0.2368 Accuracy 0.4368\n",
      "Epoch 143 Batch 250 Loss 0.2392 Accuracy 0.4376\n",
      "Epoch 143 Batch 300 Loss 0.2416 Accuracy 0.4383\n",
      "Epoch 143 Batch 350 Loss 0.2436 Accuracy 0.4379\n",
      "Epoch 143 Batch 400 Loss 0.2452 Accuracy 0.4381\n",
      "Epoch 143 Batch 450 Loss 0.2472 Accuracy 0.4380\n",
      "Epoch 143 Batch 500 Loss 0.2494 Accuracy 0.4376\n",
      "Epoch 143 Batch 550 Loss 0.2517 Accuracy 0.4371\n",
      "Epoch 143 Batch 600 Loss 0.2538 Accuracy 0.4366\n",
      "Epoch 143 Batch 650 Loss 0.2556 Accuracy 0.4367\n",
      "Epoch 143 Batch 700 Loss 0.2580 Accuracy 0.4366\n",
      "Epoch 143 Loss 0.2581 Accuracy 0.4367\n",
      "Time taken for 1 epoch: 34.38776230812073 secs\n",
      "\n",
      "Epoch 144 Batch 0 Loss 0.2277 Accuracy 0.4618\n",
      "Epoch 144 Batch 50 Loss 0.2280 Accuracy 0.4400\n",
      "Epoch 144 Batch 100 Loss 0.2356 Accuracy 0.4388\n",
      "Epoch 144 Batch 150 Loss 0.2369 Accuracy 0.4369\n",
      "Epoch 144 Batch 200 Loss 0.2380 Accuracy 0.4367\n",
      "Epoch 144 Batch 250 Loss 0.2401 Accuracy 0.4378\n",
      "Epoch 144 Batch 300 Loss 0.2424 Accuracy 0.4382\n",
      "Epoch 144 Batch 350 Loss 0.2440 Accuracy 0.4393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144 Batch 400 Loss 0.2458 Accuracy 0.4383\n",
      "Epoch 144 Batch 450 Loss 0.2479 Accuracy 0.4378\n",
      "Epoch 144 Batch 500 Loss 0.2497 Accuracy 0.4379\n",
      "Epoch 144 Batch 550 Loss 0.2518 Accuracy 0.4374\n",
      "Epoch 144 Batch 600 Loss 0.2543 Accuracy 0.4368\n",
      "Epoch 144 Batch 650 Loss 0.2564 Accuracy 0.4363\n",
      "Epoch 144 Batch 700 Loss 0.2580 Accuracy 0.4361\n",
      "Epoch 144 Loss 0.2582 Accuracy 0.4362\n",
      "Time taken for 1 epoch: 34.32992100715637 secs\n",
      "\n",
      "Epoch 145 Batch 0 Loss 0.2319 Accuracy 0.4091\n",
      "Epoch 145 Batch 50 Loss 0.2291 Accuracy 0.4355\n",
      "Epoch 145 Batch 100 Loss 0.2322 Accuracy 0.4374\n",
      "Epoch 145 Batch 150 Loss 0.2349 Accuracy 0.4369\n",
      "Epoch 145 Batch 200 Loss 0.2369 Accuracy 0.4378\n",
      "Epoch 145 Batch 250 Loss 0.2401 Accuracy 0.4392\n",
      "Epoch 145 Batch 300 Loss 0.2419 Accuracy 0.4389\n",
      "Epoch 145 Batch 350 Loss 0.2442 Accuracy 0.4385\n",
      "Epoch 145 Batch 400 Loss 0.2453 Accuracy 0.4379\n",
      "Epoch 145 Batch 450 Loss 0.2476 Accuracy 0.4388\n",
      "Epoch 145 Batch 500 Loss 0.2497 Accuracy 0.4386\n",
      "Epoch 145 Batch 550 Loss 0.2516 Accuracy 0.4389\n",
      "Epoch 145 Batch 600 Loss 0.2534 Accuracy 0.4385\n",
      "Epoch 145 Batch 650 Loss 0.2551 Accuracy 0.4384\n",
      "Epoch 145 Batch 700 Loss 0.2568 Accuracy 0.4382\n",
      "Saving checkpoint for epoch 145 at ./checkpoints/train/ckpt-41\n",
      "Epoch 145 Loss 0.2571 Accuracy 0.4380\n",
      "Time taken for 1 epoch: 34.477872133255005 secs\n",
      "\n",
      "Epoch 146 Batch 0 Loss 0.2009 Accuracy 0.4178\n",
      "Epoch 146 Batch 50 Loss 0.2271 Accuracy 0.4372\n",
      "Epoch 146 Batch 100 Loss 0.2312 Accuracy 0.4365\n",
      "Epoch 146 Batch 150 Loss 0.2351 Accuracy 0.4362\n",
      "Epoch 146 Batch 200 Loss 0.2379 Accuracy 0.4374\n",
      "Epoch 146 Batch 250 Loss 0.2401 Accuracy 0.4384\n",
      "Epoch 146 Batch 300 Loss 0.2417 Accuracy 0.4391\n",
      "Epoch 146 Batch 350 Loss 0.2436 Accuracy 0.4381\n",
      "Epoch 146 Batch 400 Loss 0.2451 Accuracy 0.4378\n",
      "Epoch 146 Batch 450 Loss 0.2469 Accuracy 0.4371\n",
      "Epoch 146 Batch 500 Loss 0.2485 Accuracy 0.4372\n",
      "Epoch 146 Batch 550 Loss 0.2509 Accuracy 0.4374\n",
      "Epoch 146 Batch 600 Loss 0.2526 Accuracy 0.4368\n",
      "Epoch 146 Batch 650 Loss 0.2548 Accuracy 0.4368\n",
      "Epoch 146 Batch 700 Loss 0.2568 Accuracy 0.4367\n",
      "Epoch 146 Loss 0.2568 Accuracy 0.4367\n",
      "Time taken for 1 epoch: 34.38833403587341 secs\n",
      "\n",
      "Epoch 147 Batch 0 Loss 0.2330 Accuracy 0.4462\n",
      "Epoch 147 Batch 50 Loss 0.2270 Accuracy 0.4387\n",
      "Epoch 147 Batch 100 Loss 0.2260 Accuracy 0.4368\n",
      "Epoch 147 Batch 150 Loss 0.2289 Accuracy 0.4356\n",
      "Epoch 147 Batch 200 Loss 0.2347 Accuracy 0.4368\n",
      "Epoch 147 Batch 250 Loss 0.2375 Accuracy 0.4384\n",
      "Epoch 147 Batch 300 Loss 0.2397 Accuracy 0.4390\n",
      "Epoch 147 Batch 350 Loss 0.2421 Accuracy 0.4384\n",
      "Epoch 147 Batch 400 Loss 0.2437 Accuracy 0.4387\n",
      "Epoch 147 Batch 450 Loss 0.2455 Accuracy 0.4385\n",
      "Epoch 147 Batch 500 Loss 0.2473 Accuracy 0.4388\n",
      "Epoch 147 Batch 550 Loss 0.2496 Accuracy 0.4386\n",
      "Epoch 147 Batch 600 Loss 0.2515 Accuracy 0.4380\n",
      "Epoch 147 Batch 650 Loss 0.2532 Accuracy 0.4380\n",
      "Epoch 147 Batch 700 Loss 0.2551 Accuracy 0.4374\n",
      "Epoch 147 Loss 0.2551 Accuracy 0.4374\n",
      "Time taken for 1 epoch: 34.36217713356018 secs\n",
      "\n",
      "Epoch 148 Batch 0 Loss 0.2253 Accuracy 0.4379\n",
      "Epoch 148 Batch 50 Loss 0.2282 Accuracy 0.4435\n",
      "Epoch 148 Batch 100 Loss 0.2319 Accuracy 0.4378\n",
      "Epoch 148 Batch 150 Loss 0.2341 Accuracy 0.4385\n",
      "Epoch 148 Batch 200 Loss 0.2362 Accuracy 0.4390\n",
      "Epoch 148 Batch 250 Loss 0.2389 Accuracy 0.4388\n",
      "Epoch 148 Batch 300 Loss 0.2410 Accuracy 0.4386\n",
      "Epoch 148 Batch 350 Loss 0.2418 Accuracy 0.4388\n",
      "Epoch 148 Batch 400 Loss 0.2431 Accuracy 0.4380\n",
      "Epoch 148 Batch 450 Loss 0.2446 Accuracy 0.4382\n",
      "Epoch 148 Batch 500 Loss 0.2465 Accuracy 0.4381\n",
      "Epoch 148 Batch 550 Loss 0.2483 Accuracy 0.4383\n",
      "Epoch 148 Batch 600 Loss 0.2500 Accuracy 0.4381\n",
      "Epoch 148 Batch 650 Loss 0.2520 Accuracy 0.4376\n",
      "Epoch 148 Batch 700 Loss 0.2537 Accuracy 0.4374\n",
      "Epoch 148 Loss 0.2537 Accuracy 0.4373\n",
      "Time taken for 1 epoch: 34.40310525894165 secs\n",
      "\n",
      "Epoch 149 Batch 0 Loss 0.2149 Accuracy 0.4145\n",
      "Epoch 149 Batch 50 Loss 0.2251 Accuracy 0.4367\n",
      "Epoch 149 Batch 100 Loss 0.2266 Accuracy 0.4371\n",
      "Epoch 149 Batch 150 Loss 0.2312 Accuracy 0.4368\n",
      "Epoch 149 Batch 200 Loss 0.2329 Accuracy 0.4342\n",
      "Epoch 149 Batch 250 Loss 0.2353 Accuracy 0.4351\n",
      "Epoch 149 Batch 300 Loss 0.2370 Accuracy 0.4372\n",
      "Epoch 149 Batch 350 Loss 0.2393 Accuracy 0.4391\n",
      "Epoch 149 Batch 400 Loss 0.2415 Accuracy 0.4395\n",
      "Epoch 149 Batch 450 Loss 0.2433 Accuracy 0.4397\n",
      "Epoch 149 Batch 500 Loss 0.2459 Accuracy 0.4390\n",
      "Epoch 149 Batch 550 Loss 0.2478 Accuracy 0.4379\n",
      "Epoch 149 Batch 600 Loss 0.2502 Accuracy 0.4374\n",
      "Epoch 149 Batch 650 Loss 0.2524 Accuracy 0.4368\n",
      "Epoch 149 Batch 700 Loss 0.2539 Accuracy 0.4370\n",
      "Epoch 149 Loss 0.2541 Accuracy 0.4371\n",
      "Time taken for 1 epoch: 34.33735394477844 secs\n",
      "\n",
      "Epoch 150 Batch 0 Loss 0.2124 Accuracy 0.4642\n",
      "Epoch 150 Batch 50 Loss 0.2292 Accuracy 0.4385\n",
      "Epoch 150 Batch 100 Loss 0.2270 Accuracy 0.4364\n",
      "Epoch 150 Batch 150 Loss 0.2295 Accuracy 0.4359\n",
      "Epoch 150 Batch 200 Loss 0.2338 Accuracy 0.4372\n",
      "Epoch 150 Batch 250 Loss 0.2356 Accuracy 0.4387\n",
      "Epoch 150 Batch 300 Loss 0.2389 Accuracy 0.4392\n",
      "Epoch 150 Batch 350 Loss 0.2399 Accuracy 0.4391\n",
      "Epoch 150 Batch 400 Loss 0.2413 Accuracy 0.4391\n",
      "Epoch 150 Batch 450 Loss 0.2441 Accuracy 0.4391\n",
      "Epoch 150 Batch 500 Loss 0.2456 Accuracy 0.4389\n",
      "Epoch 150 Batch 550 Loss 0.2477 Accuracy 0.4388\n",
      "Epoch 150 Batch 600 Loss 0.2493 Accuracy 0.4385\n",
      "Epoch 150 Batch 650 Loss 0.2510 Accuracy 0.4383\n",
      "Epoch 150 Batch 700 Loss 0.2535 Accuracy 0.4378\n",
      "Saving checkpoint for epoch 150 at ./checkpoints/train/ckpt-42\n",
      "Epoch 150 Loss 0.2536 Accuracy 0.4378\n",
      "Time taken for 1 epoch: 34.50337076187134 secs\n",
      "\n",
      "Epoch 151 Batch 0 Loss 0.2202 Accuracy 0.4100\n",
      "Epoch 151 Batch 50 Loss 0.2262 Accuracy 0.4439\n",
      "Epoch 151 Batch 100 Loss 0.2291 Accuracy 0.4409\n",
      "Epoch 151 Batch 150 Loss 0.2301 Accuracy 0.4408\n",
      "Epoch 151 Batch 200 Loss 0.2328 Accuracy 0.4407\n",
      "Epoch 151 Batch 250 Loss 0.2354 Accuracy 0.4403\n",
      "Epoch 151 Batch 300 Loss 0.2378 Accuracy 0.4403\n",
      "Epoch 151 Batch 350 Loss 0.2399 Accuracy 0.4398\n",
      "Epoch 151 Batch 400 Loss 0.2418 Accuracy 0.4394\n",
      "Epoch 151 Batch 450 Loss 0.2441 Accuracy 0.4390\n",
      "Epoch 151 Batch 500 Loss 0.2458 Accuracy 0.4389\n",
      "Epoch 151 Batch 550 Loss 0.2480 Accuracy 0.4387\n",
      "Epoch 151 Batch 600 Loss 0.2500 Accuracy 0.4383\n",
      "Epoch 151 Batch 650 Loss 0.2519 Accuracy 0.4374\n",
      "Epoch 151 Batch 700 Loss 0.2536 Accuracy 0.4374\n",
      "Epoch 151 Loss 0.2536 Accuracy 0.4374\n",
      "Time taken for 1 epoch: 34.35204577445984 secs\n",
      "\n",
      "Epoch 152 Batch 0 Loss 0.1737 Accuracy 0.4275\n",
      "Epoch 152 Batch 50 Loss 0.2247 Accuracy 0.4436\n",
      "Epoch 152 Batch 100 Loss 0.2265 Accuracy 0.4383\n",
      "Epoch 152 Batch 150 Loss 0.2290 Accuracy 0.4379\n",
      "Epoch 152 Batch 200 Loss 0.2327 Accuracy 0.4382\n",
      "Epoch 152 Batch 250 Loss 0.2354 Accuracy 0.4388\n",
      "Epoch 152 Batch 300 Loss 0.2373 Accuracy 0.4391\n",
      "Epoch 152 Batch 350 Loss 0.2389 Accuracy 0.4392\n",
      "Epoch 152 Batch 400 Loss 0.2407 Accuracy 0.4394\n",
      "Epoch 152 Batch 450 Loss 0.2427 Accuracy 0.4396\n",
      "Epoch 152 Batch 500 Loss 0.2449 Accuracy 0.4391\n",
      "Epoch 152 Batch 550 Loss 0.2462 Accuracy 0.4394\n",
      "Epoch 152 Batch 600 Loss 0.2478 Accuracy 0.4388\n",
      "Epoch 152 Batch 650 Loss 0.2499 Accuracy 0.4380\n",
      "Epoch 152 Batch 700 Loss 0.2523 Accuracy 0.4374\n",
      "Epoch 152 Loss 0.2523 Accuracy 0.4373\n",
      "Time taken for 1 epoch: 34.37589168548584 secs\n",
      "\n",
      "Epoch 153 Batch 0 Loss 0.2549 Accuracy 0.4458\n",
      "Epoch 153 Batch 50 Loss 0.2270 Accuracy 0.4426\n",
      "Epoch 153 Batch 100 Loss 0.2288 Accuracy 0.4405\n",
      "Epoch 153 Batch 150 Loss 0.2303 Accuracy 0.4398\n",
      "Epoch 153 Batch 200 Loss 0.2348 Accuracy 0.4381\n",
      "Epoch 153 Batch 250 Loss 0.2367 Accuracy 0.4386\n",
      "Epoch 153 Batch 300 Loss 0.2377 Accuracy 0.4382\n",
      "Epoch 153 Batch 350 Loss 0.2395 Accuracy 0.4386\n",
      "Epoch 153 Batch 400 Loss 0.2411 Accuracy 0.4388\n",
      "Epoch 153 Batch 450 Loss 0.2426 Accuracy 0.4388\n",
      "Epoch 153 Batch 500 Loss 0.2453 Accuracy 0.4381\n",
      "Epoch 153 Batch 550 Loss 0.2477 Accuracy 0.4378\n",
      "Epoch 153 Batch 600 Loss 0.2493 Accuracy 0.4379\n",
      "Epoch 153 Batch 650 Loss 0.2510 Accuracy 0.4378\n",
      "Epoch 153 Batch 700 Loss 0.2529 Accuracy 0.4377\n",
      "Epoch 153 Loss 0.2530 Accuracy 0.4376\n",
      "Time taken for 1 epoch: 34.3528687953949 secs\n",
      "\n",
      "Epoch 154 Batch 0 Loss 0.2503 Accuracy 0.4945\n",
      "Epoch 154 Batch 50 Loss 0.2272 Accuracy 0.4421\n",
      "Epoch 154 Batch 100 Loss 0.2297 Accuracy 0.4372\n",
      "Epoch 154 Batch 150 Loss 0.2318 Accuracy 0.4401\n",
      "Epoch 154 Batch 200 Loss 0.2332 Accuracy 0.4394\n",
      "Epoch 154 Batch 250 Loss 0.2350 Accuracy 0.4382\n",
      "Epoch 154 Batch 300 Loss 0.2372 Accuracy 0.4399\n",
      "Epoch 154 Batch 350 Loss 0.2393 Accuracy 0.4400\n",
      "Epoch 154 Batch 400 Loss 0.2403 Accuracy 0.4403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154 Batch 450 Loss 0.2419 Accuracy 0.4400\n",
      "Epoch 154 Batch 500 Loss 0.2431 Accuracy 0.4399\n",
      "Epoch 154 Batch 550 Loss 0.2450 Accuracy 0.4391\n",
      "Epoch 154 Batch 600 Loss 0.2471 Accuracy 0.4391\n",
      "Epoch 154 Batch 650 Loss 0.2490 Accuracy 0.4390\n",
      "Epoch 154 Batch 700 Loss 0.2513 Accuracy 0.4385\n",
      "Epoch 154 Loss 0.2513 Accuracy 0.4385\n",
      "Time taken for 1 epoch: 34.400733947753906 secs\n",
      "\n",
      "Epoch 155 Batch 0 Loss 0.2171 Accuracy 0.4303\n",
      "Epoch 155 Batch 50 Loss 0.2260 Accuracy 0.4440\n",
      "Epoch 155 Batch 100 Loss 0.2272 Accuracy 0.4406\n",
      "Epoch 155 Batch 150 Loss 0.2289 Accuracy 0.4416\n",
      "Epoch 155 Batch 200 Loss 0.2314 Accuracy 0.4409\n",
      "Epoch 155 Batch 250 Loss 0.2340 Accuracy 0.4413\n",
      "Epoch 155 Batch 300 Loss 0.2363 Accuracy 0.4402\n",
      "Epoch 155 Batch 350 Loss 0.2376 Accuracy 0.4400\n",
      "Epoch 155 Batch 400 Loss 0.2387 Accuracy 0.4388\n",
      "Epoch 155 Batch 450 Loss 0.2409 Accuracy 0.4386\n",
      "Epoch 155 Batch 500 Loss 0.2427 Accuracy 0.4385\n",
      "Epoch 155 Batch 550 Loss 0.2446 Accuracy 0.4385\n",
      "Epoch 155 Batch 600 Loss 0.2472 Accuracy 0.4382\n",
      "Epoch 155 Batch 650 Loss 0.2492 Accuracy 0.4381\n",
      "Epoch 155 Batch 700 Loss 0.2507 Accuracy 0.4375\n",
      "Saving checkpoint for epoch 155 at ./checkpoints/train/ckpt-43\n",
      "Epoch 155 Loss 0.2507 Accuracy 0.4375\n",
      "Time taken for 1 epoch: 34.566068172454834 secs\n",
      "\n",
      "Epoch 156 Batch 0 Loss 0.2333 Accuracy 0.4100\n",
      "Epoch 156 Batch 50 Loss 0.2267 Accuracy 0.4402\n",
      "Epoch 156 Batch 100 Loss 0.2282 Accuracy 0.4432\n",
      "Epoch 156 Batch 150 Loss 0.2307 Accuracy 0.4424\n",
      "Epoch 156 Batch 200 Loss 0.2340 Accuracy 0.4422\n",
      "Epoch 156 Batch 250 Loss 0.2353 Accuracy 0.4417\n",
      "Epoch 156 Batch 300 Loss 0.2370 Accuracy 0.4415\n",
      "Epoch 156 Batch 350 Loss 0.2380 Accuracy 0.4418\n",
      "Epoch 156 Batch 400 Loss 0.2397 Accuracy 0.4417\n",
      "Epoch 156 Batch 450 Loss 0.2416 Accuracy 0.4410\n",
      "Epoch 156 Batch 500 Loss 0.2434 Accuracy 0.4401\n",
      "Epoch 156 Batch 550 Loss 0.2447 Accuracy 0.4399\n",
      "Epoch 156 Batch 600 Loss 0.2465 Accuracy 0.4395\n",
      "Epoch 156 Batch 650 Loss 0.2482 Accuracy 0.4389\n",
      "Epoch 156 Batch 700 Loss 0.2500 Accuracy 0.4387\n",
      "Epoch 156 Loss 0.2501 Accuracy 0.4387\n",
      "Time taken for 1 epoch: 34.374629735946655 secs\n",
      "\n",
      "Epoch 157 Batch 0 Loss 0.2050 Accuracy 0.4333\n",
      "Epoch 157 Batch 50 Loss 0.2231 Accuracy 0.4424\n",
      "Epoch 157 Batch 100 Loss 0.2273 Accuracy 0.4420\n",
      "Epoch 157 Batch 150 Loss 0.2282 Accuracy 0.4423\n",
      "Epoch 157 Batch 200 Loss 0.2299 Accuracy 0.4411\n",
      "Epoch 157 Batch 250 Loss 0.2324 Accuracy 0.4402\n",
      "Epoch 157 Batch 300 Loss 0.2345 Accuracy 0.4403\n",
      "Epoch 157 Batch 350 Loss 0.2361 Accuracy 0.4407\n",
      "Epoch 157 Batch 400 Loss 0.2384 Accuracy 0.4409\n",
      "Epoch 157 Batch 450 Loss 0.2403 Accuracy 0.4403\n",
      "Epoch 157 Batch 500 Loss 0.2419 Accuracy 0.4391\n",
      "Epoch 157 Batch 550 Loss 0.2444 Accuracy 0.4389\n",
      "Epoch 157 Batch 600 Loss 0.2465 Accuracy 0.4385\n",
      "Epoch 157 Batch 650 Loss 0.2481 Accuracy 0.4387\n",
      "Epoch 157 Batch 700 Loss 0.2498 Accuracy 0.4387\n",
      "Epoch 157 Loss 0.2498 Accuracy 0.4387\n",
      "Time taken for 1 epoch: 34.387219190597534 secs\n",
      "\n",
      "Epoch 158 Batch 0 Loss 0.2777 Accuracy 0.5013\n",
      "Epoch 158 Batch 50 Loss 0.2233 Accuracy 0.4406\n",
      "Epoch 158 Batch 100 Loss 0.2247 Accuracy 0.4387\n",
      "Epoch 158 Batch 150 Loss 0.2276 Accuracy 0.4399\n",
      "Epoch 158 Batch 200 Loss 0.2309 Accuracy 0.4402\n",
      "Epoch 158 Batch 250 Loss 0.2326 Accuracy 0.4398\n",
      "Epoch 158 Batch 300 Loss 0.2345 Accuracy 0.4392\n",
      "Epoch 158 Batch 350 Loss 0.2369 Accuracy 0.4396\n",
      "Epoch 158 Batch 400 Loss 0.2380 Accuracy 0.4391\n",
      "Epoch 158 Batch 450 Loss 0.2388 Accuracy 0.4395\n",
      "Epoch 158 Batch 500 Loss 0.2410 Accuracy 0.4390\n",
      "Epoch 158 Batch 550 Loss 0.2434 Accuracy 0.4391\n",
      "Epoch 158 Batch 600 Loss 0.2458 Accuracy 0.4389\n",
      "Epoch 158 Batch 650 Loss 0.2474 Accuracy 0.4383\n",
      "Epoch 158 Batch 700 Loss 0.2490 Accuracy 0.4383\n",
      "Epoch 158 Loss 0.2491 Accuracy 0.4383\n",
      "Time taken for 1 epoch: 34.312459230422974 secs\n",
      "\n",
      "Epoch 159 Batch 0 Loss 0.1948 Accuracy 0.4400\n",
      "Epoch 159 Batch 50 Loss 0.2241 Accuracy 0.4369\n",
      "Epoch 159 Batch 100 Loss 0.2234 Accuracy 0.4384\n",
      "Epoch 159 Batch 150 Loss 0.2243 Accuracy 0.4386\n",
      "Epoch 159 Batch 200 Loss 0.2271 Accuracy 0.4375\n",
      "Epoch 159 Batch 250 Loss 0.2295 Accuracy 0.4378\n",
      "Epoch 159 Batch 300 Loss 0.2316 Accuracy 0.4388\n",
      "Epoch 159 Batch 350 Loss 0.2342 Accuracy 0.4397\n",
      "Epoch 159 Batch 400 Loss 0.2365 Accuracy 0.4400\n",
      "Epoch 159 Batch 450 Loss 0.2387 Accuracy 0.4399\n",
      "Epoch 159 Batch 500 Loss 0.2404 Accuracy 0.4398\n",
      "Epoch 159 Batch 550 Loss 0.2419 Accuracy 0.4387\n",
      "Epoch 159 Batch 600 Loss 0.2439 Accuracy 0.4387\n",
      "Epoch 159 Batch 650 Loss 0.2459 Accuracy 0.4384\n",
      "Epoch 159 Batch 700 Loss 0.2480 Accuracy 0.4381\n",
      "Epoch 159 Loss 0.2481 Accuracy 0.4381\n",
      "Time taken for 1 epoch: 34.40296292304993 secs\n",
      "\n",
      "Epoch 160 Batch 0 Loss 0.1838 Accuracy 0.4451\n",
      "Epoch 160 Batch 50 Loss 0.2203 Accuracy 0.4378\n",
      "Epoch 160 Batch 100 Loss 0.2246 Accuracy 0.4417\n",
      "Epoch 160 Batch 150 Loss 0.2278 Accuracy 0.4401\n",
      "Epoch 160 Batch 200 Loss 0.2297 Accuracy 0.4404\n",
      "Epoch 160 Batch 250 Loss 0.2318 Accuracy 0.4395\n",
      "Epoch 160 Batch 300 Loss 0.2332 Accuracy 0.4390\n",
      "Epoch 160 Batch 350 Loss 0.2352 Accuracy 0.4391\n",
      "Epoch 160 Batch 400 Loss 0.2374 Accuracy 0.4393\n",
      "Epoch 160 Batch 450 Loss 0.2386 Accuracy 0.4400\n",
      "Epoch 160 Batch 500 Loss 0.2403 Accuracy 0.4398\n",
      "Epoch 160 Batch 550 Loss 0.2421 Accuracy 0.4399\n",
      "Epoch 160 Batch 600 Loss 0.2439 Accuracy 0.4399\n",
      "Epoch 160 Batch 650 Loss 0.2457 Accuracy 0.4392\n",
      "Epoch 160 Batch 700 Loss 0.2471 Accuracy 0.4389\n",
      "Saving checkpoint for epoch 160 at ./checkpoints/train/ckpt-44\n",
      "Epoch 160 Loss 0.2471 Accuracy 0.4389\n",
      "Time taken for 1 epoch: 34.52799367904663 secs\n",
      "\n",
      "Epoch 161 Batch 0 Loss 0.2425 Accuracy 0.4848\n",
      "Epoch 161 Batch 50 Loss 0.2193 Accuracy 0.4461\n",
      "Epoch 161 Batch 100 Loss 0.2247 Accuracy 0.4446\n",
      "Epoch 161 Batch 150 Loss 0.2269 Accuracy 0.4437\n",
      "Epoch 161 Batch 200 Loss 0.2287 Accuracy 0.4427\n",
      "Epoch 161 Batch 250 Loss 0.2315 Accuracy 0.4413\n",
      "Epoch 161 Batch 300 Loss 0.2331 Accuracy 0.4412\n",
      "Epoch 161 Batch 350 Loss 0.2348 Accuracy 0.4406\n",
      "Epoch 161 Batch 400 Loss 0.2365 Accuracy 0.4407\n",
      "Epoch 161 Batch 450 Loss 0.2382 Accuracy 0.4405\n",
      "Epoch 161 Batch 500 Loss 0.2397 Accuracy 0.4399\n",
      "Epoch 161 Batch 550 Loss 0.2413 Accuracy 0.4393\n",
      "Epoch 161 Batch 600 Loss 0.2435 Accuracy 0.4385\n",
      "Epoch 161 Batch 650 Loss 0.2454 Accuracy 0.4382\n",
      "Epoch 161 Batch 700 Loss 0.2474 Accuracy 0.4383\n",
      "Epoch 161 Loss 0.2473 Accuracy 0.4383\n",
      "Time taken for 1 epoch: 34.38475060462952 secs\n",
      "\n",
      "Epoch 162 Batch 0 Loss 0.2568 Accuracy 0.4248\n",
      "Epoch 162 Batch 50 Loss 0.2234 Accuracy 0.4451\n",
      "Epoch 162 Batch 100 Loss 0.2233 Accuracy 0.4414\n",
      "Epoch 162 Batch 150 Loss 0.2254 Accuracy 0.4405\n",
      "Epoch 162 Batch 200 Loss 0.2275 Accuracy 0.4392\n",
      "Epoch 162 Batch 250 Loss 0.2305 Accuracy 0.4383\n",
      "Epoch 162 Batch 300 Loss 0.2326 Accuracy 0.4397\n",
      "Epoch 162 Batch 350 Loss 0.2341 Accuracy 0.4393\n",
      "Epoch 162 Batch 400 Loss 0.2357 Accuracy 0.4394\n",
      "Epoch 162 Batch 450 Loss 0.2375 Accuracy 0.4399\n",
      "Epoch 162 Batch 500 Loss 0.2397 Accuracy 0.4390\n",
      "Epoch 162 Batch 550 Loss 0.2416 Accuracy 0.4387\n",
      "Epoch 162 Batch 600 Loss 0.2438 Accuracy 0.4388\n",
      "Epoch 162 Batch 650 Loss 0.2452 Accuracy 0.4382\n",
      "Epoch 162 Batch 700 Loss 0.2466 Accuracy 0.4379\n",
      "Epoch 162 Loss 0.2467 Accuracy 0.4379\n",
      "Time taken for 1 epoch: 34.36239576339722 secs\n",
      "\n",
      "Epoch 163 Batch 0 Loss 0.2408 Accuracy 0.4555\n",
      "Epoch 163 Batch 50 Loss 0.2208 Accuracy 0.4410\n",
      "Epoch 163 Batch 100 Loss 0.2256 Accuracy 0.4393\n",
      "Epoch 163 Batch 150 Loss 0.2281 Accuracy 0.4385\n",
      "Epoch 163 Batch 200 Loss 0.2314 Accuracy 0.4390\n",
      "Epoch 163 Batch 250 Loss 0.2329 Accuracy 0.4397\n",
      "Epoch 163 Batch 300 Loss 0.2347 Accuracy 0.4383\n",
      "Epoch 163 Batch 350 Loss 0.2361 Accuracy 0.4399\n",
      "Epoch 163 Batch 400 Loss 0.2366 Accuracy 0.4404\n",
      "Epoch 163 Batch 450 Loss 0.2376 Accuracy 0.4398\n",
      "Epoch 163 Batch 500 Loss 0.2388 Accuracy 0.4397\n",
      "Epoch 163 Batch 550 Loss 0.2412 Accuracy 0.4401\n",
      "Epoch 163 Batch 600 Loss 0.2431 Accuracy 0.4397\n",
      "Epoch 163 Batch 650 Loss 0.2445 Accuracy 0.4395\n",
      "Epoch 163 Batch 700 Loss 0.2460 Accuracy 0.4395\n",
      "Epoch 163 Loss 0.2460 Accuracy 0.4396\n",
      "Time taken for 1 epoch: 34.31806778907776 secs\n",
      "\n",
      "Epoch 164 Batch 0 Loss 0.1893 Accuracy 0.4337\n",
      "Epoch 164 Batch 50 Loss 0.2247 Accuracy 0.4438\n",
      "Epoch 164 Batch 100 Loss 0.2216 Accuracy 0.4409\n",
      "Epoch 164 Batch 150 Loss 0.2244 Accuracy 0.4393\n",
      "Epoch 164 Batch 200 Loss 0.2285 Accuracy 0.4400\n",
      "Epoch 164 Batch 250 Loss 0.2302 Accuracy 0.4384\n",
      "Epoch 164 Batch 300 Loss 0.2320 Accuracy 0.4380\n",
      "Epoch 164 Batch 350 Loss 0.2343 Accuracy 0.4389\n",
      "Epoch 164 Batch 400 Loss 0.2360 Accuracy 0.4394\n",
      "Epoch 164 Batch 450 Loss 0.2375 Accuracy 0.4383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164 Batch 500 Loss 0.2394 Accuracy 0.4385\n",
      "Epoch 164 Batch 550 Loss 0.2406 Accuracy 0.4387\n",
      "Epoch 164 Batch 600 Loss 0.2417 Accuracy 0.4391\n",
      "Epoch 164 Batch 650 Loss 0.2439 Accuracy 0.4390\n",
      "Epoch 164 Batch 700 Loss 0.2458 Accuracy 0.4385\n",
      "Epoch 164 Loss 0.2459 Accuracy 0.4385\n",
      "Time taken for 1 epoch: 34.378846168518066 secs\n",
      "\n",
      "Epoch 165 Batch 0 Loss 0.2159 Accuracy 0.3990\n",
      "Epoch 165 Batch 50 Loss 0.2208 Accuracy 0.4384\n",
      "Epoch 165 Batch 100 Loss 0.2212 Accuracy 0.4379\n",
      "Epoch 165 Batch 150 Loss 0.2255 Accuracy 0.4372\n",
      "Epoch 165 Batch 200 Loss 0.2281 Accuracy 0.4385\n",
      "Epoch 165 Batch 250 Loss 0.2300 Accuracy 0.4380\n",
      "Epoch 165 Batch 300 Loss 0.2324 Accuracy 0.4379\n",
      "Epoch 165 Batch 350 Loss 0.2339 Accuracy 0.4373\n",
      "Epoch 165 Batch 400 Loss 0.2350 Accuracy 0.4387\n",
      "Epoch 165 Batch 450 Loss 0.2366 Accuracy 0.4388\n",
      "Epoch 165 Batch 500 Loss 0.2383 Accuracy 0.4392\n",
      "Epoch 165 Batch 550 Loss 0.2401 Accuracy 0.4395\n",
      "Epoch 165 Batch 600 Loss 0.2413 Accuracy 0.4398\n",
      "Epoch 165 Batch 650 Loss 0.2430 Accuracy 0.4390\n",
      "Epoch 165 Batch 700 Loss 0.2447 Accuracy 0.4386\n",
      "Saving checkpoint for epoch 165 at ./checkpoints/train/ckpt-45\n",
      "Epoch 165 Loss 0.2447 Accuracy 0.4386\n",
      "Time taken for 1 epoch: 34.542582511901855 secs\n",
      "\n",
      "Epoch 166 Batch 0 Loss 0.1684 Accuracy 0.4560\n",
      "Epoch 166 Batch 50 Loss 0.2198 Accuracy 0.4428\n",
      "Epoch 166 Batch 100 Loss 0.2218 Accuracy 0.4419\n",
      "Epoch 166 Batch 150 Loss 0.2259 Accuracy 0.4401\n",
      "Epoch 166 Batch 200 Loss 0.2273 Accuracy 0.4404\n",
      "Epoch 166 Batch 250 Loss 0.2290 Accuracy 0.4392\n",
      "Epoch 166 Batch 300 Loss 0.2303 Accuracy 0.4388\n",
      "Epoch 166 Batch 350 Loss 0.2321 Accuracy 0.4389\n",
      "Epoch 166 Batch 400 Loss 0.2338 Accuracy 0.4386\n",
      "Epoch 166 Batch 450 Loss 0.2355 Accuracy 0.4394\n",
      "Epoch 166 Batch 500 Loss 0.2377 Accuracy 0.4391\n",
      "Epoch 166 Batch 550 Loss 0.2389 Accuracy 0.4388\n",
      "Epoch 166 Batch 600 Loss 0.2410 Accuracy 0.4388\n",
      "Epoch 166 Batch 650 Loss 0.2431 Accuracy 0.4385\n",
      "Epoch 166 Batch 700 Loss 0.2448 Accuracy 0.4383\n",
      "Epoch 166 Loss 0.2449 Accuracy 0.4383\n",
      "Time taken for 1 epoch: 34.36136341094971 secs\n",
      "\n",
      "Epoch 167 Batch 0 Loss 0.1759 Accuracy 0.4335\n",
      "Epoch 167 Batch 50 Loss 0.2150 Accuracy 0.4425\n",
      "Epoch 167 Batch 100 Loss 0.2168 Accuracy 0.4407\n",
      "Epoch 167 Batch 150 Loss 0.2203 Accuracy 0.4412\n",
      "Epoch 167 Batch 200 Loss 0.2234 Accuracy 0.4411\n",
      "Epoch 167 Batch 250 Loss 0.2259 Accuracy 0.4405\n",
      "Epoch 167 Batch 300 Loss 0.2278 Accuracy 0.4403\n",
      "Epoch 167 Batch 350 Loss 0.2295 Accuracy 0.4397\n",
      "Epoch 167 Batch 400 Loss 0.2312 Accuracy 0.4394\n",
      "Epoch 167 Batch 450 Loss 0.2334 Accuracy 0.4396\n",
      "Epoch 167 Batch 500 Loss 0.2356 Accuracy 0.4395\n",
      "Epoch 167 Batch 550 Loss 0.2376 Accuracy 0.4388\n",
      "Epoch 167 Batch 600 Loss 0.2393 Accuracy 0.4388\n",
      "Epoch 167 Batch 650 Loss 0.2412 Accuracy 0.4385\n",
      "Epoch 167 Batch 700 Loss 0.2430 Accuracy 0.4386\n",
      "Epoch 167 Loss 0.2430 Accuracy 0.4386\n",
      "Time taken for 1 epoch: 34.42568635940552 secs\n",
      "\n",
      "Epoch 168 Batch 0 Loss 0.2442 Accuracy 0.4662\n",
      "Epoch 168 Batch 50 Loss 0.2174 Accuracy 0.4415\n",
      "Epoch 168 Batch 100 Loss 0.2194 Accuracy 0.4405\n",
      "Epoch 168 Batch 150 Loss 0.2216 Accuracy 0.4388\n",
      "Epoch 168 Batch 200 Loss 0.2242 Accuracy 0.4406\n",
      "Epoch 168 Batch 250 Loss 0.2269 Accuracy 0.4407\n",
      "Epoch 168 Batch 300 Loss 0.2285 Accuracy 0.4406\n",
      "Epoch 168 Batch 350 Loss 0.2298 Accuracy 0.4403\n",
      "Epoch 168 Batch 400 Loss 0.2319 Accuracy 0.4399\n",
      "Epoch 168 Batch 450 Loss 0.2337 Accuracy 0.4403\n",
      "Epoch 168 Batch 500 Loss 0.2348 Accuracy 0.4401\n",
      "Epoch 168 Batch 550 Loss 0.2364 Accuracy 0.4402\n",
      "Epoch 168 Batch 600 Loss 0.2382 Accuracy 0.4396\n",
      "Epoch 168 Batch 650 Loss 0.2402 Accuracy 0.4395\n",
      "Epoch 168 Batch 700 Loss 0.2427 Accuracy 0.4394\n",
      "Epoch 168 Loss 0.2429 Accuracy 0.4394\n",
      "Time taken for 1 epoch: 34.39109706878662 secs\n",
      "\n",
      "Epoch 169 Batch 0 Loss 0.2252 Accuracy 0.4482\n",
      "Epoch 169 Batch 50 Loss 0.2195 Accuracy 0.4415\n",
      "Epoch 169 Batch 100 Loss 0.2210 Accuracy 0.4427\n",
      "Epoch 169 Batch 150 Loss 0.2228 Accuracy 0.4409\n",
      "Epoch 169 Batch 200 Loss 0.2247 Accuracy 0.4415\n",
      "Epoch 169 Batch 250 Loss 0.2267 Accuracy 0.4410\n",
      "Epoch 169 Batch 300 Loss 0.2305 Accuracy 0.4406\n",
      "Epoch 169 Batch 350 Loss 0.2319 Accuracy 0.4409\n",
      "Epoch 169 Batch 400 Loss 0.2328 Accuracy 0.4401\n",
      "Epoch 169 Batch 450 Loss 0.2339 Accuracy 0.4406\n",
      "Epoch 169 Batch 500 Loss 0.2364 Accuracy 0.4405\n",
      "Epoch 169 Batch 550 Loss 0.2386 Accuracy 0.4399\n",
      "Epoch 169 Batch 600 Loss 0.2404 Accuracy 0.4399\n",
      "Epoch 169 Batch 650 Loss 0.2420 Accuracy 0.4404\n",
      "Epoch 169 Batch 700 Loss 0.2436 Accuracy 0.4399\n",
      "Epoch 169 Loss 0.2437 Accuracy 0.4399\n",
      "Time taken for 1 epoch: 34.315733194351196 secs\n",
      "\n",
      "Epoch 170 Batch 0 Loss 0.1936 Accuracy 0.4462\n",
      "Epoch 170 Batch 50 Loss 0.2240 Accuracy 0.4365\n",
      "Epoch 170 Batch 100 Loss 0.2230 Accuracy 0.4409\n",
      "Epoch 170 Batch 150 Loss 0.2249 Accuracy 0.4401\n",
      "Epoch 170 Batch 200 Loss 0.2264 Accuracy 0.4403\n",
      "Epoch 170 Batch 250 Loss 0.2276 Accuracy 0.4398\n",
      "Epoch 170 Batch 300 Loss 0.2291 Accuracy 0.4414\n",
      "Epoch 170 Batch 350 Loss 0.2308 Accuracy 0.4409\n",
      "Epoch 170 Batch 400 Loss 0.2319 Accuracy 0.4407\n",
      "Epoch 170 Batch 450 Loss 0.2331 Accuracy 0.4399\n",
      "Epoch 170 Batch 500 Loss 0.2351 Accuracy 0.4394\n",
      "Epoch 170 Batch 550 Loss 0.2371 Accuracy 0.4389\n",
      "Epoch 170 Batch 600 Loss 0.2392 Accuracy 0.4389\n",
      "Epoch 170 Batch 650 Loss 0.2405 Accuracy 0.4393\n",
      "Epoch 170 Batch 700 Loss 0.2419 Accuracy 0.4392\n",
      "Saving checkpoint for epoch 170 at ./checkpoints/train/ckpt-46\n",
      "Epoch 170 Loss 0.2420 Accuracy 0.4392\n",
      "Time taken for 1 epoch: 34.52626395225525 secs\n",
      "\n",
      "Epoch 171 Batch 0 Loss 0.2249 Accuracy 0.4862\n",
      "Epoch 171 Batch 50 Loss 0.2159 Accuracy 0.4414\n",
      "Epoch 171 Batch 100 Loss 0.2172 Accuracy 0.4417\n",
      "Epoch 171 Batch 150 Loss 0.2197 Accuracy 0.4428\n",
      "Epoch 171 Batch 200 Loss 0.2221 Accuracy 0.4403\n",
      "Epoch 171 Batch 250 Loss 0.2237 Accuracy 0.4394\n",
      "Epoch 171 Batch 300 Loss 0.2261 Accuracy 0.4394\n",
      "Epoch 171 Batch 350 Loss 0.2267 Accuracy 0.4389\n",
      "Epoch 171 Batch 400 Loss 0.2291 Accuracy 0.4396\n",
      "Epoch 171 Batch 450 Loss 0.2310 Accuracy 0.4398\n",
      "Epoch 171 Batch 500 Loss 0.2337 Accuracy 0.4395\n",
      "Epoch 171 Batch 550 Loss 0.2362 Accuracy 0.4393\n",
      "Epoch 171 Batch 600 Loss 0.2379 Accuracy 0.4390\n",
      "Epoch 171 Batch 650 Loss 0.2396 Accuracy 0.4389\n",
      "Epoch 171 Batch 700 Loss 0.2416 Accuracy 0.4390\n",
      "Epoch 171 Loss 0.2418 Accuracy 0.4390\n",
      "Time taken for 1 epoch: 34.398704290390015 secs\n",
      "\n",
      "Epoch 172 Batch 0 Loss 0.1652 Accuracy 0.4462\n",
      "Epoch 172 Batch 50 Loss 0.2175 Accuracy 0.4411\n",
      "Epoch 172 Batch 100 Loss 0.2204 Accuracy 0.4418\n",
      "Epoch 172 Batch 150 Loss 0.2215 Accuracy 0.4410\n",
      "Epoch 172 Batch 200 Loss 0.2240 Accuracy 0.4409\n",
      "Epoch 172 Batch 250 Loss 0.2260 Accuracy 0.4392\n",
      "Epoch 172 Batch 300 Loss 0.2279 Accuracy 0.4388\n",
      "Epoch 172 Batch 350 Loss 0.2295 Accuracy 0.4383\n",
      "Epoch 172 Batch 400 Loss 0.2305 Accuracy 0.4383\n",
      "Epoch 172 Batch 450 Loss 0.2324 Accuracy 0.4395\n",
      "Epoch 172 Batch 500 Loss 0.2339 Accuracy 0.4394\n",
      "Epoch 172 Batch 550 Loss 0.2358 Accuracy 0.4388\n",
      "Epoch 172 Batch 600 Loss 0.2376 Accuracy 0.4388\n",
      "Epoch 172 Batch 650 Loss 0.2395 Accuracy 0.4387\n",
      "Epoch 172 Batch 700 Loss 0.2412 Accuracy 0.4388\n",
      "Epoch 172 Loss 0.2412 Accuracy 0.4389\n",
      "Time taken for 1 epoch: 34.34516263008118 secs\n",
      "\n",
      "Epoch 173 Batch 0 Loss 0.2219 Accuracy 0.4219\n",
      "Epoch 173 Batch 50 Loss 0.2162 Accuracy 0.4445\n",
      "Epoch 173 Batch 100 Loss 0.2170 Accuracy 0.4434\n",
      "Epoch 173 Batch 150 Loss 0.2198 Accuracy 0.4427\n",
      "Epoch 173 Batch 200 Loss 0.2223 Accuracy 0.4421\n",
      "Epoch 173 Batch 250 Loss 0.2244 Accuracy 0.4407\n",
      "Epoch 173 Batch 300 Loss 0.2261 Accuracy 0.4399\n",
      "Epoch 173 Batch 350 Loss 0.2274 Accuracy 0.4404\n",
      "Epoch 173 Batch 400 Loss 0.2283 Accuracy 0.4406\n",
      "Epoch 173 Batch 450 Loss 0.2299 Accuracy 0.4409\n",
      "Epoch 173 Batch 500 Loss 0.2322 Accuracy 0.4411\n",
      "Epoch 173 Batch 550 Loss 0.2338 Accuracy 0.4409\n",
      "Epoch 173 Batch 600 Loss 0.2357 Accuracy 0.4411\n",
      "Epoch 173 Batch 650 Loss 0.2377 Accuracy 0.4412\n",
      "Epoch 173 Batch 700 Loss 0.2398 Accuracy 0.4405\n",
      "Epoch 173 Loss 0.2400 Accuracy 0.4404\n",
      "Time taken for 1 epoch: 34.31759977340698 secs\n",
      "\n",
      "Epoch 174 Batch 0 Loss 0.2050 Accuracy 0.4806\n",
      "Epoch 174 Batch 50 Loss 0.2195 Accuracy 0.4435\n",
      "Epoch 174 Batch 100 Loss 0.2208 Accuracy 0.4421\n",
      "Epoch 174 Batch 150 Loss 0.2212 Accuracy 0.4427\n",
      "Epoch 174 Batch 200 Loss 0.2230 Accuracy 0.4429\n",
      "Epoch 174 Batch 250 Loss 0.2250 Accuracy 0.4427\n",
      "Epoch 174 Batch 300 Loss 0.2267 Accuracy 0.4416\n",
      "Epoch 174 Batch 350 Loss 0.2275 Accuracy 0.4410\n",
      "Epoch 174 Batch 400 Loss 0.2283 Accuracy 0.4413\n",
      "Epoch 174 Batch 450 Loss 0.2309 Accuracy 0.4411\n",
      "Epoch 174 Batch 500 Loss 0.2324 Accuracy 0.4409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174 Batch 550 Loss 0.2342 Accuracy 0.4402\n",
      "Epoch 174 Batch 600 Loss 0.2358 Accuracy 0.4399\n",
      "Epoch 174 Batch 650 Loss 0.2381 Accuracy 0.4396\n",
      "Epoch 174 Batch 700 Loss 0.2398 Accuracy 0.4390\n",
      "Epoch 174 Loss 0.2400 Accuracy 0.4390\n",
      "Time taken for 1 epoch: 34.404698848724365 secs\n",
      "\n",
      "Epoch 175 Batch 0 Loss 0.1755 Accuracy 0.4579\n",
      "Epoch 175 Batch 50 Loss 0.2139 Accuracy 0.4383\n",
      "Epoch 175 Batch 100 Loss 0.2162 Accuracy 0.4407\n",
      "Epoch 175 Batch 150 Loss 0.2199 Accuracy 0.4396\n",
      "Epoch 175 Batch 200 Loss 0.2228 Accuracy 0.4400\n",
      "Epoch 175 Batch 250 Loss 0.2250 Accuracy 0.4392\n",
      "Epoch 175 Batch 300 Loss 0.2272 Accuracy 0.4396\n",
      "Epoch 175 Batch 350 Loss 0.2291 Accuracy 0.4391\n",
      "Epoch 175 Batch 400 Loss 0.2313 Accuracy 0.4385\n",
      "Epoch 175 Batch 450 Loss 0.2328 Accuracy 0.4389\n",
      "Epoch 175 Batch 500 Loss 0.2341 Accuracy 0.4390\n",
      "Epoch 175 Batch 550 Loss 0.2354 Accuracy 0.4394\n",
      "Epoch 175 Batch 600 Loss 0.2369 Accuracy 0.4395\n",
      "Epoch 175 Batch 650 Loss 0.2382 Accuracy 0.4393\n",
      "Epoch 175 Batch 700 Loss 0.2402 Accuracy 0.4390\n",
      "Saving checkpoint for epoch 175 at ./checkpoints/train/ckpt-47\n",
      "Epoch 175 Loss 0.2404 Accuracy 0.4391\n",
      "Time taken for 1 epoch: 34.55392909049988 secs\n",
      "\n",
      "Epoch 176 Batch 0 Loss 0.2244 Accuracy 0.4207\n",
      "Epoch 176 Batch 50 Loss 0.2156 Accuracy 0.4435\n",
      "Epoch 176 Batch 100 Loss 0.2165 Accuracy 0.4423\n",
      "Epoch 176 Batch 150 Loss 0.2175 Accuracy 0.4432\n",
      "Epoch 176 Batch 200 Loss 0.2199 Accuracy 0.4414\n",
      "Epoch 176 Batch 250 Loss 0.2224 Accuracy 0.4420\n",
      "Epoch 176 Batch 300 Loss 0.2243 Accuracy 0.4422\n",
      "Epoch 176 Batch 350 Loss 0.2263 Accuracy 0.4417\n",
      "Epoch 176 Batch 400 Loss 0.2277 Accuracy 0.4406\n",
      "Epoch 176 Batch 450 Loss 0.2298 Accuracy 0.4407\n",
      "Epoch 176 Batch 500 Loss 0.2316 Accuracy 0.4403\n",
      "Epoch 176 Batch 550 Loss 0.2328 Accuracy 0.4399\n",
      "Epoch 176 Batch 600 Loss 0.2344 Accuracy 0.4403\n",
      "Epoch 176 Batch 650 Loss 0.2361 Accuracy 0.4405\n",
      "Epoch 176 Batch 700 Loss 0.2377 Accuracy 0.4402\n",
      "Epoch 176 Loss 0.2378 Accuracy 0.4402\n",
      "Time taken for 1 epoch: 34.396260023117065 secs\n",
      "\n",
      "Epoch 177 Batch 0 Loss 0.1751 Accuracy 0.3972\n",
      "Epoch 177 Batch 50 Loss 0.2152 Accuracy 0.4408\n",
      "Epoch 177 Batch 100 Loss 0.2164 Accuracy 0.4372\n",
      "Epoch 177 Batch 150 Loss 0.2179 Accuracy 0.4384\n",
      "Epoch 177 Batch 200 Loss 0.2199 Accuracy 0.4383\n",
      "Epoch 177 Batch 250 Loss 0.2216 Accuracy 0.4395\n",
      "Epoch 177 Batch 300 Loss 0.2237 Accuracy 0.4397\n",
      "Epoch 177 Batch 350 Loss 0.2253 Accuracy 0.4396\n",
      "Epoch 177 Batch 400 Loss 0.2264 Accuracy 0.4397\n",
      "Epoch 177 Batch 450 Loss 0.2285 Accuracy 0.4396\n",
      "Epoch 177 Batch 500 Loss 0.2302 Accuracy 0.4398\n",
      "Epoch 177 Batch 550 Loss 0.2319 Accuracy 0.4395\n",
      "Epoch 177 Batch 600 Loss 0.2336 Accuracy 0.4396\n",
      "Epoch 177 Batch 650 Loss 0.2356 Accuracy 0.4395\n",
      "Epoch 177 Batch 700 Loss 0.2376 Accuracy 0.4395\n",
      "Epoch 177 Loss 0.2376 Accuracy 0.4395\n",
      "Time taken for 1 epoch: 34.384316205978394 secs\n",
      "\n",
      "Epoch 178 Batch 0 Loss 0.2060 Accuracy 0.4239\n",
      "Epoch 178 Batch 50 Loss 0.2101 Accuracy 0.4387\n",
      "Epoch 178 Batch 100 Loss 0.2134 Accuracy 0.4401\n",
      "Epoch 178 Batch 150 Loss 0.2162 Accuracy 0.4409\n",
      "Epoch 178 Batch 200 Loss 0.2183 Accuracy 0.4402\n",
      "Epoch 178 Batch 250 Loss 0.2206 Accuracy 0.4403\n",
      "Epoch 178 Batch 300 Loss 0.2228 Accuracy 0.4407\n",
      "Epoch 178 Batch 350 Loss 0.2252 Accuracy 0.4410\n",
      "Epoch 178 Batch 400 Loss 0.2267 Accuracy 0.4417\n",
      "Epoch 178 Batch 450 Loss 0.2286 Accuracy 0.4415\n",
      "Epoch 178 Batch 500 Loss 0.2305 Accuracy 0.4409\n",
      "Epoch 178 Batch 550 Loss 0.2319 Accuracy 0.4407\n",
      "Epoch 178 Batch 600 Loss 0.2341 Accuracy 0.4402\n",
      "Epoch 178 Batch 650 Loss 0.2357 Accuracy 0.4403\n",
      "Epoch 178 Batch 700 Loss 0.2373 Accuracy 0.4404\n",
      "Epoch 178 Loss 0.2373 Accuracy 0.4403\n",
      "Time taken for 1 epoch: 34.3688268661499 secs\n",
      "\n",
      "Epoch 179 Batch 0 Loss 0.2454 Accuracy 0.4784\n",
      "Epoch 179 Batch 50 Loss 0.2152 Accuracy 0.4412\n",
      "Epoch 179 Batch 100 Loss 0.2151 Accuracy 0.4423\n",
      "Epoch 179 Batch 150 Loss 0.2183 Accuracy 0.4436\n",
      "Epoch 179 Batch 200 Loss 0.2216 Accuracy 0.4417\n",
      "Epoch 179 Batch 250 Loss 0.2232 Accuracy 0.4412\n",
      "Epoch 179 Batch 300 Loss 0.2244 Accuracy 0.4408\n",
      "Epoch 179 Batch 350 Loss 0.2261 Accuracy 0.4399\n",
      "Epoch 179 Batch 400 Loss 0.2271 Accuracy 0.4401\n",
      "Epoch 179 Batch 450 Loss 0.2284 Accuracy 0.4404\n",
      "Epoch 179 Batch 500 Loss 0.2302 Accuracy 0.4408\n",
      "Epoch 179 Batch 550 Loss 0.2322 Accuracy 0.4401\n",
      "Epoch 179 Batch 600 Loss 0.2341 Accuracy 0.4401\n",
      "Epoch 179 Batch 650 Loss 0.2362 Accuracy 0.4400\n",
      "Epoch 179 Batch 700 Loss 0.2381 Accuracy 0.4394\n",
      "Epoch 179 Loss 0.2381 Accuracy 0.4394\n",
      "Time taken for 1 epoch: 34.3587851524353 secs\n",
      "\n",
      "Epoch 180 Batch 0 Loss 0.2127 Accuracy 0.4058\n",
      "Epoch 180 Batch 50 Loss 0.2146 Accuracy 0.4419\n",
      "Epoch 180 Batch 100 Loss 0.2132 Accuracy 0.4389\n",
      "Epoch 180 Batch 150 Loss 0.2155 Accuracy 0.4408\n",
      "Epoch 180 Batch 200 Loss 0.2187 Accuracy 0.4398\n",
      "Epoch 180 Batch 250 Loss 0.2210 Accuracy 0.4400\n",
      "Epoch 180 Batch 300 Loss 0.2239 Accuracy 0.4401\n",
      "Epoch 180 Batch 350 Loss 0.2258 Accuracy 0.4398\n",
      "Epoch 180 Batch 400 Loss 0.2281 Accuracy 0.4394\n",
      "Epoch 180 Batch 450 Loss 0.2296 Accuracy 0.4397\n",
      "Epoch 180 Batch 500 Loss 0.2311 Accuracy 0.4394\n",
      "Epoch 180 Batch 550 Loss 0.2319 Accuracy 0.4391\n",
      "Epoch 180 Batch 600 Loss 0.2335 Accuracy 0.4400\n",
      "Epoch 180 Batch 650 Loss 0.2352 Accuracy 0.4393\n",
      "Epoch 180 Batch 700 Loss 0.2372 Accuracy 0.4390\n",
      "Saving checkpoint for epoch 180 at ./checkpoints/train/ckpt-48\n",
      "Epoch 180 Loss 0.2374 Accuracy 0.4390\n",
      "Time taken for 1 epoch: 34.55510210990906 secs\n",
      "\n",
      "Epoch 181 Batch 0 Loss 0.2415 Accuracy 0.4219\n",
      "Epoch 181 Batch 50 Loss 0.2118 Accuracy 0.4456\n",
      "Epoch 181 Batch 100 Loss 0.2161 Accuracy 0.4438\n",
      "Epoch 181 Batch 150 Loss 0.2179 Accuracy 0.4448\n",
      "Epoch 181 Batch 200 Loss 0.2205 Accuracy 0.4431\n",
      "Epoch 181 Batch 250 Loss 0.2217 Accuracy 0.4430\n",
      "Epoch 181 Batch 300 Loss 0.2234 Accuracy 0.4431\n",
      "Epoch 181 Batch 350 Loss 0.2251 Accuracy 0.4425\n",
      "Epoch 181 Batch 400 Loss 0.2258 Accuracy 0.4427\n",
      "Epoch 181 Batch 450 Loss 0.2276 Accuracy 0.4425\n",
      "Epoch 181 Batch 500 Loss 0.2297 Accuracy 0.4422\n",
      "Epoch 181 Batch 550 Loss 0.2312 Accuracy 0.4418\n",
      "Epoch 181 Batch 600 Loss 0.2327 Accuracy 0.4415\n",
      "Epoch 181 Batch 650 Loss 0.2340 Accuracy 0.4407\n",
      "Epoch 181 Batch 700 Loss 0.2356 Accuracy 0.4399\n",
      "Epoch 181 Loss 0.2357 Accuracy 0.4400\n",
      "Time taken for 1 epoch: 34.409071922302246 secs\n",
      "\n",
      "Epoch 182 Batch 0 Loss 0.2145 Accuracy 0.4561\n",
      "Epoch 182 Batch 50 Loss 0.2155 Accuracy 0.4425\n",
      "Epoch 182 Batch 100 Loss 0.2155 Accuracy 0.4405\n",
      "Epoch 182 Batch 150 Loss 0.2167 Accuracy 0.4393\n",
      "Epoch 182 Batch 200 Loss 0.2178 Accuracy 0.4397\n",
      "Epoch 182 Batch 250 Loss 0.2196 Accuracy 0.4389\n",
      "Epoch 182 Batch 300 Loss 0.2222 Accuracy 0.4387\n",
      "Epoch 182 Batch 350 Loss 0.2244 Accuracy 0.4387\n",
      "Epoch 182 Batch 400 Loss 0.2256 Accuracy 0.4396\n",
      "Epoch 182 Batch 450 Loss 0.2275 Accuracy 0.4397\n",
      "Epoch 182 Batch 500 Loss 0.2295 Accuracy 0.4394\n",
      "Epoch 182 Batch 550 Loss 0.2313 Accuracy 0.4393\n",
      "Epoch 182 Batch 600 Loss 0.2328 Accuracy 0.4396\n",
      "Epoch 182 Batch 650 Loss 0.2343 Accuracy 0.4392\n",
      "Epoch 182 Batch 700 Loss 0.2360 Accuracy 0.4392\n",
      "Epoch 182 Loss 0.2361 Accuracy 0.4392\n",
      "Time taken for 1 epoch: 34.38206434249878 secs\n",
      "\n",
      "Epoch 183 Batch 0 Loss 0.2130 Accuracy 0.4379\n",
      "Epoch 183 Batch 50 Loss 0.2083 Accuracy 0.4447\n",
      "Epoch 183 Batch 100 Loss 0.2123 Accuracy 0.4428\n",
      "Epoch 183 Batch 150 Loss 0.2149 Accuracy 0.4437\n",
      "Epoch 183 Batch 200 Loss 0.2150 Accuracy 0.4439\n",
      "Epoch 183 Batch 250 Loss 0.2166 Accuracy 0.4444\n",
      "Epoch 183 Batch 300 Loss 0.2184 Accuracy 0.4439\n",
      "Epoch 183 Batch 350 Loss 0.2203 Accuracy 0.4419\n",
      "Epoch 183 Batch 400 Loss 0.2219 Accuracy 0.4421\n",
      "Epoch 183 Batch 450 Loss 0.2245 Accuracy 0.4419\n",
      "Epoch 183 Batch 500 Loss 0.2263 Accuracy 0.4417\n",
      "Epoch 183 Batch 550 Loss 0.2280 Accuracy 0.4411\n",
      "Epoch 183 Batch 600 Loss 0.2307 Accuracy 0.4410\n",
      "Epoch 183 Batch 650 Loss 0.2322 Accuracy 0.4408\n",
      "Epoch 183 Batch 700 Loss 0.2346 Accuracy 0.4406\n",
      "Epoch 183 Loss 0.2347 Accuracy 0.4406\n",
      "Time taken for 1 epoch: 34.43298697471619 secs\n",
      "\n",
      "Epoch 184 Batch 0 Loss 0.1947 Accuracy 0.4631\n",
      "Epoch 184 Batch 50 Loss 0.2145 Accuracy 0.4373\n",
      "Epoch 184 Batch 100 Loss 0.2173 Accuracy 0.4407\n",
      "Epoch 184 Batch 150 Loss 0.2187 Accuracy 0.4408\n",
      "Epoch 184 Batch 200 Loss 0.2202 Accuracy 0.4408\n",
      "Epoch 184 Batch 250 Loss 0.2221 Accuracy 0.4415\n",
      "Epoch 184 Batch 300 Loss 0.2233 Accuracy 0.4409\n",
      "Epoch 184 Batch 350 Loss 0.2247 Accuracy 0.4405\n",
      "Epoch 184 Batch 400 Loss 0.2257 Accuracy 0.4402\n",
      "Epoch 184 Batch 450 Loss 0.2277 Accuracy 0.4395\n",
      "Epoch 184 Batch 500 Loss 0.2288 Accuracy 0.4401\n",
      "Epoch 184 Batch 550 Loss 0.2303 Accuracy 0.4399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184 Batch 600 Loss 0.2317 Accuracy 0.4400\n",
      "Epoch 184 Batch 650 Loss 0.2336 Accuracy 0.4396\n",
      "Epoch 184 Batch 700 Loss 0.2353 Accuracy 0.4397\n",
      "Epoch 184 Loss 0.2355 Accuracy 0.4397\n",
      "Time taken for 1 epoch: 34.402355909347534 secs\n",
      "\n",
      "Epoch 185 Batch 0 Loss 0.1821 Accuracy 0.4347\n",
      "Epoch 185 Batch 50 Loss 0.2113 Accuracy 0.4463\n",
      "Epoch 185 Batch 100 Loss 0.2138 Accuracy 0.4459\n",
      "Epoch 185 Batch 150 Loss 0.2173 Accuracy 0.4473\n",
      "Epoch 185 Batch 200 Loss 0.2184 Accuracy 0.4456\n",
      "Epoch 185 Batch 250 Loss 0.2196 Accuracy 0.4442\n",
      "Epoch 185 Batch 300 Loss 0.2212 Accuracy 0.4434\n",
      "Epoch 185 Batch 350 Loss 0.2222 Accuracy 0.4441\n",
      "Epoch 185 Batch 400 Loss 0.2242 Accuracy 0.4436\n",
      "Epoch 185 Batch 450 Loss 0.2266 Accuracy 0.4424\n",
      "Epoch 185 Batch 500 Loss 0.2283 Accuracy 0.4420\n",
      "Epoch 185 Batch 550 Loss 0.2297 Accuracy 0.4417\n",
      "Epoch 185 Batch 600 Loss 0.2320 Accuracy 0.4409\n",
      "Epoch 185 Batch 650 Loss 0.2341 Accuracy 0.4408\n",
      "Epoch 185 Batch 700 Loss 0.2359 Accuracy 0.4405\n",
      "Saving checkpoint for epoch 185 at ./checkpoints/train/ckpt-49\n",
      "Epoch 185 Loss 0.2360 Accuracy 0.4405\n",
      "Time taken for 1 epoch: 34.51329040527344 secs\n",
      "\n",
      "Epoch 186 Batch 0 Loss 0.1948 Accuracy 0.4286\n",
      "Epoch 186 Batch 50 Loss 0.2160 Accuracy 0.4423\n",
      "Epoch 186 Batch 100 Loss 0.2135 Accuracy 0.4404\n",
      "Epoch 186 Batch 150 Loss 0.2156 Accuracy 0.4388\n",
      "Epoch 186 Batch 200 Loss 0.2174 Accuracy 0.4399\n",
      "Epoch 186 Batch 250 Loss 0.2187 Accuracy 0.4411\n",
      "Epoch 186 Batch 300 Loss 0.2212 Accuracy 0.4414\n",
      "Epoch 186 Batch 350 Loss 0.2235 Accuracy 0.4413\n",
      "Epoch 186 Batch 400 Loss 0.2247 Accuracy 0.4410\n",
      "Epoch 186 Batch 450 Loss 0.2261 Accuracy 0.4410\n",
      "Epoch 186 Batch 500 Loss 0.2279 Accuracy 0.4411\n",
      "Epoch 186 Batch 550 Loss 0.2296 Accuracy 0.4408\n",
      "Epoch 186 Batch 600 Loss 0.2316 Accuracy 0.4408\n",
      "Epoch 186 Batch 650 Loss 0.2336 Accuracy 0.4406\n",
      "Epoch 186 Batch 700 Loss 0.2354 Accuracy 0.4406\n",
      "Epoch 186 Loss 0.2354 Accuracy 0.4406\n",
      "Time taken for 1 epoch: 34.34023189544678 secs\n",
      "\n",
      "Epoch 187 Batch 0 Loss 0.2286 Accuracy 0.4486\n",
      "Epoch 187 Batch 50 Loss 0.2111 Accuracy 0.4429\n",
      "Epoch 187 Batch 100 Loss 0.2114 Accuracy 0.4434\n",
      "Epoch 187 Batch 150 Loss 0.2133 Accuracy 0.4410\n",
      "Epoch 187 Batch 200 Loss 0.2171 Accuracy 0.4406\n",
      "Epoch 187 Batch 250 Loss 0.2195 Accuracy 0.4416\n",
      "Epoch 187 Batch 300 Loss 0.2214 Accuracy 0.4408\n",
      "Epoch 187 Batch 350 Loss 0.2226 Accuracy 0.4404\n",
      "Epoch 187 Batch 400 Loss 0.2242 Accuracy 0.4409\n",
      "Epoch 187 Batch 450 Loss 0.2258 Accuracy 0.4410\n",
      "Epoch 187 Batch 500 Loss 0.2278 Accuracy 0.4411\n",
      "Epoch 187 Batch 550 Loss 0.2293 Accuracy 0.4411\n",
      "Epoch 187 Batch 600 Loss 0.2307 Accuracy 0.4403\n",
      "Epoch 187 Batch 650 Loss 0.2324 Accuracy 0.4404\n",
      "Epoch 187 Batch 700 Loss 0.2339 Accuracy 0.4402\n",
      "Epoch 187 Loss 0.2340 Accuracy 0.4402\n",
      "Time taken for 1 epoch: 34.3887300491333 secs\n",
      "\n",
      "Epoch 188 Batch 0 Loss 0.1983 Accuracy 0.4612\n",
      "Epoch 188 Batch 50 Loss 0.2142 Accuracy 0.4426\n",
      "Epoch 188 Batch 100 Loss 0.2142 Accuracy 0.4414\n",
      "Epoch 188 Batch 150 Loss 0.2149 Accuracy 0.4415\n",
      "Epoch 188 Batch 200 Loss 0.2161 Accuracy 0.4419\n",
      "Epoch 188 Batch 250 Loss 0.2184 Accuracy 0.4419\n",
      "Epoch 188 Batch 300 Loss 0.2203 Accuracy 0.4427\n",
      "Epoch 188 Batch 350 Loss 0.2221 Accuracy 0.4419\n",
      "Epoch 188 Batch 400 Loss 0.2233 Accuracy 0.4414\n",
      "Epoch 188 Batch 450 Loss 0.2250 Accuracy 0.4418\n",
      "Epoch 188 Batch 500 Loss 0.2274 Accuracy 0.4414\n",
      "Epoch 188 Batch 550 Loss 0.2288 Accuracy 0.4412\n",
      "Epoch 188 Batch 600 Loss 0.2310 Accuracy 0.4411\n",
      "Epoch 188 Batch 650 Loss 0.2325 Accuracy 0.4411\n",
      "Epoch 188 Batch 700 Loss 0.2338 Accuracy 0.4408\n",
      "Epoch 188 Loss 0.2339 Accuracy 0.4409\n",
      "Time taken for 1 epoch: 34.297353982925415 secs\n",
      "\n",
      "Epoch 189 Batch 0 Loss 0.1918 Accuracy 0.4434\n",
      "Epoch 189 Batch 50 Loss 0.2084 Accuracy 0.4400\n",
      "Epoch 189 Batch 100 Loss 0.2114 Accuracy 0.4413\n",
      "Epoch 189 Batch 150 Loss 0.2157 Accuracy 0.4424\n",
      "Epoch 189 Batch 200 Loss 0.2161 Accuracy 0.4427\n",
      "Epoch 189 Batch 250 Loss 0.2180 Accuracy 0.4433\n",
      "Epoch 189 Batch 300 Loss 0.2197 Accuracy 0.4432\n",
      "Epoch 189 Batch 350 Loss 0.2217 Accuracy 0.4411\n",
      "Epoch 189 Batch 400 Loss 0.2232 Accuracy 0.4411\n",
      "Epoch 189 Batch 450 Loss 0.2249 Accuracy 0.4414\n",
      "Epoch 189 Batch 500 Loss 0.2264 Accuracy 0.4414\n",
      "Epoch 189 Batch 550 Loss 0.2284 Accuracy 0.4411\n",
      "Epoch 189 Batch 600 Loss 0.2298 Accuracy 0.4408\n",
      "Epoch 189 Batch 650 Loss 0.2312 Accuracy 0.4407\n",
      "Epoch 189 Batch 700 Loss 0.2327 Accuracy 0.4408\n",
      "Epoch 189 Loss 0.2328 Accuracy 0.4407\n",
      "Time taken for 1 epoch: 34.37145185470581 secs\n",
      "\n",
      "Epoch 190 Batch 0 Loss 0.2197 Accuracy 0.4135\n",
      "Epoch 190 Batch 50 Loss 0.2083 Accuracy 0.4390\n",
      "Epoch 190 Batch 100 Loss 0.2101 Accuracy 0.4403\n",
      "Epoch 190 Batch 150 Loss 0.2125 Accuracy 0.4407\n",
      "Epoch 190 Batch 200 Loss 0.2144 Accuracy 0.4394\n",
      "Epoch 190 Batch 250 Loss 0.2165 Accuracy 0.4408\n",
      "Epoch 190 Batch 300 Loss 0.2188 Accuracy 0.4409\n",
      "Epoch 190 Batch 350 Loss 0.2208 Accuracy 0.4410\n",
      "Epoch 190 Batch 400 Loss 0.2223 Accuracy 0.4412\n",
      "Epoch 190 Batch 450 Loss 0.2239 Accuracy 0.4412\n",
      "Epoch 190 Batch 500 Loss 0.2252 Accuracy 0.4407\n",
      "Epoch 190 Batch 550 Loss 0.2273 Accuracy 0.4405\n",
      "Epoch 190 Batch 600 Loss 0.2291 Accuracy 0.4400\n",
      "Epoch 190 Batch 650 Loss 0.2310 Accuracy 0.4404\n",
      "Epoch 190 Batch 700 Loss 0.2326 Accuracy 0.4401\n",
      "Saving checkpoint for epoch 190 at ./checkpoints/train/ckpt-50\n",
      "Epoch 190 Loss 0.2326 Accuracy 0.4402\n",
      "Time taken for 1 epoch: 34.50573420524597 secs\n",
      "\n",
      "Epoch 191 Batch 0 Loss 0.2167 Accuracy 0.4319\n",
      "Epoch 191 Batch 50 Loss 0.2121 Accuracy 0.4411\n",
      "Epoch 191 Batch 100 Loss 0.2131 Accuracy 0.4448\n",
      "Epoch 191 Batch 150 Loss 0.2135 Accuracy 0.4426\n",
      "Epoch 191 Batch 200 Loss 0.2169 Accuracy 0.4431\n",
      "Epoch 191 Batch 250 Loss 0.2180 Accuracy 0.4427\n",
      "Epoch 191 Batch 300 Loss 0.2198 Accuracy 0.4419\n",
      "Epoch 191 Batch 350 Loss 0.2218 Accuracy 0.4421\n",
      "Epoch 191 Batch 400 Loss 0.2233 Accuracy 0.4421\n",
      "Epoch 191 Batch 450 Loss 0.2246 Accuracy 0.4418\n",
      "Epoch 191 Batch 500 Loss 0.2258 Accuracy 0.4415\n",
      "Epoch 191 Batch 550 Loss 0.2275 Accuracy 0.4414\n",
      "Epoch 191 Batch 600 Loss 0.2288 Accuracy 0.4412\n",
      "Epoch 191 Batch 650 Loss 0.2307 Accuracy 0.4408\n",
      "Epoch 191 Batch 700 Loss 0.2322 Accuracy 0.4408\n",
      "Epoch 191 Loss 0.2322 Accuracy 0.4408\n",
      "Time taken for 1 epoch: 34.36666250228882 secs\n",
      "\n",
      "Epoch 192 Batch 0 Loss 0.1865 Accuracy 0.4761\n",
      "Epoch 192 Batch 50 Loss 0.2067 Accuracy 0.4426\n",
      "Epoch 192 Batch 100 Loss 0.2074 Accuracy 0.4433\n",
      "Epoch 192 Batch 150 Loss 0.2110 Accuracy 0.4440\n",
      "Epoch 192 Batch 200 Loss 0.2136 Accuracy 0.4421\n",
      "Epoch 192 Batch 250 Loss 0.2156 Accuracy 0.4415\n",
      "Epoch 192 Batch 300 Loss 0.2178 Accuracy 0.4418\n",
      "Epoch 192 Batch 350 Loss 0.2204 Accuracy 0.4414\n",
      "Epoch 192 Batch 400 Loss 0.2223 Accuracy 0.4413\n",
      "Epoch 192 Batch 450 Loss 0.2238 Accuracy 0.4413\n",
      "Epoch 192 Batch 500 Loss 0.2249 Accuracy 0.4408\n",
      "Epoch 192 Batch 550 Loss 0.2267 Accuracy 0.4409\n",
      "Epoch 192 Batch 600 Loss 0.2283 Accuracy 0.4409\n",
      "Epoch 192 Batch 650 Loss 0.2302 Accuracy 0.4406\n",
      "Epoch 192 Batch 700 Loss 0.2322 Accuracy 0.4403\n",
      "Epoch 192 Loss 0.2324 Accuracy 0.4403\n",
      "Time taken for 1 epoch: 34.35400199890137 secs\n",
      "\n",
      "Epoch 193 Batch 0 Loss 0.2128 Accuracy 0.4282\n",
      "Epoch 193 Batch 50 Loss 0.2090 Accuracy 0.4474\n",
      "Epoch 193 Batch 100 Loss 0.2099 Accuracy 0.4437\n",
      "Epoch 193 Batch 150 Loss 0.2115 Accuracy 0.4424\n",
      "Epoch 193 Batch 200 Loss 0.2143 Accuracy 0.4438\n",
      "Epoch 193 Batch 250 Loss 0.2161 Accuracy 0.4437\n",
      "Epoch 193 Batch 300 Loss 0.2190 Accuracy 0.4428\n",
      "Epoch 193 Batch 350 Loss 0.2211 Accuracy 0.4421\n",
      "Epoch 193 Batch 400 Loss 0.2229 Accuracy 0.4416\n",
      "Epoch 193 Batch 450 Loss 0.2240 Accuracy 0.4420\n",
      "Epoch 193 Batch 500 Loss 0.2258 Accuracy 0.4415\n",
      "Epoch 193 Batch 550 Loss 0.2277 Accuracy 0.4412\n",
      "Epoch 193 Batch 600 Loss 0.2285 Accuracy 0.4406\n",
      "Epoch 193 Batch 650 Loss 0.2306 Accuracy 0.4406\n",
      "Epoch 193 Batch 700 Loss 0.2321 Accuracy 0.4405\n",
      "Epoch 193 Loss 0.2322 Accuracy 0.4405\n",
      "Time taken for 1 epoch: 34.36698603630066 secs\n",
      "\n",
      "Epoch 194 Batch 0 Loss 0.2359 Accuracy 0.4219\n",
      "Epoch 194 Batch 50 Loss 0.2138 Accuracy 0.4447\n",
      "Epoch 194 Batch 100 Loss 0.2117 Accuracy 0.4461\n",
      "Epoch 194 Batch 150 Loss 0.2117 Accuracy 0.4441\n",
      "Epoch 194 Batch 200 Loss 0.2146 Accuracy 0.4415\n",
      "Epoch 194 Batch 250 Loss 0.2164 Accuracy 0.4412\n",
      "Epoch 194 Batch 300 Loss 0.2185 Accuracy 0.4416\n",
      "Epoch 194 Batch 350 Loss 0.2195 Accuracy 0.4425\n",
      "Epoch 194 Batch 400 Loss 0.2213 Accuracy 0.4419\n",
      "Epoch 194 Batch 450 Loss 0.2220 Accuracy 0.4419\n",
      "Epoch 194 Batch 500 Loss 0.2236 Accuracy 0.4413\n",
      "Epoch 194 Batch 550 Loss 0.2258 Accuracy 0.4407\n",
      "Epoch 194 Batch 600 Loss 0.2272 Accuracy 0.4405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194 Batch 650 Loss 0.2286 Accuracy 0.4404\n",
      "Epoch 194 Batch 700 Loss 0.2303 Accuracy 0.4407\n",
      "Epoch 194 Loss 0.2304 Accuracy 0.4407\n",
      "Time taken for 1 epoch: 34.35343647003174 secs\n",
      "\n",
      "Epoch 195 Batch 0 Loss 0.2185 Accuracy 0.4443\n",
      "Epoch 195 Batch 50 Loss 0.2044 Accuracy 0.4367\n",
      "Epoch 195 Batch 100 Loss 0.2062 Accuracy 0.4408\n",
      "Epoch 195 Batch 150 Loss 0.2088 Accuracy 0.4411\n",
      "Epoch 195 Batch 200 Loss 0.2117 Accuracy 0.4408\n",
      "Epoch 195 Batch 250 Loss 0.2147 Accuracy 0.4402\n",
      "Epoch 195 Batch 300 Loss 0.2170 Accuracy 0.4417\n",
      "Epoch 195 Batch 350 Loss 0.2181 Accuracy 0.4424\n",
      "Epoch 195 Batch 400 Loss 0.2202 Accuracy 0.4421\n",
      "Epoch 195 Batch 450 Loss 0.2215 Accuracy 0.4420\n",
      "Epoch 195 Batch 500 Loss 0.2229 Accuracy 0.4417\n",
      "Epoch 195 Batch 550 Loss 0.2246 Accuracy 0.4415\n",
      "Epoch 195 Batch 600 Loss 0.2262 Accuracy 0.4409\n",
      "Epoch 195 Batch 650 Loss 0.2279 Accuracy 0.4411\n",
      "Epoch 195 Batch 700 Loss 0.2296 Accuracy 0.4409\n",
      "Saving checkpoint for epoch 195 at ./checkpoints/train/ckpt-51\n",
      "Epoch 195 Loss 0.2296 Accuracy 0.4409\n",
      "Time taken for 1 epoch: 34.51220679283142 secs\n",
      "\n",
      "Epoch 196 Batch 0 Loss 0.2115 Accuracy 0.4332\n",
      "Epoch 196 Batch 50 Loss 0.1980 Accuracy 0.4457\n",
      "Epoch 196 Batch 100 Loss 0.2018 Accuracy 0.4442\n",
      "Epoch 196 Batch 150 Loss 0.2059 Accuracy 0.4460\n",
      "Epoch 196 Batch 200 Loss 0.2099 Accuracy 0.4458\n",
      "Epoch 196 Batch 250 Loss 0.2119 Accuracy 0.4448\n",
      "Epoch 196 Batch 300 Loss 0.2147 Accuracy 0.4443\n",
      "Epoch 196 Batch 350 Loss 0.2171 Accuracy 0.4429\n",
      "Epoch 196 Batch 400 Loss 0.2193 Accuracy 0.4425\n",
      "Epoch 196 Batch 450 Loss 0.2205 Accuracy 0.4419\n",
      "Epoch 196 Batch 500 Loss 0.2225 Accuracy 0.4414\n",
      "Epoch 196 Batch 550 Loss 0.2242 Accuracy 0.4416\n",
      "Epoch 196 Batch 600 Loss 0.2258 Accuracy 0.4418\n",
      "Epoch 196 Batch 650 Loss 0.2278 Accuracy 0.4416\n",
      "Epoch 196 Batch 700 Loss 0.2299 Accuracy 0.4415\n",
      "Epoch 196 Loss 0.2300 Accuracy 0.4415\n",
      "Time taken for 1 epoch: 34.393985986709595 secs\n",
      "\n",
      "Epoch 197 Batch 0 Loss 0.1808 Accuracy 0.4227\n",
      "Epoch 197 Batch 50 Loss 0.2056 Accuracy 0.4419\n",
      "Epoch 197 Batch 100 Loss 0.2096 Accuracy 0.4413\n",
      "Epoch 197 Batch 150 Loss 0.2104 Accuracy 0.4416\n",
      "Epoch 197 Batch 200 Loss 0.2121 Accuracy 0.4422\n",
      "Epoch 197 Batch 250 Loss 0.2134 Accuracy 0.4421\n",
      "Epoch 197 Batch 300 Loss 0.2147 Accuracy 0.4420\n",
      "Epoch 197 Batch 350 Loss 0.2162 Accuracy 0.4415\n",
      "Epoch 197 Batch 400 Loss 0.2183 Accuracy 0.4408\n",
      "Epoch 197 Batch 450 Loss 0.2198 Accuracy 0.4407\n",
      "Epoch 197 Batch 500 Loss 0.2215 Accuracy 0.4402\n",
      "Epoch 197 Batch 550 Loss 0.2238 Accuracy 0.4405\n",
      "Epoch 197 Batch 600 Loss 0.2249 Accuracy 0.4402\n",
      "Epoch 197 Batch 650 Loss 0.2265 Accuracy 0.4404\n",
      "Epoch 197 Batch 700 Loss 0.2283 Accuracy 0.4402\n",
      "Epoch 197 Loss 0.2284 Accuracy 0.4402\n",
      "Time taken for 1 epoch: 34.39749479293823 secs\n",
      "\n",
      "Epoch 198 Batch 0 Loss 0.2063 Accuracy 0.4498\n",
      "Epoch 198 Batch 50 Loss 0.2060 Accuracy 0.4440\n",
      "Epoch 198 Batch 100 Loss 0.2076 Accuracy 0.4433\n",
      "Epoch 198 Batch 150 Loss 0.2092 Accuracy 0.4422\n",
      "Epoch 198 Batch 200 Loss 0.2110 Accuracy 0.4415\n",
      "Epoch 198 Batch 250 Loss 0.2138 Accuracy 0.4408\n",
      "Epoch 198 Batch 300 Loss 0.2161 Accuracy 0.4407\n",
      "Epoch 198 Batch 350 Loss 0.2178 Accuracy 0.4408\n",
      "Epoch 198 Batch 400 Loss 0.2192 Accuracy 0.4418\n",
      "Epoch 198 Batch 450 Loss 0.2203 Accuracy 0.4419\n",
      "Epoch 198 Batch 500 Loss 0.2220 Accuracy 0.4421\n",
      "Epoch 198 Batch 550 Loss 0.2240 Accuracy 0.4420\n",
      "Epoch 198 Batch 600 Loss 0.2256 Accuracy 0.4419\n",
      "Epoch 198 Batch 650 Loss 0.2276 Accuracy 0.4419\n",
      "Epoch 198 Batch 700 Loss 0.2296 Accuracy 0.4414\n",
      "Epoch 198 Loss 0.2297 Accuracy 0.4414\n",
      "Time taken for 1 epoch: 34.325456380844116 secs\n",
      "\n",
      "Epoch 199 Batch 0 Loss 0.2231 Accuracy 0.3923\n",
      "Epoch 199 Batch 50 Loss 0.2093 Accuracy 0.4379\n",
      "Epoch 199 Batch 100 Loss 0.2082 Accuracy 0.4436\n",
      "Epoch 199 Batch 150 Loss 0.2098 Accuracy 0.4399\n",
      "Epoch 199 Batch 200 Loss 0.2121 Accuracy 0.4404\n",
      "Epoch 199 Batch 250 Loss 0.2125 Accuracy 0.4418\n",
      "Epoch 199 Batch 300 Loss 0.2141 Accuracy 0.4419\n",
      "Epoch 199 Batch 350 Loss 0.2157 Accuracy 0.4417\n",
      "Epoch 199 Batch 400 Loss 0.2173 Accuracy 0.4414\n",
      "Epoch 199 Batch 450 Loss 0.2184 Accuracy 0.4416\n",
      "Epoch 199 Batch 500 Loss 0.2201 Accuracy 0.4422\n",
      "Epoch 199 Batch 550 Loss 0.2220 Accuracy 0.4420\n",
      "Epoch 199 Batch 600 Loss 0.2239 Accuracy 0.4418\n",
      "Epoch 199 Batch 650 Loss 0.2260 Accuracy 0.4416\n",
      "Epoch 199 Batch 700 Loss 0.2272 Accuracy 0.4420\n",
      "Epoch 199 Loss 0.2272 Accuracy 0.4420\n",
      "Time taken for 1 epoch: 34.32305550575256 secs\n",
      "\n",
      "Epoch 200 Batch 0 Loss 0.2294 Accuracy 0.4309\n",
      "Epoch 200 Batch 50 Loss 0.2036 Accuracy 0.4399\n",
      "Epoch 200 Batch 100 Loss 0.2043 Accuracy 0.4409\n",
      "Epoch 200 Batch 150 Loss 0.2063 Accuracy 0.4411\n",
      "Epoch 200 Batch 200 Loss 0.2103 Accuracy 0.4424\n",
      "Epoch 200 Batch 250 Loss 0.2121 Accuracy 0.4441\n",
      "Epoch 200 Batch 300 Loss 0.2137 Accuracy 0.4437\n",
      "Epoch 200 Batch 350 Loss 0.2159 Accuracy 0.4422\n",
      "Epoch 200 Batch 400 Loss 0.2181 Accuracy 0.4419\n",
      "Epoch 200 Batch 450 Loss 0.2193 Accuracy 0.4417\n",
      "Epoch 200 Batch 500 Loss 0.2211 Accuracy 0.4418\n",
      "Epoch 200 Batch 550 Loss 0.2229 Accuracy 0.4421\n",
      "Epoch 200 Batch 600 Loss 0.2247 Accuracy 0.4419\n",
      "Epoch 200 Batch 650 Loss 0.2269 Accuracy 0.4414\n",
      "Epoch 200 Batch 700 Loss 0.2283 Accuracy 0.4412\n",
      "Saving checkpoint for epoch 200 at ./checkpoints/train/ckpt-52\n",
      "Epoch 200 Loss 0.2284 Accuracy 0.4412\n",
      "Time taken for 1 epoch: 34.522944927215576 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "  \n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  \n",
    "  # inp -> portuguese, tar -> english\n",
    "  for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "    train_step(inp, tar)\n",
    "    \n",
    "    if batch % 50 == 0:\n",
    "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "      \n",
    "  if (epoch + 1) % 5 == 0:\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                         ckpt_save_path))\n",
    "    \n",
    "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))\n",
    "\n",
    "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "  start_token = [tokenizer_pt.vocab_size]\n",
    "  end_token = [tokenizer_pt.vocab_size + 1]\n",
    "  \n",
    "  # inp sentence is portuguese, hence adding the start and end token\n",
    "  inp_sentence = start_token + tokenizer_pt.encode(inp_sentence) + end_token\n",
    "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
    "  \n",
    "  # as the target is english, the first word to the transformer should be the\n",
    "  # english start token.\n",
    "  decoder_input = [tokenizer_en.vocab_size]\n",
    "  output = tf.expand_dims(decoder_input, 0)\n",
    "    \n",
    "  for i in range(MAX_LENGTH):\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "        encoder_input, output)\n",
    "  \n",
    "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "    predictions, attention_weights = transformer(encoder_input, \n",
    "                                                 output,\n",
    "                                                 False,\n",
    "                                                 enc_padding_mask,\n",
    "                                                 combined_mask,\n",
    "                                                 dec_padding_mask)\n",
    "    \n",
    "    # select the last word from the seq_len dimension\n",
    "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "    \n",
    "    # return the result if the predicted_id is equal to the end token\n",
    "    if predicted_id == tokenizer_en.vocab_size+1:\n",
    "      return tf.squeeze(output, axis=0), attention_weights\n",
    "    \n",
    "    # concatentate the predicted_id to the output which is given to the decoder\n",
    "    # as its input.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "  fig = plt.figure(figsize=(16, 8))\n",
    "  \n",
    "  sentence = tokenizer_pt.encode(sentence)\n",
    "  \n",
    "  attention = tf.squeeze(attention[layer], axis=0)\n",
    "  \n",
    "  for head in range(attention.shape[0]):\n",
    "    ax = fig.add_subplot(2, 4, head+1)\n",
    "    \n",
    "    # plot the attention weights\n",
    "    ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 10}\n",
    "    \n",
    "    ax.set_xticks(range(len(sentence)+2))\n",
    "    ax.set_yticks(range(len(result)))\n",
    "    \n",
    "    ax.set_ylim(len(result)-1.5, -0.5)\n",
    "        \n",
    "    ax.set_xticklabels(\n",
    "        ['<start>']+[tokenizer_pt.decode([i]) for i in sentence]+['<end>'], \n",
    "        fontdict=fontdict, rotation=90)\n",
    "    \n",
    "    ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n",
    "                        if i < tokenizer_en.vocab_size], \n",
    "                       fontdict=fontdict)\n",
    "    \n",
    "    ax.set_xlabel('Head {}'.format(head+1))\n",
    "  \n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence, plot=''):\n",
    "  result, attention_weights = evaluate(sentence)\n",
    "  \n",
    "  predicted_sentence = tokenizer_en.decode([i for i in result \n",
    "                                            if i < tokenizer_en.vocab_size])  \n",
    "\n",
    "  print('Input: {}'.format(sentence))\n",
    "  print('Predicted translation: {}'.format(predicted_sentence))\n",
    "  \n",
    "  if plot:\n",
    "    plot_attention_weights(attention_weights, sentence, result, plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: este é um problema que temos que resolver.\n",
      "Predicted translation: this is a problem we need to solve us .\n",
      "Real translation: this is a problem we have to solve .\n"
     ]
    }
   ],
   "source": [
    "translate(\"este é um problema que temos que resolver.\")\n",
    "print (\"Real translation: this is a problem we have to solve .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: os meus vizinhos ouviram sobre esta ideia.\n",
      "Predicted translation: my neighbors heard about this idea .\n",
      "Real translation: and my neighboring homes heard about this idea .\n"
     ]
    }
   ],
   "source": [
    "translate(\"os meus vizinhos ouviram sobre esta ideia.\")\n",
    "print (\"Real translation: and my neighboring homes heard about this idea .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\n",
      "Predicted translation: so i 'm going to be quickly share with you some magic stories that have happened .\n",
      "Real translation: so i 'll just share with you some stories very quickly of some magical things that have happened .\n"
     ]
    }
   ],
   "source": [
    "translate(\"vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\")\n",
    "print (\"Real translation: so i 'll just share with you some stories very quickly of some magical things that have happened .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: este é o primeiro livro que eu fiz.\n",
      "Predicted translation: that 's the first book i did when i was do .\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real translation: this is the first book i've ever done.\n"
     ]
    }
   ],
   "source": [
    "translate(\"este é o primeiro livro que eu fiz.\", plot='decoder_layer4_block2')\n",
    "print (\"Real translation: this is the first book i've ever done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.5.zip (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 2.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting click\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "\u001b[K     |████████████████████████████████| 82 kB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting joblib\n",
      "  Downloading joblib-0.17.0-py3-none-any.whl (301 kB)\n",
      "\u001b[K     |████████████████████████████████| 301 kB 11.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex\n",
      "  Downloading regex-2020.10.15-cp36-cp36m-manylinux2010_x86_64.whl (662 kB)\n",
      "\u001b[K     |████████████████████████████████| 662 kB 11.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from nltk) (4.50.2)\n",
      "Building wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1435510 sha256=c86ed2f147d34e83e7c1d31ee13cfccef5cf4179fd294f3259cbe4bc6dee4fcf\n",
      "  Stored in directory: /root/.cache/pip/wheels/de/5e/42/64abaeca668161c3e2cecc24f864a8fc421e3d07a104fc8a51\n",
      "Successfully built nltk\n",
      "Installing collected packages: click, joblib, regex, nltk\n",
      "Successfully installed click-7.1.2 joblib-0.17.0 nltk-3.5 regex-2020.10.15\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4671379777282001\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "reference = [\"this is a problem we have to solve .\".split( )]\n",
    "candidate = \"this is a problem we need to solve us .\".split( )\n",
    "score = sentence_bleu(reference, candidate)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4835447404743731\n"
     ]
    }
   ],
   "source": [
    "reference = [\"and my neighboring homes heard about this idea .\".split( )]\n",
    "candidate = \"my neighbors heard about this idea .\".split( )\n",
    "score = sentence_bleu(reference, candidate)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Ola meu nome é Harin.\n",
      "Predicted translation: i made my name is baln .\n",
      "Real translation: Hello my name is Harin .\n"
     ]
    }
   ],
   "source": [
    "translate(\"Ola meu nome é Harin.\")\n",
    "print (\"Real translation: Hello my name is Harin .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.395774370246974e-78\n"
     ]
    }
   ],
   "source": [
    "reference = [\"Hello my name is Harin .\".split( )]\n",
    "candidate = \"i made my name is baln .\".split( )\n",
    "score = sentence_bleu(reference, candidate)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
